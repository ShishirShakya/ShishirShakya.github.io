<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 3.2.0">
  <meta name="generator" content="Hugo 0.53" />
  <meta name="author" content="Shishir Shakya">

  
  
  
  
    
  
  <meta name="description" content="Theorem 1.1. and detailed proofs Let ${{X}_{1}},{{X}_{2}},\ldots ,{{X}_{n}}$ $i.i.d$ observation having a three-times differentiable $PDF$ $f(x)$, and ${{f}^{s}}(x)$ denote the $s-th$ order derivative of $f(x)\ s=(1,2,3)$. Let $x$ be an interior point in the support of $X$, and let $\hat{f}(x)$ be $\frac{1}{2h}{{n}^{-1}}\left( numbers\ of\ {{X}_{i}}\ in\ between\ \left[ x-h,x&#43;h \right] \right)$. Assume that the kernel function $k\left( \centerdot \right)$ bounded and satisfies: $\int{k(v)dv=1}$, $k(v)=k(-v)$ and $\int{{{v}^{2}}k(v)dv={{\kappa }_{2}}&gt;0}$. And as $n\to\infty$, $h\to 0$ and $nh\to\infty$ then, the $MSE$ of estimator $\hat{f}(x)$ is given as: $$MSE\left( \hat{f}(x) \right)=\frac{{{h}^{4}}}{4}{{\left[ {{\kappa }_{2}}{{f}^{\left( 2 \right)}}(x) \right]}^{2}}&#43;\frac{\kappa f(x)}{nh}&#43;o\left( {{h}^{4}}&#43;{{(nh)}^{-1}} \right)=O\left( {{h}^{4}}&#43;{{(nh)}^{-1}} \right)$$ Where, $v=\left( \frac{{{X}_{i}}-x}{h} \right)$, ${{\kappa }_{2}}=\int{{{v}^{2}}k(v)dv}$ and $\kappa =\int{{{k}^{2}}(v)dv}$">

  
  <link rel="alternate" hreflang="en-us" href="../../tutorial/np05/">

  


  

  

  

  

  

  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous">
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono">
  

  <link rel="stylesheet" href="../../styles.css">
  

  
  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-131353943-1', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  
  

  
  <link rel="alternate" href="../../index.xml" type="application/rss+xml" title="Shishir Shakya">
  <link rel="feed" href="../../index.xml" type="application/rss+xml" title="Shishir Shakya">
  

  <link rel="manifest" href="../../site.webmanifest">
  <link rel="icon" type="image/png" href="../../img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="../../img/icon-192.png">

  <link rel="canonical" href="../../tutorial/np05/">

  
  
  
  
    
    
  
  <meta property="twitter:card" content="summary">
  
  <meta property="twitter:site" content="@econshishir">
  <meta property="twitter:creator" content="@econshishir">
  
  <meta property="og:site_name" content="Shishir Shakya">
  <meta property="og:url" content="/tutorial/np05/">
  <meta property="og:title" content="Nonparametric Econometrics | Shishir Shakya">
  <meta property="og:description" content="Theorem 1.1. and detailed proofs Let ${{X}_{1}},{{X}_{2}},\ldots ,{{X}_{n}}$ $i.i.d$ observation having a three-times differentiable $PDF$ $f(x)$, and ${{f}^{s}}(x)$ denote the $s-th$ order derivative of $f(x)\ s=(1,2,3)$. Let $x$ be an interior point in the support of $X$, and let $\hat{f}(x)$ be $\frac{1}{2h}{{n}^{-1}}\left( numbers\ of\ {{X}_{i}}\ in\ between\ \left[ x-h,x&#43;h \right] \right)$. Assume that the kernel function $k\left( \centerdot \right)$ bounded and satisfies: $\int{k(v)dv=1}$, $k(v)=k(-v)$ and $\int{{{v}^{2}}k(v)dv={{\kappa }_{2}}&gt;0}$. And as $n\to\infty$, $h\to 0$ and $nh\to\infty$ then, the $MSE$ of estimator $\hat{f}(x)$ is given as: $$MSE\left( \hat{f}(x) \right)=\frac{{{h}^{4}}}{4}{{\left[ {{\kappa }_{2}}{{f}^{\left( 2 \right)}}(x) \right]}^{2}}&#43;\frac{\kappa f(x)}{nh}&#43;o\left( {{h}^{4}}&#43;{{(nh)}^{-1}} \right)=O\left( {{h}^{4}}&#43;{{(nh)}^{-1}} \right)$$ Where, $v=\left( \frac{{{X}_{i}}-x}{h} \right)$, ${{\kappa }_{2}}=\int{{{v}^{2}}k(v)dv}$ and $\kappa =\int{{{k}^{2}}(v)dv}$"><meta property="og:image" content="/img/portrait.jpg">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2018-09-09T00:00:00-04:00">
  
  <meta property="article:modified_time" content="2018-09-09T00:00:00-04:00">
  

  

  

  <title>Nonparametric Econometrics | Shishir Shakya</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >
  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" role="textbox" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="../../">Shishir Shakya</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="../../#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="../../#publications_selected">
            
            <span>Research</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="../../#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="../../tutorial/">
            
            <span>Tutorials</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="../../#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="../../files/cv.pdf">
            
            <span>CV</span>
            
          </a>
        </li>

        
        

      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>



<div class="container-fluid docs">
  <div class="row flex-xl-nowrap">
    <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
      




<form class="docs-search d-flex align-items-center">
  <button class="btn docs-toggle d-md-none p-0 mr-3" type="button" data-toggle="collapse" data-target="#docs-nav" aria-controls="docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    <span><i class="fas fa-bars"></i></span>
  </button>

  
  <input name="q" type="search" class="form-control" id="search-query" placeholder="Search..." autocomplete="off">
  
</form>

<nav class="collapse docs-links" id="docs-nav">
  
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="../../tutorial/">Overview</a>

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="../../tutorial/ci01/">Causal Inference</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="../../tutorial/ci01/">C1: Fundamental problem of causal inference</a>
      </li>
      
    </ul>
    

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="../../tutorial/np01/">Nonparametric Econometrics</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="../../tutorial/np01/">NP1: Parametric density estimation (univariate case)</a>
      </li>
      
      <li >
        <a href="../../tutorial/np02/">NP2: NonParametric density estimation (univariate case)</a>
      </li>
      
      <li >
        <a href="../../tutorial/np03/">NP3: Three properties of kernel</a>
      </li>
      
      <li >
        <a href="../../tutorial/np04/">NP4: Taylor, MSE, Bias, Variance, Big O and Small o</a>
      </li>
      
      <li class="active">
        <a href="../../tutorial/np05/">NP5: Nonparametric density estimation (Proof of Theorem 1.1)</a>
      </li>
      
    </ul>
    

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="../../tutorial/shiny01/">Shiny Tutorial</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="../../tutorial/shiny01/">Two Shiny</a>
      </li>
      
    </ul>
    

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="../../tutorial/slt01/">Statistical Learning Theory</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="../../tutorial/slt01/">S1: Gaussian Tail Inequality</a>
      </li>
      
      <li >
        <a href="../../tutorial/slt02/">S2: Hoeffding Inequality</a>
      </li>
      
      <li >
        <a href="../../tutorial/slt03/">S3: Kullback Leibler Distance</a>
      </li>
      
      <li >
        <a href="../../tutorial/slt04/">S4: Maximum of a random variable</a>
      </li>
      
    </ul>
    

  </div>
  
  
</nav>

    </div>

    
    <div class="d-none d-xl-block col-xl-2 docs-toc">
      
      <p class="docs-toc-title">On this page</p>
      

      <nav id="TableOfContents">
<ul>
<li><a href="#theorem-1-1-and-detailed-proofs">Theorem 1.1. and detailed proofs</a>
<ul>
<li><a href="#mse-variance-and-biases">MSE, variance and biases</a></li>
<li><a href="#biases">Biases</a></li>
<li><a href="#variance">Variance</a></li>
</ul></li>
</ul>
</nav>

      <ul class="nav toc-top">
        <li><a href="#">Back to top</a></li>
      </ul>

      
    </div>
    

    <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">

      <article class="article" itemscope itemtype="http://schema.org/Article">

        <div class="docs-article-container">
          <h1 itemprop="name">Nonparametric Econometrics</h1>

          <div class="article-style" itemprop="articleBody">
            

<h1 id="theorem-1-1-and-detailed-proofs">Theorem 1.1. and detailed proofs</h1>

<p>Let ${{X}_{1}},{{X}_{2}},\ldots ,{{X}_{n}}$ $i.i.d$ observation having a three-times differentiable $PDF$ $f(x)$, and ${{f}^{s}}(x)$ denote the $s-th$ order derivative of $f(x)\ s=(1,2,3)$. Let $x$ be an interior point in the support of $X$, and let $\hat{f}(x)$ be $\frac{1}{2h}{{n}^{-1}}\left( numbers\ of\ {{X}_{i}}\ in\ between\ \left[ x-h,x+h \right] \right)$. Assume that the kernel function $k\left( \centerdot  \right)$ bounded and satisfies: $\int{k(v)dv=1}$, $k(v)=k(-v)$ and $\int{{{v}^{2}}k(v)dv={{\kappa }_{2}}&gt;0}$. And as $n\to\infty$, $h\to 0$ and $nh\to\infty$ then, the $MSE$ of estimator $\hat{f}(x)$ is given as:
    $$MSE\left( \hat{f}(x) \right)=\frac{{{h}^{4}}}{4}{{\left[ {{\kappa }_{2}}{{f}^{\left( 2 \right)}}(x) \right]}^{2}}+\frac{\kappa f(x)}{nh}+o\left( {{h}^{4}}+{{(nh)}^{-1}} \right)=O\left( {{h}^{4}}+{{(nh)}^{-1}} \right)$$
Where, $v=\left( \frac{{{X}_{i}}-x}{h} \right)$, ${{\kappa }_{2}}=\int{{{v}^{2}}k(v)dv}$ and $\kappa =\int{{{k}^{2}}(v)dv}$</p>

<h2 id="mse-variance-and-biases">MSE, variance and biases</h2>

<p>We can express the relationship of MSE, variance and bias of estimator $MSE\left( \hat{f}(x) \right)$ as:
    $$MSE\left( \hat{f}(x) \right)=\operatorname{var}\left( \hat{f}(x) \right)+{{\left[ bias\left( \hat{f}(x) \right) \right]}^{2}}$$</p>

<p>Then we deal with $\left[ bias\left( \hat{f}(x) \right) \right]$ and $\operatorname{var}\left( \hat{f}(x) \right)$ separately.</p>

<h2 id="biases">Biases</h2>

<p>The bias of $\hat{f}(x)$ is given as
    $$bias\left[ \hat{f}(x) \right]=E[\hat{f}(x)]-f(x)$$
    $$bias\left[ \hat{f}(x) \right]=E\left[ \frac{1}{nh}\sum\limits_{i=1}^{n}{k\left( \frac{{{X}_{i}}-x}{h} \right)} \right]-f(x)$$</p>

<p>By the identical distribution, we can write:
    $$bias\left[ \hat{f}(x) \right]=\frac{1}{nh}nE\left[ k\left( \frac{{{X}_{1}}-x}{h} \right) \right]-f(x)$$
    $$bias\left[ \hat{f}(x) \right]={{h}^{-1}}\int{f({{x}_{1}})}k\left( \frac{{{x}_{1}}-x}{h} \right)d{{x}_{1}}-f(x)$$
Note: $\frac{{{x}_{1}}-x}{h}=v$; ${{x}_{1}}-x=hv$; ${{x}_{1}}=x+hv$; $\frac{d{{x}_{1}}}{dv}=\frac{d}{dv}\left( x+hv \right)=h$ and $d{{x}_{1}}=hdv$.
    $$bias\left[ \hat{f}(x) \right]={{h}^{-1}}\int{f(x+hv)}k\left( v \right)hdv-f(x)$$
    $$bias\left[ \hat{f}(x) \right]={{h}^{-1}}h\int{f(x+hv)}k\left( v \right)dv-f(x)$$
    $$bias\left[ \hat{f}(x) \right]=\int{f(x+hv)}k\left( v \right)dv-f(x)$$</p>

<p>Let&rsquo;s expand $f(x+hv)$ with Taylor series expansion evaluated at $x$. Since $f(x)$ is only three times differentiable:  $$bias\left[ \hat{f}(x) \right]=\int{\left[ f(x)+{{f}^{(1)}}(x)(x+hv-x)+\frac{1}{2!}{{f}^{(2)}}(x){{(x+hv-x)}^{2}}+\frac{1}{3!}{{f}^{(3)}}(\tilde{x}){{(x+hv-x)}^{3}} \right]}k\left( v \right)dv-f(x)$$
    $$bias\left[ \hat{f}(x) \right]=\int{\left[ f(x)+{{f}^{(1)}}(x)hv+\frac{1}{2!}{{f}^{(2)}}(x){{h}^{2}}{{v}^{2}}+\frac{1}{3!}{{f}^{(3)}}(\tilde{x}){{h}^{3}}{{v}^{3}} \right]}k\left( v \right)dv-f(x)$$
    $$bias\left[ \hat{f}(x) \right]=\int{\left[ f(x)+{{f}^{(1)}}(x)hv+\frac{1}{2!}{{f}^{(2)}}(x){{h}^{2}}{{v}^{2}}+O({{h}^{3}}) \right]}k\left( v \right)dv-f(x)$$
    $$bias\left[ \hat{f}(x) \right]=f(x)\int{k\left( v \right)dv}+{{f}^{(1)}}(x)h\int{v}k\left( v \right)dv+\frac{{{h}^{2}}}{2!}{{f}^{(2)}}(x)\int{{{v}^{2}}}k\left( v \right)dv+\int{O({{h}^{3}})k\left( v \right)dv}-f(x)$$
    $$bias\left[ \hat{f}(x) \right]=f(x)\underbrace{\int{k\left( v \right)dv}}_{1}+{{f}^{(1)}}(x)h\int{v}k\left( v \right)dv+\frac{{{h}^{2}}}{2!}{{f}^{(2)}}(x)\underbrace{\int{{{v}^{2}}}k\left( v \right)dv}_{{{\kappa }_{2}}}+\underbrace{\int{O({{h}^{3}})k\left( v \right)dv}}_{O({{h}^{3}})}-f(x)$$
    $$bias\left[ \hat{f}(x) \right]=f(x)+{{f}^{(1)}}(x)h\int{v}k\left( v \right)dv+\frac{{{h}^{2}}}{2!}{{f}^{(2)}}(x){{\kappa }_{2}}+O({{h}^{3}})-f(x)$$
    $$bias\left[ \hat{f}(x) \right]={{f}^{(1)}}(x)h\int{v}k\left( v \right)dv+\frac{{{h}^{2}}}{2!}{{f}^{(2)}}(x){{\kappa }_{2}}+O({{h}^{3}})$$</p>

<p>By symmetrical definition
    $$bias\left[ \hat{f}(x) \right]={{f}^{(1)}}(x)h\left[ \left( \int\limits_{-\infty }^{0}{+\int\limits_{0}^{\infty }{{}}} \right)vk\left( v \right)dv \right]+\frac{{{h}^{2}}}{2!}{{f}^{(2)}}(x){{\kappa }_{2}}+O({{h}^{3}})$$
    $$bias\left[ \hat{f}(x) \right]={{f}^{(1)}}(x)h\left[ \left( \int\limits_{-\infty }^{0}{vk\left( v \right)dv+\int\limits_{0}^{\infty }{vk\left( v \right)dv}} \right) \right]+\frac{{{h}^{2}}}{2!}{{f}^{(2)}}(x){{\kappa }_{2}}+O({{h}^{3}})$$</p>

<p>Then, we can switch the bound of definite integrals. Click for <a href="https://www.khanacademy.org/math/ap-calculus-ab/ab-integration-new/ab-6-6/v/switching-integral-bounds" target="_blank">tutorial.</a>
    $$bias\left[ \hat{f}(x) \right]={{f}^{(1)}}(x)h\underbrace{\left[ \left( -\int\limits_{0}^{\infty }{vk\left( v \right)dv+\int\limits_{0}^{\infty }{vk\left( v \right)dv}} \right) \right]}_{0}+\frac{{{h}^{2}}}{2!}{{f}^{(2)}}(x){{\kappa }_{2}}+O({{h}^{3}})$$
    $$bias\left[ \hat{f}(x) \right]=\frac{{{h}^{2}}}{2!}{{f}^{(2)}}(x){{\kappa }_{2}}+O({{h}^{3}})$$
    $$bias\left[ \hat{f}(x) \right]=\frac{{{h}^{2}}}{2!}{{f}^{(2)}}(x){{\kappa }_{2}}+o({{h}^{2}})$$</p>

<h2 id="variance">Variance</h2>

<p>The variance of $\hat{f}(x)$ is given as:
    $$\operatorname{var}\left[ \hat{f}(x) \right]=E{{\left( \hat{f}(x)-E\left[ \hat{f}(x) \right] \right)}^{2}}=E\left[ {{\left( \hat{f}(x) \right)}^{2}} \right]-{{E}^{2}}\left[ {{\left( \hat{f}(x) \right)}^{2}} \right]$$
    $$\operatorname{var}\left[ \hat{f}(x) \right]=\operatorname{var}\left[ \frac{1}{nh}\sum\limits_{i=1}^{n}{k\left( \frac{{{X}_{i}}-x}{h} \right)} \right]$$</p>

<p>For $b\in \mathbb{R}$ be a constant and $y$ be a random variable, then, $\operatorname{var}[by]={{b}^{2}}\operatorname{var}[y]$, therefore,
    $$\operatorname{var}\left[ \hat{f}(x) \right]=\frac{1}{{{n}^{2}}{{h}^{2}}}\operatorname{var}\left[ \sum\limits_{i=1}^{n}{k\left( \frac{{{X}_{i}}-x}{h} \right)} \right]$$</p>

<p>For $\operatorname{var}(a+b)=\operatorname{var}(a)+\operatorname{var}(b)+2\operatorname{cov}(a,b)$ and if $a\bot b$ then $2\operatorname{cov}(a,b)=0$. In above expression ${{X}_{i}}$ are independent observation therefore ${{X}_{i}}\bot {{X}_{j}}\ \forall \ i\ne j$. Hence, we can express
    $$\operatorname{var}\left[ \hat{f}(x) \right]=\frac{1}{{{n}^{2}}{{h}^{2}}}\left( \sum\limits_{i=1}^{n}{\operatorname{var}\left[ k\left( \frac{{{X}_{i}}-x}{h} \right) \right]}+0 \right)$$</p>

<p>Note, ${{X}_{i}}$ are also identical, therefore $\operatorname{var}({{X}_{i}})=\operatorname{var}({{X}_{j}})$ so, $\sum\limits_{i=1}^{n}{\operatorname{var}({{X}_{i}})}=n\operatorname{var}({{X}_{1}})$. Therefore,
    $$\operatorname{var}\left[ \hat{f}(x) \right]=\frac{1}{{{n}^{2}}{{h}^{2}}}n\operatorname{var}\left[ k\left( \frac{{{X}_{1}}-x}{h} \right) \right]$$
    $$\operatorname{var}\left[ \hat{f}(x) \right]=\frac{1}{n{{h}^{2}}}\operatorname{var}\left[ k\left( \frac{{{X}_{1}}-x}{h} \right) \right]$$
    $$\operatorname{var}\left[ \hat{f}(x) \right]=\frac{1}{n{{h}^{2}}}\left( E\left[ {{k}^{2}}\left( \frac{{{X}_{1}}-x}{h} \right) \right]-\left[ E{{\left( k\left( \frac{{{X}_{1}}-x}{h} \right) \right)}^{2}} \right] \right)$$</p>

<p>Which is equivalent to:
    $$\operatorname{var}\left[ \hat{f}(x) \right]=\frac{1}{n{{h}^{2}}}\left[ \int{f({{x}_{1}}){{k}^{2}}\left( \frac{{{x}_{1}}-x}{h} \right)d{{x}_{1}}}-{{\left[ \int{f({{x}_{1}})k\left( \frac{{{x}_{1}}-x}{h} \right)d{{x}_{1}}} \right]}^{2}} \right]$$</p>

<p>Note: $\frac{{{x}_{1}}-x}{h}=v$; ${{x}_{1}}-x=hv$; ${{x}_{1}}=x+hv$; $\frac{d{{x}_{1}}}{dv}=\frac{d}{dv}\left( x+hv \right)=h$ and $d{{x}_{1}}=hdv$.
    $$\operatorname{var}\left[ \hat{f}(x) \right]=\frac{1}{n{{h}^{2}}}\left[ \int{f(x+hv){{k}^{2}}\left( v \right)hdv}-{{\left[ \int{f(x+hv)k\left( v \right)hdv} \right]}^{2}} \right]$$
    $$\operatorname{var}\left[ \hat{f}(x) \right]=\frac{1}{n{{h}^{2}}}\left[ h\int{f(x+hv){{k}^{2}}\left( v \right)dv}-{{\left[ h\int{f(x+hv)k\left( v \right)dv} \right]}^{2}} \right]$$
    $$\operatorname{var}\left[ \hat{f}(x) \right]=\frac{1}{n{{h}^{2}}}\left[ \int{f(x+hv){{k}^{2}}\left( v \right)hdv}-\underbrace{{{\left[ \int{f(x+hv)k\left( v \right)hdv} \right]}^{2}}}_{O\left( {{h}^{2}} \right)} \right]$$
    $$\operatorname{var}\left[ \hat{f}(x) \right]=\frac{1}{n{{h}^{2}}}\left[ \int{f(x+hv){{k}^{2}}\left( v \right)hdv}-O\left( {{h}^{2}} \right) \right]$$</p>

<p>Taylor series expansion
    $$\operatorname{var}\left[ \hat{f}(x) \right]=\frac{1}{n{{h}^{2}}}\left[ h\int{f(x)+{{f}^{(1)}}(\xi )(x+hv-x){{k}^{2}}\left( v \right)dv}-O\left( {{h}^{2}} \right) \right]$$
    $$\operatorname{var}\left[ \hat{f}(x) \right]=\frac{1}{n{{h}^{2}}}\left[ h\int{f(x){{k}^{2}}\left( v \right)dv}+\int{{{f}^{(1)}}(\xi )(hv){{k}^{2}}\left( v \right)dv}-O\left( {{h}^{2}} \right) \right]$$
    $$\operatorname{var}\left[ \hat{f}(x) \right]=\frac{1}{n{{h}^{2}}}\left[ hf(x)\underbrace{\int{{{k}^{2}}\left( v \right)dv}}_{\kappa }+\underbrace{\int{{{f}^{(1)}}(\xi )(hv){{k}^{2}}\left( v \right)dv}}_{O\left( {{h}^{2}} \right)}-O\left( {{h}^{2}} \right) \right]$$
    $$\operatorname{var}\left[ \hat{f}(x) \right]=\frac{1}{n{{h}^{2}}}\left[ h\kappa f(x)+O\left( {{h}^{2}} \right) \right]$$
    $$\operatorname{var}\left[ \hat{f}(x) \right]=\frac{1}{nh}\left[ \kappa f(x)+O\left( h \right) \right]=O\left( {{(nh)}^{-1}} \right)$$</p>

<p>We now know that the order of variance is $O\left( {{(nh)}^{-1}} \right)$, the order of bias is $O\left( {{h}^{2}} \right)$ and the order of biases square is $O\left( {{h}^{4}} \right)$. As we know the MSE is sum of variance and square of biases and plugging the values of variance and bias, we get,
    $$MSE\left( \hat{f}(x) \right)=\operatorname{var}\left( \hat{f}(x) \right)+{{\left[ bias\left( \hat{f}(x) \right) \right]}^{2}}$$
    $$MSE\left( \hat{f}(x) \right)=\frac{{{h}^{4}}}{4}{{\left[ {{\kappa }_{2}}{{f}^{\left( 2 \right)}}(x) \right]}^{2}}+\frac{\kappa f(x)}{nh}+o\left( {{h}^{4}}+{{(nh)}^{-1}} \right)=O\left( {{h}^{4}}+{{(nh)}^{-1}} \right)$$
Where, $v=\left( \frac{{{X}_{i}}-x}{h} \right)$, ${{\kappa }_{2}}=\int{{{v}^{2}}k(v)dv}$ and $\kappa =\int{{{k}^{2}}(v)dv}$</p>

          </div>

          

        </div>

        <div class="body-footer">
          Last updated on Sep 9, 2018
        </div>

      </article>

      <footer class="site-footer">
  
  <p class="powered-by">
    <a href="../../privacy/">Privacy Policy</a>
  </p>
  

  <p class="powered-by">
    &copy; 2018 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
  </p>
</footer>


    </main>
  </div>
</div>

    

    
    
    
    <script src="../../js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    

    
    
    
    <script id="dsq-count-scr" src="//SS.disqus.com/count.js" async></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.1/anchor.min.js" integrity="sha256-pB/deHc9CGfFpJRjC43imB29Rse8tak+5eXqntO94ck=" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
    
    <script src="../../js/academic.min.d037ee5294b166a79dec317c58aea9cc.js"></script>

    

  </body>
</html>


