[{"path":"index.html","id":"this-is-a-work-in-progress","chapter":"Lecture 1 This is a work in progress!","heading":"Lecture 1 This is a work in progress!","text":"","code":""},{"path":"index.html","id":"set-up","chapter":"Lecture 1 This is a work in progress!","heading":"1.1 Set up","text":"Welcome “Mostly Handsdirty Metrics” course! course, learn use R programming language analyze large complex data sets, focus applications economics. gain solid understanding key concepts techniques data manipulation, visualization, statistical analysis, opportunity apply skills real-world data sets. end course, well-equipped conduct independent research analysis using big data economics. look forward working helping succeed exciting field!Grading course based combination individual assignments, group projects, exams. Individual assignments typically consist problem sets exercises designed help apply concepts techniques covered class. Group projects provide opportunity work collaboratively substantial research analysis task, using real data applying methods techniques learned. Exams used assess overall understanding course material ability apply new situations.addition completing assignments exams, attendance laptop also mandatory course. Attendance important course material presented dynamic interactive manner, opportunity ask questions engage material real time. laptop also essential, need access course materials, complete assignments, participate class activities. expected bring laptop every class, fully charged ready use.","code":""},{"path":"index.html","id":"why-r","chapter":"Lecture 1 This is a work in progress!","heading":"1.2 Why R?","text":"using R course powerful versatile programming language well-suited working large datasets. R rich ecosystem libraries packages make easy perform complex data analysis tasks, data cleaning, visualization, statistical modeling. Additionally, R free open-source software, can easily install use computer without incurring costs. Overall, R excellent choice working big data economics provide skills tools need succeed course.","code":""},{"path":"index.html","id":"why-rstudio","chapter":"Lecture 1 This is a work in progress!","heading":"1.3 Why RStudio?","text":"RStudio integrated development environment (IDE) R. provides user-friendly interface working R includes number features make easier write run R code. course, using RStudio write execute R code, well create reports documents use R output. RStudio provides convenient way organize manage R projects, features can help work efficiently effectively R. Additionally, RStudio free open-source, cost-effective choice students researchers. using RStudio, able take full advantage capabilities R apply economic analysis big data.","code":""},{"path":"index.html","id":"installing-r","chapter":"Lecture 1 This is a work in progress!","heading":"1.4 Installing R","text":"install R computer, first need determine operating system. R available Windows, MacOS, Linux. know operating system, follow instructions:Windows: go R website (https://cran.r-project.org/) click “Download R Windows” link. download latest version R Windows. download complete, double-click downloaded file begin installation process. Follow -screen instructions complete installation. See video tutorial [https://youtu./NZxSA80lF1I].Windows: go R website (https://cran.r-project.org/) click “Download R Windows” link. download latest version R Windows. download complete, double-click downloaded file begin installation process. Follow -screen instructions complete installation. See video tutorial [https://youtu./NZxSA80lF1I].MacOS: go R website (https://cran.r-project.org/) click “Download R (Mac) OS X” link. download latest version R MacOS. download complete, double-click downloaded file begin installation process. Follow -screen instructions complete installation. See video tutorial [https://youtu./cCgiR1uwXzU]MacOS: go R website (https://cran.r-project.org/) click “Download R (Mac) OS X” link. download latest version R MacOS. download complete, double-click downloaded file begin installation process. Follow -screen instructions complete installation. See video tutorial [https://youtu./cCgiR1uwXzU]Linux: R typically included package repositories Linux distributions. install R, open terminal window type following command: sudo apt-get install r-base. install latest version R Linux system.Linux: R typically included package repositories Linux distributions. install R, open terminal window type following command: sudo apt-get install r-base. install latest version R Linux system.R installed, can launch typing R command prompt (Windows Linux) opening R application (MacOS). bring R console, can type R commands run .Note: encounter difficulties installation process, consult R website (https://cran.r-project.org/) detailed instructions troubleshooting tips. Additionally, can search online help ask assistance forums online communities.","code":""},{"path":"index.html","id":"installing-rstudio","chapter":"Lecture 1 This is a work in progress!","heading":"1.5 Installing RStudio","text":"install RStudio computer, first need R installed. yet installed R, follow instructions previous response install operating system. R installed, can install RStudio following instructions:Windows: go RStudio website (https://www.rstudio.com/) click “Download” button. take download page, can click “Download RStudio Desktop” button download latest version RStudio Windows. download complete, double-click downloaded file begin installation process. Follow -screen instructions complete installation.Windows: go RStudio website (https://www.rstudio.com/) click “Download” button. take download page, can click “Download RStudio Desktop” button download latest version RStudio Windows. download complete, double-click downloaded file begin installation process. Follow -screen instructions complete installation.MacOS: go RStudio website (https://www.rstudio.com/) click “Download” button. take download page, can click “Download RStudio Desktop” button download latest version RStudio MacOS. download complete, double-click downloaded file begin installation process. Follow -screen instructions complete installation.MacOS: go RStudio website (https://www.rstudio.com/) click “Download” button. take download page, can click “Download RStudio Desktop” button download latest version RStudio MacOS. download complete, double-click downloaded file begin installation process. Follow -screen instructions complete installation.Linux: RStudio available binary package Linux distributions. install RStudio, open terminal window type appropriate command Linux distribution. example, Ubuntu Debian-based systems, can use following command install RStudio: sudo apt-get install rstudio.Linux: RStudio available binary package Linux distributions. install RStudio, open terminal window type appropriate command Linux distribution. example, Ubuntu Debian-based systems, can use following command install RStudio: sudo apt-get install rstudio.RStudio installed, can launch double-clicking RStudio icon typing rstudio command prompt (Windows Linux). open RStudio application, can create new R projects start working R.Note: encounter difficulties installation process, consult RStudio website (https://www.rstudio.com/) detailed instructions troubleshooting tips. Additionally, can search online help ask assistance forums online communities.","code":""},{"path":"data-types-structures-and-extractions.html","id":"data-types-structures-and-extractions","chapter":"Lecture 2 Data types, structures, and extractions","heading":"Lecture 2 Data types, structures, and extractions","text":"","code":""},{"path":"data-types-structures-and-extractions.html","id":"basic-mathematical-operations","chapter":"Lecture 2 Data types, structures, and extractions","heading":"2.1 Basic Mathematical operations","text":"R provides built-functions performing basic mathematical operations, addition, subtraction, multiplication, division. examples R code demonstrate use functions:Addition: add two numbers R, use + operator. example, add 2 3, write 2 + 3.Subtraction: subtract one number another R, use - operator. example, subtract 3 5, write 5 - 3.Multiplication: multiply two numbers R, use * operator. example, multiply 2 3, write 2 * 3.Division: divide one number another R, use / operator. example, divide 10 2, write 10 / 2.\nexample might use operations simple R script:code, define two variables b perform four basic mathematical operations . print results operation R console verify correct. Note R uses standard order operations, multiplication division performed addition subtraction.","code":"\n# define two variables\na <- 2\nb <- 3\n\n# add the variables\nc <- a + b\nprint(c) # prints 5\n#> [1] 5\n\n# subtract the variables\nd <- a - b\nprint(d) # prints -1\n#> [1] -1\n\n# multiply the variables\ne <- a * b\nprint(e) # prints 6\n#> [1] 6\n\n# divide the variables\nf <- a / b\nprint(f) # prints 0.6666667\n#> [1] 0.6666667"},{"path":"data-types-structures-and-extractions.html","id":"good-versus-bad-names","chapter":"Lecture 2 Data types, structures, and extractions","heading":"2.2 Good versus bad names","text":"copied section Hands-Programming R Garrett Grolemund chapter 2 “Basics” (https://rstudio-education.github.io/hopr/basics.html).naming convention R. can name object R almost anything want, rules. First, name start number. Second, name use special symbols, like ^, !, $, @, +, -, /, *.R variable defined “” equal “”. words, R case-sensitive, name Name refer different objects:Finally, R overwrite previous information stored object without asking permission. , good idea use names already taken:","code":"\nName <- 1\nname <- 0\n\nName + 1\n#> [1] 2\nname + 1\n#> [1] 1\nmy_number <- 1\nmy_number \n#> [1] 1\n\nmy_number <- 999\nmy_number\n#> [1] 999"},{"path":"data-types-structures-and-extractions.html","id":"some-additional-mathematical-operations","chapter":"Lecture 2 Data types, structures, and extractions","heading":"2.3 Some additional mathematical operations","text":"Now, let’s get back additional mathematical operations. R also provides functions performing advanced operations, exponentiation square roots. operations performed using ^ sqrt() functions. examples use functions R:Exponentiation: raise number power R, use ^ operator. example, raise 2 power 3, write 2^3. compute 2 * 2 * 2, equal 8.Exponentiation: raise number power R, use ^ operator. example, raise 2 power 3, write 2^3. compute 2 * 2 * 2, equal 8.Square root: compute square root number R, use sqrt() function. example, compute square root 4, write sqrt(4). compute square root 4, equal 2.\nexample might use operations simple R script:Square root: compute square root number R, use sqrt() function. example, compute square root 4, write sqrt(4). compute square root 4, equal 2.\nexample might use operations simple R script:code, define variable x use ^ sqrt() functions perform exponentiation square root operations. print results operation R console verify correct. Note using ^ operator, number raised power must placed left side operator, power must placed right side. Similarly, using sqrt() function, number whose square root computed must placed inside parentheses.economics, logarithm number often used represent growth rate variable time. can useful analyzing economic phenomena inflation, GDP growth, population growth. R, logarithm number can computed using log() function. example use function R:code, define variable x use log() function compute natural logarithm x. print result R console verify correct. natural logarithm logarithm base e, e mathematical constant approximately equal 2.71828.R also provides log10() function, computes logarithm base 10. example, compute logarithm base 10 100, write log10(100), return 2 (since 100 = 10^2). log() log10() functions commonly used economics analyze growth rates economic phenomena.","code":"\n# define a variable\nx <- 2\n\n# compute x to the power of 3\ny <- x^3\nprint(y) # prints 8\n#> [1] 8\n\n# compute the square root of x\nz <- sqrt(x)\nprint(z) # prints 2\n#> [1] 1.414214\n# define a variable\nx <- 100\n\n# compute the natural log of x\ny <- log(x)\nprint(y) # prints 4.60517\n#> [1] 4.60517"},{"path":"data-types-structures-and-extractions.html","id":"data-types","chapter":"Lecture 2 Data types, structures, and extractions","heading":"2.4 Data types","text":"R, three main data types: integer, numeric, character.Integer: integer whole number, 1, 2, 3. R, integers represented using int data type. example create integer variable R:Numeric: numeric value decimal number, 1.5, 2.7, 3.14. R, numeric values represented using numeric data type. example create numeric variable R:Character: character value string text, “hello” “world”. R, character values represented using character data type kept quote marks. example create character variable R:important understand different data types R, determine data treated operations can perform . example, perform mathematical operations character values, can concatenate using paste() function. Additionally, must careful convert data types necessary, R automatically . instance, try divide integer numeric value, get error unless explicitly convert integer numeric value first.","code":"\n# define an integer variable\nx <- 1\n\n# print the data type of x\nclass(x) # prints \"integer\"\n#> [1] \"numeric\"\n# define a numeric variable\nx <- 1.5\n\n# print the data type of x\nclass(x) # prints \"numeric\"\n#> [1] \"numeric\"\n# define a character variable\nx <- \"hello\"\n\n# print the data type of x\nclass(x) # prints \"character\"\n#> [1] \"character\""},{"path":"data-types-structures-and-extractions.html","id":"data-structure","chapter":"Lecture 2 Data types, structures, and extractions","heading":"2.5 Data structure","text":"R programming language includes various data structures commonly used statistical analysis data science, including vectors, matrices, data frames, lists.Vectors one-dimensional data arrays can hold numeric, character, logical values.Matrices two-dimensional data arrays can hold numeric, character, logical values.Data frames two-dimensional arrays can hold different data types column, similar spreadsheet.Lists collections objects can hold various data types, including lists.data structures designed make easy organize manipulate data statistical analysis visualization.","code":""},{"path":"data-types-structures-and-extractions.html","id":"atomic-vector-and-extraction","chapter":"Lecture 2 Data types, structures, and extractions","heading":"2.5.1 Atomic vector and extraction","text":"R, atomic vector data structure holds single data type. values atomic vector must type, integer, numeric, character. example create atomic vector R:code, create three atomic vectors: x, holds integer values; y, holds numeric values; z, holds character values. use class() function print data type vector, shows correct type. Note use c() function create atomic vector, must pass values want include vector arguments function.Atomic vectors fundamental data structure R used many different contexts. example, can used represent columns data frame elements list. also used hold results many R functions, statistical tests regression models. Understanding atomic vectors work essential working data R.extract value “hello” atomic vector z, can use [] operator index vector retrieve desired element. example R:code, create atomic vector z holds values “hello” “world”. use [] operator extract first element z, “hello”. assign value variable x, print x verify correct value.Note R, indexing starts 1, first element vector index 1, second element index 2, . [] extract first element z, must use index 1, 0, might expect programming languages. Additionally, [] operator can used extract multiple elements vector passing vector indices index. example, extract first third elements z, write x <- z[c(1, 3)], assign values “hello” “world” x order.specify exact value “hello” [] operator, can use () function find index “hello” vector z. example R:code, create atomic vector z holds values “hello” “world.” use () function find index “hello” z. function returns vector indices, case, return single value 1. assign value variable , use index extract element index z. Finally, print x verify correct value.example extract elements numeric atomic vector R:code, define numeric atomic vector x contains values 1, 3, 5, 7, 9. use different indexing operators extract different elements vector x.example, use [1] indexing operator extract first element vector x, value 1. use [length(x)] indexing operator extract last element vector x, value 9. use [2:3] indexing operator extract second third elements vector x, values 3 5. Finally, use seq() function [seq(2, length(x), 2)] indexing operator extract even-numbered elements vector x, values 3 9.code demonstrates use different indexing operators extract elements numeric atomic vector R. using operators, can select manipulate specific elements vector, can use extracted elements calculations operations.","code":"\n# create an atomic vector of integers\nx <- c(1, 2, 3)\n\n# print the data type of x\nclass(x) # prints \"integer\"\n#> [1] \"numeric\"\n\n# create an atomic vector of numeric values\ny <- c(1.5, 2.7, 3.14)\n\n# print the data type of y\nclass(y) # prints \"numeric\"\n#> [1] \"numeric\"\n\n# create an atomic vector of character values\nz <- c(\"hello\", \"world\")\n\n# print the data type of z\nclass(z) # prints \"character\"\n#> [1] \"character\"\n# create an atomic vector of character values\nz <- c(\"hello\", \"world\", \"anime\")\n\n# extract the first element of z\nx <- z[1]\n\n# print x\nprint(x) # prints \"hello\"\n#> [1] \"hello\"\n# create an atomic vector of character values\nz <- c(\"hello\", \"world\")\n\n# find the index of \"hello\" in z\ni <- which(z == \"hello\")\n\n# extract the element at index i from z\nx <- z[i]\n\n# print x\nprint(x) # prints \"hello\"\n#> [1] \"hello\"\n# define a numeric atomic vector\nx <- c(1, 3, 5, 7, 9)\n\n# extract the first element from the vector\nprint(x[1])  # prints 1\n#> [1] 1\n\n# extract the last element from the vector\nprint(x[length(x)])  # prints 9\n#> [1] 9\n\n# extract the second and third elements from the vector\nprint(x[2:3])  # prints 3 5\n#> [1] 3 5\n\n# extract the even-numbered elements from the vector\nprint(x[seq(2, length(x), 2)])  # prints 3 9\n#> [1] 3 7"},{"path":"data-types-structures-and-extractions.html","id":"matrix-and-extraction","chapter":"Lecture 2 Data types, structures, and extractions","heading":"2.5.2 Matrix and extraction","text":"matrix data structure R allows store manipulate data two-dimensional grid. element matrix identified row column indices can accessed using [,] operator.example create matrix R:code create matrix 2 rows 3 columns, containing values 1, 2, 3, 4, 5. matrix printed console, look like :example, matrix 2 rows 3 columns, values matrix arranged grid according row column indices. example, value 3 located first row second column matrix, can accessed using [1,2] index.access element matrix, can use [,] operator. example :Let’s create large matrix.Now lets extract selected row 2 7, 89, 99 column 1 3 7.Matrix can one type data type, either character numeric. reasons, class, use matrix lot.","code":"\n# Define a matrix containing the values 1, 2, 3, 4, 5\nmatrix <- matrix(c(1, 2, 3, 4, 5, 6), nrow = 2, ncol = 3)\n# Print the matrix\nmatrix\n#>      [,1] [,2] [,3]\n#> [1,]    1    3    5\n#> [2,]    2    4    6\n# Print the element at the first row and second column of the matrix\nmatrix[1,2]\n#> [1] 3\n\n# Don't print the first element but print second column of the matrix\nmatrix[-1,2]\n#> [1] 4\n\n# Don't print the first element and second column of the matrix, but print all\nmatrix[-1,-2]\n#> [1] 2 6\n\n# Print first two rows and all columns\nmatrix[c(1,2), ]\n#>      [,1] [,2] [,3]\n#> [1,]    1    3    5\n#> [2,]    2    4    6\n\n# Don't print first two rows but print all the columns\nmatrix[-c(1,2), ]\n#>      [,1] [,2] [,3]\n# Define a matrix containing the values 1, 2, 3, 4, 5\nlarge_matrix <- matrix(c(1:1000), nrow = 100, ncol = 10)\nlarge_matrix[c(2:17,89,99), c(1:3, 7)]\n#>       [,1] [,2] [,3] [,4]\n#>  [1,]    2  102  202  602\n#>  [2,]    3  103  203  603\n#>  [3,]    4  104  204  604\n#>  [4,]    5  105  205  605\n#>  [5,]    6  106  206  606\n#>  [6,]    7  107  207  607\n#>  [7,]    8  108  208  608\n#>  [8,]    9  109  209  609\n#>  [9,]   10  110  210  610\n#> [10,]   11  111  211  611\n#> [11,]   12  112  212  612\n#> [12,]   13  113  213  613\n#> [13,]   14  114  214  614\n#> [14,]   15  115  215  615\n#> [15,]   16  116  216  616\n#> [16,]   17  117  217  617\n#> [17,]   89  189  289  689\n#> [18,]   99  199  299  699\n# Define a matrix containing the values 1, 2, 3, 4, 5, A\nmatrix <- matrix(c(1, 2, 3, 4, 5, \"A\"), nrow = 2, ncol = 3)\nmatrix\n#>      [,1] [,2] [,3]\n#> [1,] \"1\"  \"3\"  \"5\" \n#> [2,] \"2\"  \"4\"  \"A\""},{"path":"data-types-structures-and-extractions.html","id":"dataframe-and-extraction","chapter":"Lecture 2 Data types, structures, and extractions","heading":"2.5.3 Dataframe and extraction","text":"data frame data structure R allows store manipulate tabular data. data frame similar matrix, can different data types columns, can row column names.example create data frame R:code create data frame 5 rows 2 columns, containing values 1, 2, 3, 4, 5. columns data frame named “x” “y”, data frame printed console. look like :example, data frame 5 rows 2 columns, values data frame arranged table according row column names. Similar matrix, can use [,] operator.can see can almost extract elements like matrix. However even better approach. example, value 3 located third row “x” column data frame, can accessed using data_frame$x[3] index.access element data frame, can use $ operator access column, [,] operator access row. example :code access value third row “y” column data_frame, print console. example, value third row “y” column data_frame “C”, code print value “C” toHowever applied setting use either dplyr package manipulate data frame. now use data frame weeks.","code":"\n# Define a data frame containing the values 1, 2, 3, 4, 5\ndata_frame <- data.frame(x = c(1, 2, 3, 4, 5),\n                         y = c(\"A\", \"B\", \"C\", \"D\", \"E\"))\n# Print the data frame\ndata_frame\n#>   x y\n#> 1 1 A\n#> 2 2 B\n#> 3 3 C\n#> 4 4 D\n#> 5 5 E\n# Print the element at the first row and second column of the data_frame\ndata_frame[1,2]\n#> [1] \"A\"\n\n# Don't print the first element but print second column of the data_frame\ndata_frame[-1,2]\n#> [1] \"B\" \"C\" \"D\" \"E\"\n\n# Don't print the first element and second column of the data_frame, but print all\ndata_frame[-1,-2]\n#> [1] 2 3 4 5\n\n# Print first two rows and all columns\ndata_frame[c(1,2), ]\n#>   x y\n#> 1 1 A\n#> 2 2 B\n\n# Don't print first two rows but print all the columns\ndata_frame[-c(1,2), ]\n#>   x y\n#> 3 3 C\n#> 4 4 D\n#> 5 5 E\n# Print the value at the third row and \"y\" column of the data frame\ndata_frame$y[3]\n#> [1] \"C\"\n# Print the value at the first and second row of \"y\" column of the data frame\ndata_frame$y[c(1:2)]\n#> [1] \"A\" \"B\"\n\n# Print the value at the third row and \"y\" column of the data frame\ndata_frame$y[c(1:2)]\n#> [1] \"A\" \"B\""},{"path":"data-types-structures-and-extractions.html","id":"list-and-extraction","chapter":"Lecture 2 Data types, structures, and extractions","heading":"2.5.4 List and extraction","text":"list() function R used create list, data structure allows store manipulate “collection objects.” list can contain objects different types, including lists, can modified dynamically.two matrices, two data frames, two vectors. can use list() function specify matrices, data frames, vectors arguments. example :Finally, lets print my_list variable console, output look like :can see, my_list variable contains list four elements, one matrices data frames defined code. can access modify elements list using [[]] operator.use [[]] operator access modify element list, can specify position element list first argument, name element second argument. example :Now can also extract elements within lists.can also give names list following.name even easier extract $.","code":"\n# Define two matrices, each containing the values 1, 2, 3, 4, 5\nmatrix1 <- matrix(c(1, 2, 3, 4, 5, 6), nrow = 2, ncol = 3)\nmatrix2 <- matrix(c(5, 4, 3, 2, 1, 8), nrow = 2, ncol = 3)\n\n# Define two data frames, each containing the values 1, 2, 3, 4, 5\ndata_frame1 <- data.frame(x = c(1, 2, 3, 4, 5), y = c(-1,-4, -9,-8,-7))\ndata_frame2 <- data.frame(win = c(5, 4, 3, 2, 1), loss = c(-2,-90,-3,-2,-0.5))\n\n# Define two vector\nnumeric_vector <- c(1:100)\ncharacter_vector <- c(\"alpha\", \"beta\", \"gamma\", \"delta\", \"theta\")\n\n# Create a list that contains the two matrices and the two data frames\nmy_list <- list(matrix1, matrix2, data_frame1, data_frame2, numeric_vector, character_vector)\n# Print the list\nmy_list\n#> [[1]]\n#>      [,1] [,2] [,3]\n#> [1,]    1    3    5\n#> [2,]    2    4    6\n#> \n#> [[2]]\n#>      [,1] [,2] [,3]\n#> [1,]    5    3    1\n#> [2,]    4    2    8\n#> \n#> [[3]]\n#>   x  y\n#> 1 1 -1\n#> 2 2 -4\n#> 3 3 -9\n#> 4 4 -8\n#> 5 5 -7\n#> \n#> [[4]]\n#>   win  loss\n#> 1   5  -2.0\n#> 2   4 -90.0\n#> 3   3  -3.0\n#> 4   2  -2.0\n#> 5   1  -0.5\n#> \n#> [[5]]\n#>   [1]   1   2   3   4   5   6   7   8   9  10  11  12  13\n#>  [14]  14  15  16  17  18  19  20  21  22  23  24  25  26\n#>  [27]  27  28  29  30  31  32  33  34  35  36  37  38  39\n#>  [40]  40  41  42  43  44  45  46  47  48  49  50  51  52\n#>  [53]  53  54  55  56  57  58  59  60  61  62  63  64  65\n#>  [66]  66  67  68  69  70  71  72  73  74  75  76  77  78\n#>  [79]  79  80  81  82  83  84  85  86  87  88  89  90  91\n#>  [92]  92  93  94  95  96  97  98  99 100\n#> \n#> [[6]]\n#> [1] \"alpha\" \"beta\"  \"gamma\" \"delta\" \"theta\"\n# Access the second matrix in the list\nmy_list[[2]]\n#>      [,1] [,2] [,3]\n#> [1,]    5    3    1\n#> [2,]    4    2    8\n\n# Access the first matrix in the list\nmy_list[[3]]\n#>   x  y\n#> 1 1 -1\n#> 2 2 -4\n#> 3 3 -9\n#> 4 4 -8\n#> 5 5 -7\n# Access the second matrix in the list and extract the second row and third element\nmy_list[[2]][2,3]\n#> [1] 8\n\n# Access the second matrix in the list and get the wins\nmy_list[[4]]$win\n#> [1] 5 4 3 2 1\n\n# Access the second matrix in the list and get the wins, with 1, 4 element\nmy_list[[4]]$win[c(1,4)]\n#> [1] 5 2\n# Lets define my_list2 which is same as my_list\nmy_list2 <- my_list\n\n# Also give some names in my_list2. Note that we have 6 objects within list, so there must be 6 names.\nnames(my_list2) <- c(\"matrix1\", \"matrix2\", \"dataframe1\", \"dataframe2\", \"vector1\", \"vector2\")\n# Access the second matrix in the list\nmy_list2$matrix2\n#>      [,1] [,2] [,3]\n#> [1,]    5    3    1\n#> [2,]    4    2    8\n\n# Access the first matrix in the list\nmy_list2$dataframe1\n#>   x  y\n#> 1 1 -1\n#> 2 2 -4\n#> 3 3 -9\n#> 4 4 -8\n#> 5 5 -7\n\n# Access the second matrix in the list and extract the second row and third element\nmy_list2$matrix2[2,3]\n#> [1] 8\n\n# Access the second matrix in the list and get the wins\nmy_list2$dataframe2$win\n#> [1] 5 4 3 2 1\n\n# Access the second matrix in the list and get the wins, with 1, 4 element\nmy_list2$dataframe2$win[c(1,4)]\n#> [1] 5 2"},{"path":"data-types-structures-and-extractions.html","id":"summary","chapter":"Lecture 2 Data types, structures, and extractions","heading":"2.6 Summary","text":"R, vectors, matrices, data frames, lists commonly used data structures allow store manipulate collections objects.vector one-dimensional array can contain objects type, numbers character strings. Vectors often used represent single variable set observations typically used mathematical operations statistical functions.matrix two-dimensional array can contain objects type, numbers character strings. Matrices often used represent data tabular format typically used linear algebra statistical modeling.data frame two-dimensional array can contain objects different types, numbers, character strings, logical values. Data frames often used represent data tabular format typically used data analysis statistical modeling.list data structure allows store manipulate collection objects, including lists. Lists often used represent complex data structures typically used data manipulation programming.summary, vectors, matrices, data frames, lists essential data structures R frequently used data analysis statistical modeling.","code":""},{"path":"data-types-structures-and-extractions.html","id":"some-additional-resources","chapter":"Lecture 2 Data types, structures, and extractions","heading":"2.7 Some additional resources","text":"Check YouTube playlist R tutorial - Learn R Programming data camp (https://www.youtube.com/playlist?list=PLjgj6kdf_snYBkIsWQYcYtUZiDpam7ygg), still prefer read check free book Hands-Programming R Garrett Grolemund chapter 2 “Basics” (https://rstudio-education.github.io/hopr/basics.html).","code":""},{"path":"sampling.html","id":"sampling","chapter":"Lecture 3 Sampling","heading":"Lecture 3 Sampling","text":"Sampling process selecting subset elements larger population elements, order study analyze properties subset. Sampling common technique used statistics, research, fields, often impractical infeasible study entire population elements. Instead, selecting representative sample population, researchers can study sample make inferences properties population whole.Different types sampling methods can used select sample population, depending goals constraints study. example, random sampling method element population equal probability selected sample. Stratified sampling method population divided different groups strata, representative sample selected group. Cluster sampling method population divided different clusters groups, sample selected cluster.Sampling can effective way study population elements make inferences properties population. selecting representative sample population, researchers can study sample make statistical estimates inferences population whole. However, important carefully design implement sampling process order ensure sample representative population inferences made sample valid accurate.","code":""},{"path":"sampling.html","id":"random-sampling","chapter":"Lecture 3 Sampling","heading":"3.1 Random sampling","text":"course, mainly focus random sampling. Random sampling method sampling element population equal probability selected sample. Random sampling widely used method statistics, research, fields, often important select representative sample population unbiased objective manner.many different examples random sampling can used statistics, research, fields. common examples random sampling include:Surveys polls: Random sampling often used surveys polls, important select representative sample population order make inferences attitudes, opinions, behaviors population whole. using random sampling, researchers can ensure sample selected unbiased objective manner sample representative population.Surveys polls: Random sampling often used surveys polls, important select representative sample population order make inferences attitudes, opinions, behaviors population whole. using random sampling, researchers can ensure sample selected unbiased objective manner sample representative population.Clinical trials: Random sampling commonly used clinical trials, important select representative sample patients order evaluate effectiveness new treatment intervention. using random sampling, researchers can ensure sample patients selected unbiased objective manner sample representative population patients potentially benefit treatment.Clinical trials: Random sampling commonly used clinical trials, important select representative sample patients order evaluate effectiveness new treatment intervention. using random sampling, researchers can ensure sample patients selected unbiased objective manner sample representative population patients potentially benefit treatment.Social experiments: Random sampling often used social experiments, important select representative sample individuals groups order study effects particular treatment intervention. using random sampling, researchers can ensure sample selected unbiased objective manner sample representative population individuals groups potentially affected treatment.Social experiments: Random sampling often used social experiments, important select representative sample individuals groups order study effects particular treatment intervention. using random sampling, researchers can ensure sample selected unbiased objective manner sample representative population individuals groups potentially affected treatment.just examples random sampling can used different contexts. many examples random sampling, specific applications methods used vary depending goals constraints study. However, examples, random sampling useful technique selecting representative sample population making inferences population based sample.","code":""},{"path":"sampling.html","id":"coin-flipping","chapter":"Lecture 3 Sampling","heading":"3.2 Coin flipping","text":"Coin flipping form random sampling simple unbiased way selecting one two options, heads tails. statistics, random sampling process selecting subset observations larger population way member population equal probability chosen. Coin flipping random sampling method satisfies criteria: time coin flipped, 50% probability landing heads 50% probability landing tails, regardless previous flips. makes useful tool generating random samples statistical analysis.","code":""},{"path":"sampling.html","id":"coin-flip-in-r","chapter":"Lecture 3 Sampling","heading":"3.2.1 Coin flip in R","text":"Let coin flip using R. create vector contains values “head” “tail” random locations, can use sample() function R. example :code, first create vector called coin_flip holds values “head” “tail”. use sample() function shuffle values vector, randomly rearranges . Finally, print resulting vector R console verify values shuffled.Note sample() function always generate different result time called, exact sequence values resulting vector vary depending random seed used R. However, vector always contain values “head” “tail”, just different order time. can use technique create vector randomly-ordered values purpose, simulating coin flip random event.Alternatively, can code :","code":"\n# create a vector of the values \"head\" and \"tail\"\ncoin_flip <- c(\"head\", \"tail\")\n\n# shuffle the values in the vector\ncoin_flip <- sample(x = coin_flip, size = 1, replace = T)\n\n# print the shuffled vector\nprint(coin_flip)\n#> [1] \"tail\"\nsample(x = c(\"head\", \"tail\"), size = 1, replace = T)\n#> [1] \"head\""},{"path":"sampling.html","id":"rolling-dice","chapter":"Lecture 3 Sampling","heading":"3.3 Rolling dice","text":"Rolling dice form random sampling simple unbiased way selecting number set possible values. Rolling dice random sampling method satisfies criterion: time die rolled, equal probability landing possible values (e.g., 1, 2, 3, 4, 5, 6 standard six-sided die), regardless previous rolls. makes useful tool generating random samples statistical analysis.","code":""},{"path":"sampling.html","id":"dice-roll-in-r","chapter":"Lecture 3 Sampling","heading":"3.3.1 Dice roll in R","text":"simulate rolling die R, can create vector holds values 1 6 uses sample() function shuffle values vector. example :code, first create vector called dice holds values 1 6. use sample() function shuffle values vector, randomly rearranges . Finally, print resulting vector R console verify values shuffled.previous example, sample() function generate different result time called, exact sequence values resulting vector vary depending random seed used R. However, vector always contain values 1 6, just different order time. can use technique simulate rolling die random event involves set values.","code":"\n# create a vector of the values 1 through 6\ndice <- 1:6\n\n# shuffle the values in the vector\ndice <- sample(dice, size = 1, replace = T)\n\n# print the shuffled vector\nprint(dice)\n#> [1] 3"},{"path":"sampling.html","id":"additional-arguments-in-sample","chapter":"Lecture 3 Sampling","heading":"3.4 Additional arguments in sample()","text":"sample() function R two optional arguments: size replace. size argument specifies number values returned function, replace argument specifies whether sampling done without replacement. example use arguments:code, first create vector called dice holds values 1 6. use sample() function shuffle values vector, using size replace arguments specify want 3 values returned, sampling done replacement. means value can returned multiple times resulting vector. Finally, print resulting vector R console verify values shuffled size replacement arguments applied correctly.omitted replace argument set FALSE, sample() function returned vector values randomly shuffled, without replacement. means value appear resulting vector, value repeated. example, standard 52 cards, first value returned sample() function “3 Spades”, remaining 2 values “3 Spades”, cards deck.size replace arguments can useful controlling behavior sample() function generating specific types random samples. example, use size argument simulate drawing certain number cards deck, simulate rolling certain number dice. Similarly, use replace argument specify whether sampling done without replacement, depending specific application.","code":"\n# create a vector of the values 1 through 6\ndice <- 1:6\n\n# shuffle the values in the vector with replacement, returning 3 values\ndice <- sample(dice, size = 3, replace = TRUE)\n\n# print the shuffled vector\nprint(dice)\n#> [1] 5 3 2"},{"path":"sampling.html","id":"exercises","chapter":"Lecture 3 Sampling","heading":"3.5 Exercises","text":"E1. Show R codes simulate sum roll two standard six-sided dice.E2. Show R codes draw 7 cards deck 52 standard playing cards without replacement.","code":""},{"path":"for-loop-and-probability.html","id":"for-loop-and-probability","chapter":"Lecture 4 For loop and probability","heading":"Lecture 4 For loop and probability","text":"","code":""},{"path":"for-loop-and-probability.html","id":"for-loop-control-flow-statement","chapter":"Lecture 4 For loop and probability","heading":"4.1 For loop control flow statement","text":"loop control flow statement programming allows set instructions operations repeated specified number times, certain condition met. loops common feature many programming languages, including R, often used perform repetitive operations set data iterate elements data structure.loop typically three components: initial value, condition, update expression.initial value starting point loop, typically defined variable used store current value loop.initial value starting point loop, typically defined variable used store current value loop.condition logical expression evaluated start iteration loop, determines whether loop continue stop.condition logical expression evaluated start iteration loop, determines whether loop continue stop.update expression statement executed end iteration loop, updates value loop variable order move loop next iteration.update expression statement executed end iteration loop, updates value loop variable order move loop next iteration.","code":""},{"path":"for-loop-and-probability.html","id":"probability-of-heads","chapter":"Lecture 4 For loop and probability","heading":"4.2 Probability of heads","text":"Let ask mundane question. probability getting heads flipping fair coin?probability getting heads flipping coin 1/2, 0.5. coin two possible outcomes (heads tails), outcome equal probability occurring. flipping fair coin, 50% chance landing heads 50% chance landing tails. Therefore, probability getting heads 1/2, 0.5.way verify experimentation?One way verify probability getting heads flipping coin experiment. , need flip coin large number times (e.g., 100, 1000, ) keep track number times lands heads. flipping coin sufficient number times, can calculate percentage times landed heads. close expected probability 1/2, 0.5. experimental result significantly different expected probability, may indicate coin fair biased towards one side .","code":""},{"path":"for-loop-and-probability.html","id":"experimenting-with-100-coin-flips","chapter":"Lecture 4 For loop and probability","heading":"4.3 Experimenting with 100 coin flips","text":"simulate coin flip 100 times store values, can use loop R iterate flips store results vector. example :code, first create vector called coin_flip holds values “head” “tail”. create empty vector called results store outcomes coin flips. Next, use loop simulate 100 coin flips, using sample() function shuffle values coin_flip storing first value shuffled vector results vector. Finally, loop completed, print results vector R console see outcomes simulated coin flips.Note result simulation vary time run, due random nature sample() function. However, results vector always contain 100 elements, either “head” “tail”. can use technique simulate random event involves set possible outcomes store results analysis.count number “head” outcomes results coin flip simulation, can use sum() function R count number times value “head” appears results vector.use sum() function count number times value “head” appears results vector assign value head_count variable. Finally, print head_count variable R console see number “head” outcomes simulated coin flips.probability getting “head” flipping fair coin 50%, fair coin equal chance landing either “head” “tail” flipped. means flip fair coin 100 times, can expect get approximately 50 “head” outcomes 50 “tail” outcomes, although exact number outcome may vary slightly due randomness.example, probability getting head :Given 100 trials, got 58 heads. Hence probability getting head 0.58, close theoretical value probability \\(\\frac{1}{2}=0.5\\).found exact 50% probability, can increase experimentation trails say 10000 times.Actually faster better way simply changing size sample() arguments.see increase experimentation probability getting head converges zero. Let show one simulation, experiments record probability getting head plot .first line code creates sequence numbers 1 10000 increments 100, assigns sequence variable R. next line creates empty vector called head_prob, used store probability flipping head iteration experiment.loop iterates sequence stored R. value R, code uses sample function simulate flipping coin R[] times. function returns vector R[] elements, either “head” “tail”. results variable assigned vector.Next, code uses sum function count number elements results equal “head”, divides number total number elements results calculate probability flipping head. probability stored ith element head_prob vector.loop finished, head_prob vector contain probability flipping head value R. can used visualize relationship number coin flips probability flipping head.code plotting results coin flip experiment R. plot function used create line plot x-axis representing number coin flips (stored R variable), y-axis representing probability flipping head (stored head_prob variable). type = “l” argument tells function create line plot, col = “red” lwd = 2 arguments specify color thickness line, respectively.abline function used add horizontal line plot y-value 0.5. line represents expected probability flipping head coin fair. h = 0.5 argument specifies y-value line, lty = 3 argument specifies line type (case, dotted line), col = “blue” argument specifies color line.Together, two lines code create line plot shows relationship number coin flips probability flipping head. horizontal line 0.5 serves reference point show whether coin fair . line representing probability flipping head 0.5 line, indicates coin biased towards flipping heads. 0.5 line, indicates coin biased towards flipping tails.","code":"\n# create a vector of the values \"head\" and \"tail\"\ncoin_flip <- c(\"head\", \"tail\")\n\n# create an empty vector to store the results\nresults <- vector()\n\n# simulate the coin flips\nfor (i in 1:100) {\n  # shuffle the values in the vector\n  coin_flip <- sample(coin_flip)\n  \n  # store the first value in the shuffled vector\n  results[i] <- coin_flip[1]\n}\n\n# print the results vector\nprint(results)\n#>   [1] \"head\" \"tail\" \"head\" \"head\" \"head\" \"head\" \"head\"\n#>   [8] \"head\" \"tail\" \"head\" \"head\" \"head\" \"head\" \"tail\"\n#>  [15] \"tail\" \"head\" \"tail\" \"tail\" \"head\" \"head\" \"head\"\n#>  [22] \"head\" \"head\" \"tail\" \"tail\" \"head\" \"tail\" \"head\"\n#>  [29] \"head\" \"head\" \"tail\" \"tail\" \"head\" \"tail\" \"tail\"\n#>  [36] \"tail\" \"tail\" \"head\" \"tail\" \"head\" \"tail\" \"head\"\n#>  [43] \"head\" \"head\" \"tail\" \"head\" \"tail\" \"tail\" \"tail\"\n#>  [50] \"head\" \"head\" \"head\" \"head\" \"head\" \"head\" \"head\"\n#>  [57] \"head\" \"tail\" \"tail\" \"tail\" \"tail\" \"head\" \"tail\"\n#>  [64] \"tail\" \"head\" \"head\" \"head\" \"head\" \"head\" \"tail\"\n#>  [71] \"head\" \"head\" \"head\" \"tail\" \"head\" \"head\" \"tail\"\n#>  [78] \"tail\" \"tail\" \"head\" \"tail\" \"head\" \"head\" \"tail\"\n#>  [85] \"tail\" \"head\" \"head\" \"head\" \"head\" \"tail\" \"tail\"\n#>  [92] \"head\" \"tail\" \"tail\" \"tail\" \"head\" \"head\" \"tail\"\n#>  [99] \"head\" \"tail\"\n# count the number of \"head\" outcomes in the results vector\nhead_count <- sum(results == \"head\")\n\n# print the number of \"head\" outcomes\nprint(head_count)\n#> [1] 58\nhead_prob <-  sum(results == \"head\") / length(results)\n# create an empty vector to store the results\nresults <- vector()\n# simulate the coin flips\nfor (i in 1:10000) {\n  results[i] <- sample(x = c(\"head\", \"tail\"), size = 1, replace = T)\n}\n\nhead_prob <-  sum(results == \"head\") / length(results)\n\nhead_prob\n#> [1] 0.4976\n# This doesn't need for loop\nresults <- sample(x = c(\"head\", \"tail\"), size = 10000, replace = T)\n\nhead_prob <-  sum(results == \"head\") / length(results)\n\nhead_prob\n#> [1] 0.4978\nR <- seq(from = 1, to = 10000, by = 100)\nhead_prob <- vector()\n# simulate the coin flips\nfor (i in 1:length(R)) {\n  results <- sample(x = c(\"head\", \"tail\"), size = R[i], replace = T)\n  head_prob[i] <-  sum(results == \"head\") / length(results)\n}\nplot(x = R, y = head_prob, type = \"l\", col = \"red\", lwd = 2)\nabline(h = 0.5, lty = 3, col = \"blue\")"},{"path":"for-loop-and-probability.html","id":"exercises-1","chapter":"Lecture 4 For loop and probability","heading":"4.4 Exercises","text":"E1. Suppose roll standard six-sided die 10000 times. probability getting 6 given roll, many times can expect get 6 10000 rolls? Show solution R codes.E2. Suppose roll two standard six-sided dice sum outcomes. probability getting possible sum, sum highest probability? Show solution R codes.E3. Suppose draw 7 cards deck 52 standard playing cards without replacement. expected distribution sums 7 cards? Show solution R codes.Hint: answer question, first recognize 13 possible values card, 2 10, J, Q, K, . Lets call 1, J, Q, , K 11, 12, 13 respectively. calculate probability getting possible sum 7 cards using formula probability event occurring: probability = number ways event can happen / total number possible outcomes. Show solution R codes.","code":""},{"path":"if-else-and-probability.html","id":"if-else-and-probability","chapter":"Lecture 5 If else and probability","heading":"Lecture 5 If else and probability","text":"","code":""},{"path":"if-else-and-probability.html","id":"if-else-control-flow-statement","chapter":"Lecture 5 If else and probability","heading":"5.1 If else control flow statement","text":"else statement control flow statement R allows execute different code blocks depending whether certain condition true false. else statement two components: clause, specifies condition evaluated, else clause, specifies code executed condition false.example use else statement R:code, define numeric variable x value 10. use else statement evaluate value x, print different message depending whether x greater 5 .example, use else statement evaluate value variable x, print message depending whether x greater 5 . clause else statement contains condition x > 5, evaluates true value x greater 5, false otherwise. else clause else statement contains code print(“x greater 5”), executed condition clause false.another example. code uses statement loop evaluate elements x vector determine whether element greater 5.loop used iterate elements x vector. iteration loop, code checks whether current element x vector greater 5. element greater 5, code prints message console indicating element greater 5. element greater 5, code prints message console indicating element greater 5.","code":"\n# define a numeric variable x\nx <- 10\n\n# use an if else statement to evaluate the value of x\nif (x > 5) {\n  print(\"x is greater than 5\")\n} else {\n  print(\"x is not greater than 5\")\n}\n#> [1] \"x is greater than 5\"\nx <- c(1, 2, 4, -8, 6, 10)\n\n# use an if else statement to evaluate the value of x\nfor(i in 1:length(x))\nif (x[i] > 5) {\n  print(paste0(x[i], \" is greater than 5\"))\n} else {\n  print(paste0(x[i], \" is not greater than 5\"))\n}\n#> [1] \"1 is not greater than 5\"\n#> [1] \"2 is not greater than 5\"\n#> [1] \"4 is not greater than 5\"\n#> [1] \"-8 is not greater than 5\"\n#> [1] \"6 is greater than 5\"\n#> [1] \"10 is greater than 5\""},{"path":"if-else-and-probability.html","id":"if-head-you-get-2-dollars-else-you-loose-1-dollar.","chapter":"Lecture 5 If else and probability","heading":"5.2 If head you get 2 dollars else you loose 1 dollar.","text":"game, player flips coin bets whether land heads tails. Suppose coin lands heads; player wins 2 dollars. coin lands tails, player loses 1 dollar. straightforward game often used illustrate probability statistics concepts. real game typically find casino gambling establishment, can fun way learn probability statistics. Let’s code game R.","code":"\n# Define the possible outcomes of the coin: head and tail\ncoin <- c(\"head\", \"tail\")\n\n# Define the rewards for each coin flip: head wins 2 dollars, tail loses 1 dollar\nrewards <- c(2, -1)\n\n# Simulate the coin flip from the possible outcomes\ncoin_flip <- sample(x = coin, size = 1, replace = T)\n\n# Calculate the win based on the outcome of the coin flip using an if...else statement\nif(coin_flip == \"head\"){\n  win <- rewards[1]\n} else {\n  win <- rewards[2]\n}\n\n# Print the outcome and winnings\nprint(paste(\"Your coin flipped as\", coin_flip, \"hence your reward is \", win, \"dollars.\"))\n#> [1] \"Your coin flipped as head hence your reward is  2 dollars.\""},{"path":"if-else-and-probability.html","id":"for-loop-and-if-else-together","chapter":"Lecture 5 If else and probability","heading":"5.3 For loop and if else together","text":"happen players played game? win lose? simulate scenarios, use example -else conditional statement loop. Let’s assume can play 50 times one day.","code":"\n# Define the possible outcomes of the coin: head and tail\ncoin <- c(\"head\", \"tail\")\n\n# Define the rewards for each coin flip: head wins 2 dollars, tail loses 1 dollar\nrewards <- c(2, -1)\n\n# Initialize the total winnings vector\ntotal_winnings <- c()\n\n# Simulate playing the game 50 times\nfor (i in 1:50) {\n  # Simulate the coin flip from the possible outcomes\n  coin_flip <- sample(x = coin, size = 1, replace = T)\n  \n  # Calculate the win based on the outcome of the coin flip using an if...else statement\n  if(coin_flip == \"head\"){\n    win <- rewards[1]\n  } else {\n    win <- rewards[2]\n  }\n  \n  # store the value of win in total_winnings vector\n  total_winnings[i] <- win\n  \n}\n\n# Sum the total winnings to find your balances\nsum(total_winnings)\n#> [1] 25"},{"path":"if-else-and-probability.html","id":"multiple-for-loop-with-one-if-else-together","chapter":"Lecture 5 If else and probability","heading":"5.4 Multiple for loop with one if else together","text":"Let’s imagine play game three years casino discovers , banned. distribution total_winnings?use example understand basic statistics upcoming lecture.","code":"\n# Define the possible outcomes of the coin: head and tail\ncoin <- c(\"head\", \"tail\")\n\n# Define the rewards for each coin flip: head wins 2 dollars, tail loses 1 dollar\nrewards <- c(2, -1)\n\n# Initialize the sum of total winnings vector\nsum_total_winnings <- c()\n\nfor(j in 1:365*3){\n  # Initialize the total winnings vector\n  total_winnings <- c()\n  \n  # Simulate playing the game 50 times\n  for (i in 1:50) {\n    # Simulate the coin flip from the possible outcomes\n    coin_flip <- sample(x = coin, size = 1, replace = T)\n    \n    # Calculate the win based on the outcome of the coin flip using an if...else statement\n    if(coin_flip == \"head\"){\n      win <- rewards[1]\n    } else {\n      win <- rewards[2]\n    }\n    \n    # store the value of win in total_winnings vector\n    total_winnings[i] <- win\n    \n  }\n  # store the value of sum of total winnings of the day.\n  sum_total_winnings[j] <- sum(total_winnings)\n}\n\n# To plot the distribution you can use the hist()\nhist(sum_total_winnings)"},{"path":"if-else-and-probability.html","id":"exercise","chapter":"Lecture 5 If else and probability","heading":"5.5 Exercise","text":"E1. Suppose game show presented three closed doors. Behind one doors prize, behind , two doors empty. asked choose one doors, host game show, knows behind door, opens one two doors reveal empty. given option switch remaining closed door keep one originally chose. probability winning prize switch doors, probability winning keep original door? best strategy win game?Hint: answer question, first recognize 3 possible doors choose 1 prize behind . calculate probability winning prize switch doors, using formula probability event occurring: probability = number ways event can happen / total number possible outcomes.example, probability winning prize switch doors 2/3, 2 possible ways win prize (choosing either two doors prize behind ) 3 possible outcomes total (choosing 3 doors). Similarly, probability winning prize keep original door 1/3, 1 way win prize (choosing door prize behind ) 3 possible outcomes total. solution (https://www.youtube.com/watch?v=cXqDIFUB7YU).","code":""},{"path":"basic-statistics.html","id":"basic-statistics","chapter":"Lecture 6 Basic statistics","heading":"Lecture 6 Basic statistics","text":"","code":""},{"path":"basic-statistics.html","id":"previous-example","chapter":"Lecture 6 Basic statistics","heading":"6.1 Previous example","text":"try understand basic statistics using previous example game.use previous example game “head get 2 dollars else loose 1 dollar”. somebody played game 50 times day three years, potential value portfolio?","code":"\n# Multiple for loop with one if else together\n# Define the possible outcomes of the coin: head and tail\ncoin <- c(\"head\", \"tail\")\n\n# Define the rewards for each coin flip: head wins 2 dollars, tail loses 1 dollar\nrewards <- c(2, -1)\n\n# Initialize the sum of total winnings vector\nsum_total_winnings <- c()\n\nfor(j in 1:365*3){\n  # Initialize the total winnings vector\n  total_winnings <- c()\n  \n  # Simulate playing the game 50 times\n  for (i in 1:50) {\n    # Simulate the coin flip from the possible outcomes\n    coin_flip <- sample(x = coin, size = 1, replace = T)\n    \n    # Calculate the win based on the outcome of the coin flip using an if...else statement\n    if(coin_flip == \"head\"){\n      win <- rewards[1]\n    } else {\n      win <- rewards[2]\n    }\n    \n    # store the value of win in total_winnings vector\n    total_winnings[i] <- win\n    \n  }\n  # store the value of sum of total winnings of the day.\n  sum_total_winnings[j] <- sum(total_winnings)\n}\n\n# To plot the distribution you can use the hist()\nhist(sum_total_winnings)"},{"path":"basic-statistics.html","id":"basic-statistics-1","chapter":"Lecture 6 Basic statistics","heading":"6.2 Basic statistics","text":"Basic statistics measures used describe summarize datasets. common basic statistics include following:Mean: average, arithmetic mean, measure central tendency dataset. calculated adding values dataset dividing total number values. average useful measure provides overall summary dataset can used compare different datasets. Lets find average sum_total_winnings previous lecture.mean wining positive mean expected make positive gains.Median: median middle value dataset values sorted ascending descending order. measure central tendency dataset affected extreme values., appears half time, wins 25 better. Note first need sort values ascending descending order calculate median.Min Max: minimum dataset smallest value dataset. maximum dataset largest value dataset. values commonly referred min max dataset.Min examines maximum downside. maximum downside -2 dollars. Wow! upside looks really bright 52 dollars.Range: range difference largest smallest values dataset. measure dispersion dataset.minimum value -2 maximum value 52. Thus range maximum minus minimum 54.range one measures dispersion. Measures dispersion indicate spread values dataset . fact, several measures dispersion. Let’s examine variance standard deviation.Variance: variance measure much values dataset differ mean. measure dispersion dataset.Standard deviation: standard deviation square root variance. measure dispersion dataset expressed units original data.","code":"\n# We can use na.rm to remove NA and NaN values.\n# NA and NaN values are not allowed in numeric vectors\n# unless na.rm is TRUE.\nmean_win <- mean(sum_total_winnings, na.rm = TRUE)\nmean_win\n#> [1] 24.87671\nmedian_win <- median(sum_total_winnings, na.rm = TRUE)\nmedian_win\n#> [1] 25\nmin(sum_total_winnings, na.rm = TRUE)\n#> [1] -2\nmax(sum_total_winnings, na.rm = TRUE)\n#> [1] 52\n# Calculate the range\nwinning_range <- range(sum_total_winnings, na.rm = TRUE)\n\n# Print the range of the dataset\nprint(winning_range)\n#> [1] -2 52\n\n# Min\nwinning_range[1]\n#> [1] -2\n\n# Max\nwinning_range[2]\n#> [1] 52\n\n# Range\nwinning_range[2] - winning_range[1]\n#> [1] 54\n# variance\nvar(sum_total_winnings, na.rm = TRUE)\n#> [1] 117.0589\n\n# sd\nsd(sum_total_winnings, na.rm = TRUE)\n#> [1] 10.81938"},{"path":"basic-statistics.html","id":"quantiles-to-answer-probability","chapter":"Lecture 6 Basic statistics","heading":"6.3 Quantiles to answer probability","text":"recall, previously defined median following.interpret median value NA 50 percent likely make NA less. Thus way median captures probability.Let’s define quantiles percentiles. Quantiles values divide dataset equal parts. example, median value divides dataset two equal parts, lower upper quartiles values divide dataset four equal parts.Quantiles useful identifying values specific positions dataset. example, median used identify middle value dataset, quartiles used identify values 25th, 50th, 75th percentiles.general, quantiles calculated sorting values dataset ascending descending order taking value specific position. example, median middle value dataset odd number values average two middle values dataset even number values. quartiles 25th, 50th, 75th percentile values.Quantiles commonly used statistics describe dataset’s distribution identify specific values dataset. also useful comparing datasets different numbers values. example, can compare median two datasets see higher lower central tendency.calculate quantiles dataset R, can use quantile() function. ’s example:Note win_quantiles comprises 5 different values. can define values following.seems like 25 percent likely make 16 less, 50 percent likely make 16 less, 75 percentage likely make 25 less.","code":"\nmedian_win <- median(sum_total_winnings)\n\nmedian_win\n#> [1] NA\n# Calculate the quantiles of the dataset, we can use na.rm to remove NA and NaN values. NA and NaN values are not allowed in numeric vectors unless na.rm is TRUE.\nwin_quantiles <- quantile(sum_total_winnings, na.rm = TRUE)\n\n# Print the quantiles of the dataset\nprint(win_quantiles)\n#>   0%  25%  50%  75% 100% \n#>   -2   16   25   31   52\n# minimum value of dataset\nwin_quantiles[1]\n#> 0% \n#> -2\n\n# 25 percentile of dataset\nwin_quantiles[2]\n#> 25% \n#>  16\n\n# 50 percentile or median of dataset\nwin_quantiles[3]\n#> 50% \n#>  25\n\n# 75 percentile or median of dataset\nwin_quantiles[4]\n#> 75% \n#>  31\n\n# 50 percentile or median of dataset\nwin_quantiles[5]\n#> 100% \n#>   52"},{"path":"basic-statistics.html","id":"quantiles-to-generate-confidence-intervals","chapter":"Lecture 6 Basic statistics","heading":"6.4 Quantiles to generate confidence intervals","text":"context quantiles, probs argument specifies probabilities quantiles want calculate. example, set probs = c(0.5), quantile() function calculate median dataset. set probs = c(0.25, 0.75), quantile() function calculate lower upper quartiles dataset.set probs = c(0.025, 0.05, 0.95, 0.975), quantile() function calculate quantiles 2.5th, 5th, 95th, 97.5th percentiles dataset. quantiles commonly used statistics identify extreme values dataset. example, 2.5th 97.5th percentiles used identify lower upper bounds 95% confidence interval.’s example use probs argument calculate quantiles:Running code print quantiles 2.5th, 5th, 95th, 97.5th percentiles dataset format “0% 2.5% 5% 95% 97.5% 100%”appears 2.5% likely probable winnings can 1 less 97.5% likely winnings can 46 Alternatively, can confident winning 97.5%-2.5%=95% likely range lower bound 1 upper bound 46.confidence interval range values used estimate population parameter. calculated taking sample population using statistics mean median estimate population parameter. confidence interval calculated adding subtracting margin error estimate. calculate margin error, multiply standard deviation sample critical value. However, understand critical values, understand z-statistics. now, skip .","code":"\n# Calculate the 2.5th, 5th, 95th, and 97.5th percentiles of the dataset\ndataset_quantiles <- quantile(sum_total_winnings, probs = c(0.025, 0.05, 0.95, 0.975), na.rm = T)\n\nprint(dataset_quantiles)\n#>  2.5%    5%   95% 97.5% \n#>   1.0   4.6  43.0  46.0\ndataset_quantiles[1]\n#> 2.5% \n#>    1\n\ndataset_quantiles[4]\n#> 97.5% \n#>    46"},{"path":"basic-statistics.html","id":"exercise-1","chapter":"Lecture 6 Basic statistics","heading":"6.5 Exercise","text":"stop loss order sell security reaches certain price. used limit loss trade. example, buy stock \\(100\\) set stop loss \\(95\\), stop loss order triggered stock price falls \\(95\\) lower. sell stock limit loss \\(5\\) per share.take profit opposite stop loss. order sell security reaches certain price. used lock profit trade. example, buy stock \\(100\\) set take profit \\(110\\), take profit order triggered stock price rises \\(110\\) higher. sell stock lock profit \\(10\\) per share.Stop losses take profits commonly used traders manage trades limit risk. often used conjunction create trade management strategy. example, trader might buy stock set stop loss entry price protect sudden drop stock price. might also set take profit higher price lock profit stock price rises.Overall, stopping losses taking profits helpful tools managing risk protecting potential losses trade. can help traders disciplined consistent trading manage trades effectively.Let’s imagine decided day trade (hashtag financial advice). trading philosophy straightforward. put stop loss 100 dollars took profit 125 dollars. stock goes , limit loss 100 dollars, stock goes , limit win 125. However, call skill way Mr. Market works. better coin flip, ’s 50% likely make lose. can trigger trade 99 times day, trading software limits . However, can come back tomorrow trade . 200 trading days year, past 5 years. cumulative portfolio values 90%, 95%, 99% confidence intervals? probability suffer loss? sake simplicity, fees commissions.example promote day trade. economics efficient market hypothesis states one can consistently beat Market. See Marginal Revolution University’s Macroeconomics course’s Personal Finance section (https://mru.org/courses/principles-economics-macroeconomics/expert-stock-picks).best way generating wealth invest recursively low-cost index funds, possible, within tax advantage accounts. See Bogleheads® investment philosophy (https://www.bogleheads.org/wiki/Bogleheads%C2%AE_investment_philosophy).","code":""},{"path":"investing-basics.html","id":"investing-basics","chapter":"Lecture 7 Investing basics","heading":"Lecture 7 Investing basics","text":"","code":""},{"path":"investing-basics.html","id":"an-angel-investor","chapter":"Lecture 7 Investing basics","heading":"7.1 An angel investor","text":"angel investor (private investor, seed investor, angel funder) high-net-worth individual provides financial backing small startups entrepreneurs, typically exchange ownership equity company. Often, angel investors found among entrepreneur’s family friends.Suppose angel investor one friends’ business. friend said return 10% every year next five years. expected growth investment? Let’s imagine invested $1. , know compound interest formula principal 1 dollar grow 10% every year next five year .e.,\n\\[= P(1+r)^t\\]\n\\[= 1(1+0.1)^5 = 1.4641\\]means initial investment 1 dollar 1.4641 dollars. Let show R.","code":"\n# Let call the growth rate as r\nr <- c(0.1, 0.1, 0.1, 0.1)\n\n# Lets define the 1+r \nR <- 1+r\n\n# You can simply do cumulative product as\nportfolio <- cumprod(R)\n\n# print\nprint(portfolio)\n#> [1] 1.1000 1.2100 1.3310 1.4641\n\n# To find the last year's total return\nfifth_year_return <- portfolio[length(portfolio)]\n\nprint(fifth_year_return)\n#> [1] 1.4641"},{"path":"investing-basics.html","id":"exercise-2","chapter":"Lecture 7 Investing basics","heading":"7.2 Exercise","text":"Case-1: got another friend brilliant idea. However, friends say first year, likely incur loss 5%, gain 10%, 20%, 30%, 40%. $1 initial investment grow? better opportunity previous friend’s project?Case-2: following R codes, provide Historical S&P 500 Index Stock Market Returns (https://www.thebalancemoney.com/stock-market-returns--year-2388543) 1980 onwards. expected growth investment? Let’s imagine invested $1.Case-3: One students correctly identified investor adjust inflation, investors interested real dollar value nominal value. gathered inflation past 34 years since 1980. can define real return difference nominal return inflation. inflation-adjusted value portfolio?","code":"\nsnp_ret <- c(\n  0.185,\n  0.052,\n  0.168,\n  0.315,\n  -0.031,\n  0.305,\n  0.076,\n  0.101,\n  0.011,\n  0.372,\n  0.227,\n  0.330,\n  0.2858,\n  0.2104,\n  -0.091,\n  -0.1189,\n  -0.221,\n  0.2868,\n  0.1088,\n  0.0491,\n  0.1579,\n  0.0549,\n  -0.370,\n  0.2646,\n  0.1506,\n  0.0211,\n  0.160,\n  0.3239,\n  0.1369,\n  0.0138,\n  0.1196,\n  0.2183,\n  -0.0438,\n  0.3149\n)\ninflation <- c(0.189805,\n               0.0366456,\n               0.040777411,\n               0.04827003,\n               0.053979564,\n               0.04234964,\n               0.030288197,\n               0.02951657,\n               0.026074416,\n               0.028054197,\n               0.029312042,\n               0.023376899,\n               0.015522791,\n               0.021880272,\n               0.033768573,\n               0.028261711,\n               0.015860316,\n               0.02270095,\n               0.026772367,\n               0.033927468,\n               0.032259441,\n               0.028526725,\n               0.038391003,\n               -0.003555463,\n               0.016400434,\n               0.031568416,\n               0.020693373,\n               0.014648327,\n               0.01622223,\n               0.001186271,\n               0.012615832,\n               0.0213011,\n               0.024425833,\n               0.018122101)\n\nreal_return <- snp_ret - inflation"},{"path":"recursive-investment.html","id":"recursive-investment","chapter":"Lecture 8 Recursive investment","heading":"Lecture 8 Recursive investment","text":"","code":""},{"path":"recursive-investment.html","id":"recursive-investment-1","chapter":"Lecture 8 Recursive investment","heading":"8.1 Recursive investment","text":"Imagine intend recursive investing. means plan invest every year. table , show value portfolio. example, column (8), cumulative value portfolio fifth year 6.129.Let explain table . Let’s first focus column (4). invested 1 dollar, first year, lost 5%. Thus portfolio 1(1-0.05) = 0.95. However, second year growth 10%, thus 0.95 dollar grew 10% 0.95(1+0.1) = 0.95(1.1) =1.045. third year, growth 20%. Hence 1.045 dollars grew 1.045(1.2)=1.32, 1.32 dollars grew 30% 1.32(1.3) = 1.716. Hence first dollar invested grew 1.716 dollars, solid 71.6% return.However, wise recursive investing. See column (5). second year, made additional 1 dollar investment, grew 10% 1.1 dollars. 1.1 dollars grew 20% third year become 1.1(1.2)=1.32 dollars, fourth year became 1.32(1.3)=1.56. Hence 1 dollar invested second year became 1.56 dollars, another solid 56% growth.Now work logic column (6) column (7).overall, invested 4 dollars, became 6.219 dollars end fourth year.Let’s code R.code calculates cumulative product elements R vector. creating empty vector called fifth_year_return using loop iterate elements R vector.iteration loop, code calculates cumulative product elements R vector using cumprod() function. function calculates cumulative product elements vector, product elements vector given point.code stores result cumprod() function temporary vector called growth. vector contains cumulative product elements R vector current iteration loop.Next, code stores last element growth vector fifth_year_return vector. means fifth_year_return vector contain cumulative product elements R vector element R vector.loop finished executing, code prints fifth_year_return vector console calculates sum elements vector using sum() function. gives total cumulative product elements R vector.Let’s examine code detailedly. length() function. length() function built-function R programming language. used determine length object, vector list. length(R) prompts 4 means vector 4 elements.R[] helps extract elements. example, R[1] extract first element 0.95. can extract multiple elements well. R[1:3] extract first three elements 0.95, 1.1, 1.2. Thus R[:length(R)] extract multiple elements ' runs 1 length R. HenceR[1:5]give first four elements vector R,R[2:5]` gives second element fourth element.can implement cumprod() function run cumulative product function. Note cumprod() generates vector, store object called growth. interested last element growth vector. save fifth_year_return vector. Finally sum elements fifth_year_return vector.Case-1: decided recursive investing. friends say can deliver growth rate 10%, 20%, 30%, one year, 5% loss. sure sequences returns. Since sure sequence returns, can simulate sequences returns random sampling. Perform 1000 random draws record probable values portfolio. 95% confidence interval cumulative portfolio value?Case-2: following R codes, provide Historical S&P 500 Index Stock Market Returns (https://www.thebalancemoney.com/stock-market-returns--year-2388543) 1980 onwards. expected growth recursive investment? Let’s imagine invested $1 religiously every year.Case-3: past 35 years looked like might look different future. decided remain invested next 35 years. need find future sequences growth risk. can randomize historical sequences, returns occur random order. Simulate 1000 trials R. simulation, rational investor invest US stock market? 95% confidence interval cumulative portfolio value end 35 years?","code":"\n# Let call the growth rate as r\nr <- c(-0.05, 0.1,0.2,0.3)\n# Lets define the 1+r \nR <- 1+r\n\n# Initialize a vector\nfifth_year_return <- c()\n\n# Perform a for loop\nfor(i in 1:length(R)){\n    growth <- cumprod(R[i:length(R)])\n  \n    fifth_year_return[i] <- growth[length(growth)]\n}\nfifth_year_return\n#> [1] 1.6302 1.7160 1.5600 1.3000\nsum(fifth_year_return)\n#> [1] 6.2062portfolio_value <- c()\nfor(....){\n  r <- c(0.3, 0.1, 0.2, -0.05)\n  sample_r <- sample(x = ..., size = ..., replace = FALSE)\n  R <- ....\n\n  portfolio <- c()\n  for(...){\n    portfolio[i] <- cumprod(...)[...]\n  }\n  portfolio_value[j] <- sum(...)\n}\nhist(portfolio_value)\nsnp_ret <- c(\n  0.185,\n  0.052,\n  0.168,\n  0.315,\n  -0.031,\n  0.305,\n  0.076,\n  0.101,\n  0.011,\n  0.372,\n  0.227,\n  0.330,\n  0.2858,\n  0.2104,\n  -0.091,\n  -0.1189,\n  -0.221,\n  0.2868,\n  0.1088,\n  0.0491,\n  0.1579,\n  0.0549,\n  -0.370,\n  0.2646,\n  0.1506,\n  0.0211,\n  0.160,\n  0.3239,\n  0.1369,\n  0.0138,\n  0.1196,\n  0.2183,\n  -0.0438,\n  0.3149\n)"},{"path":"index-universal-life-insurance.html","id":"index-universal-life-insurance","chapter":"Lecture 9 Index universal life insurance","heading":"Lecture 9 Index universal life insurance","text":"","code":""},{"path":"index-universal-life-insurance.html","id":"case-study-index-universal-life-insurance","chapter":"Lecture 9 Index universal life insurance","heading":"9.1 Case study, index universal life insurance","text":"Case-1: insurance sales agent wants sell index universal life insurance. idea pretty simple. invest premium S&P 500 Index Stock Market. market yields negative return, agent says, incur loss. snp_ret < 0, returns zero. Sweet Deal! However, market grew 13%, capped 13%. market ranges 0 13%, return market return. policy 30 year period.Question-1. Intuitively, good idea? Explain ?Question-1. Intuitively, good idea? Explain ?Question-2. Select first 30 elements snp_ret policy 30 years. Develop -else conditional statement.Question-2. Select first 30 elements snp_ret policy 30 years. Develop -else conditional statement.Question-3. Find value portfolio recursive investing.Question-3. Find value portfolio recursive investing.Question-4. Model sequence risk. 95% confidence interval cumulative portfolio value?Question-4. Model sequence risk. 95% confidence interval cumulative portfolio value?","code":"r <- sample(x = ..., size = length(snp_ret[1:30]), replace = F)\nfor(i in 1:length(...)){\n  if(r[...]<=0){\n    r[...] = 0\n  }\n  if(r[...]>=...){\n    r[...] = 0.13\n  }\n  else\n  {\n    r[...] = r[..]\n  }\n  "},{"path":"stock-market-monte-carlo-simulation.html","id":"stock-market-monte-carlo-simulation","chapter":"Lecture 10 Stock market monte-carlo simulation","heading":"Lecture 10 Stock market monte-carlo simulation","text":"","code":""},{"path":"stock-market-monte-carlo-simulation.html","id":"case-study-growth-of-portfolio","chapter":"Lecture 10 Stock market monte-carlo simulation","heading":"10.1 Case study, growth of portfolio","text":"Case-1: Reproduce following columns 4 7 using R codes.Lets inefficient way first develop intuition.using two new functions cbind() rowSums(). Let discuss . cbind() function combines vectors, matrices, data frames columns R. function takes objects combined arguments returns new object containing combined data. Like cbind(), also rbind() combine vectors, matrices, data frames rows.R, rowSums() function used compute sum values row matrix data frame. function takes first argument matrix data frame summed returns vector containing row sums. Similar colSums() compute sum values column matrix data frameThe example manual. let’s using loop.still need work. need column-wise bind results list. , use powerful function called .call(). R, .call() function used evaluate function call arguments given list data frame. function takes first argument name function called second argument, list data frame containing arguments passed function. Within .call(), use cbind().Lets take rowSums() plot growth portfolio.Case-1: Plot 1 dollar recursively invested portfolio grows using S&P 500 Index Stock Market growth.","code":"\n# This one is column (1)\nr <- c(-0.05, 0.1, 0.2, 0.3)\n# This is column (2)\nR <- 1 + r\n\n# To find the column (4)\nc4 <- cumprod(R)\nc4\n#> [1] 0.9500 1.0450 1.2540 1.6302\n\n# To find the column (5), we have to think slightly carefully.\nr <- c(0.1, 0.2, 0.3)\nR <- 1 + r\ncumprod(R)\n#> [1] 1.100 1.320 1.716\nc5 <- c(0, cumprod(R))\nc5\n#> [1] 0.000 1.100 1.320 1.716\n\n# To find the column (6), we have to think slightly carefully.\nr <- c(0.2, 0.3)\nR <- 1 + r\nc6 <- c(0,0,cumprod(R))\n\n# To find the column (7), we have to think slightly carefully.\nr <- c(0.3)\nR <- 1 + r\nc7 <- c(0,0,0,cumprod(R))\n\nmy_table <- cbind(c4,c5,c6,c7)\n\nmy_table\n#>          c4    c5   c6  c7\n#> [1,] 0.9500 0.000 0.00 0.0\n#> [2,] 1.0450 1.100 0.00 0.0\n#> [3,] 1.2540 1.320 1.20 0.0\n#> [4,] 1.6302 1.716 1.56 1.3\n\n# Lets rowwise sum with rowSums. Note that \"S\" is capital letter \nmy_table <- cbind(my_table, rowSums(my_table))\n\nmy_table\n#>          c4    c5   c6  c7       \n#> [1,] 0.9500 0.000 0.00 0.0 0.9500\n#> [2,] 1.0450 1.100 0.00 0.0 2.1450\n#> [3,] 1.2540 1.320 1.20 0.0 3.7740\n#> [4,] 1.6302 1.716 1.56 1.3 6.2062\nr <- c(-0.05, 0.1, 0.2, 0.3)\nR <- 1+r\n# Initialize a list() rather than an atomic vector\nportfolio <- list()\nfor(i in 1:length(R)){\n  # Here is the zero vector\n  zero_vector <- rep(0,i-1)\n  # Here is the vector of cumulative product.\n  cumprod_vector <- cumprod(R[i:length(R)])\n  \n  # We concatenate the zero and cumulative product vector\n  my_result <- c(zero_vector, cumprod_vector)\n  \n  # Let's put this results into a list.\n  portfolio[[i]] <- my_result\n}\n\n# Print the value of portfolio\nportfolio\n#> [[1]]\n#> [1] 0.9500 1.0450 1.2540 1.6302\n#> \n#> [[2]]\n#> [1] 0.000 1.100 1.320 1.716\n#> \n#> [[3]]\n#> [1] 0.00 0.00 1.20 1.56\n#> \n#> [[4]]\n#> [1] 0.0 0.0 0.0 1.3\nmy_table <- do.call(cbind, portfolio)\nportfolio_value <- rowSums(my_table)\nplot(portfolio_value, type = \"b\", col = \"red\", lwd = 2)"},{"path":"stock-market-monte-carlo-simulation.html","id":"case-monte-carlo-simulation-of-stock-market","chapter":"Lecture 10 Stock market monte-carlo simulation","heading":"10.2 Case, Monte Carlo simulation of stock market","text":"Case-2: past 35 years looked like, might look different upcoming future. decided remain invested next 35 years. don’t know future sequences growth risk. can simply randomize historical sequences returns occur random order. Simulate 1000 trials R. Show evolution cumulative portfolio value 35 years.","code":"snp_ret <- c(...)\nportfolio_value <- ...\nfor(...){\n  r <- sample(...)\n  R <- ...\n  portfolio <- ...\n  for(i in 1:length(R)){\n    zero_vector <- ...\n    cumprod_vector <- ...\n    portfolio[[i]] <- ...\n  }\n  portfolio_value[[j]] <- rowSums(do.call(..., ...))\n}\nportfolio_value <- ...(..., ...)\n\nmatplot(portfolio_value, type = \"l\")\nmatplot(portfolio_value, type = \"l\")"},{"path":"confidence-interval-z-scores-hypothesis-testing.html","id":"confidence-interval-z-scores-hypothesis-testing","chapter":"Lecture 11 Confidence interval, z-scores, hypothesis testing","heading":"Lecture 11 Confidence interval, z-scores, hypothesis testing","text":"","code":""},{"path":"confidence-interval-z-scores-hypothesis-testing.html","id":"confidence-interval","chapter":"Lecture 11 Confidence interval, z-scores, hypothesis testing","heading":"11.1 Confidence interval","text":"","code":""},{"path":"confidence-interval-z-scores-hypothesis-testing.html","id":"previous-example-on-the-day-trading.","chapter":"Lecture 11 Confidence interval, z-scores, hypothesis testing","heading":"11.1.1 Previous example on the day trading.","text":"Let’s imagine decided day trade (hashtag, financial advice). trading philosophy straightforward. put stop loss 100 dollars took profit 125 dollars. stock goes , limit loss 100 dollars, stock goes , limit win 125. However, call skill way Mr. Market works. better coin flip, ’s 50% likely make lose. can trigger trade 99 times day, trading software limits . However, can come back tomorrow trade . 200 trading days year, past five years. cumulative portfolio values 90%, 95%, 99% confidence intervals? probability suffer loss? sake simplicity, fees commissions.code simulates game player can win lose money. uses loop simulate game played 1000 times, calculates total winnings game.code begins defining empty vector called sum_total_winnings. vector used store total winnings game.Next, code uses loop simulate game played 1000 times. code defines empty vector called total_winnings iteration loop. vector store winnings round game.code uses another loop simulate 50 rounds game. round, code uses sample() function randomly select either win $125 loss $100. result stored total_winnings vector.50 rounds game simulated, code calculates sum winnings total_winnings vector using sum() function. gives total winnings current game. code stores value sum_total_winnings vector., 1000 games simulated, total winnings game calculated, code vector called sum_total_winnings contains total winnings game.can use hist() function R plot histogram sum_total_winnings vector. example :code generate histogram values sum_total_winnings vector. histogram show frequency value vector, allowing see often total winnings amount occurred simulated games.can customize appearance histogram using various arguments hist() function.Looking histogram, can quickly make educated guesses min, max, mean. example, find minimum, maximum, mean sum_total_winnings vector, can use following R code:Looking histogram mean statistics, likely game generates average winning 610.6225, bad.confident average estimate winnings? Well, 95% sure confident, average 2.5% 97.5% quantiles. find 2.5% 97.5% quantiles vector R, can use quantile() function. example use function find 2.5% 97.5% quantiles sum_total_winnings vector:2.5% quantile value 2.5% values sum_total_winnings vector fall. Similarly, 97.5% quantile value 97.5% values sum_total_winnings vector fall. words, 95% confidence interval range values 2.5% 97.5% quantiles. Thus suggests 95% confident average winning ranges -950 2200.add 95% confidence interval mean histogram sum_total_winnings vector, can use abline() function R. example :","code":"\nsum_total_winnings <- c()\nfor (j in 1:10000) {\n  total_winnings <- c()\n  for (i in 1:50) {\n    total_winnings[i] <- sample(x = c(125,-100),\n                                size = 1,\n                                replace = T)\n  }\n  sum_total_winnings[j] <- sum(total_winnings)\n}\n# Plot a histogram of the sum_total_winnings vector\nhist(sum_total_winnings)\n# Find the minimum value in the sum_total_winnings vector\nmin(sum_total_winnings)\n#> [1] -2075\n\n# Find the maximum value in the sum_total_winnings vector\nmax(sum_total_winnings)\n#> [1] 3550\n\n# Find the mean of the sum_total_winnings vector\nmean(sum_total_winnings)\n#> [1] 610.6225\n# Find the 2.5% and 97.5% quantiles of the sum_total_winnings vector\nquantiles_value <- quantile(sum_total_winnings, probs = c(0.025, 0.975))\n# Plot a histogram of the sum_total_winnings vector\nhist(sum_total_winnings)\n\n# Calculate the 2.5% and 97.5% quantiles of the sum_total_winnings vector\nquantiles <- quantile(sum_total_winnings, probs = c(0.025, 0.975))\n\n# Calculate the mean of the sum_total_winnings vector\nmean_value <- mean(sum_total_winnings)\n\n# Add lines to the histogram showing the 95% confidence interval and the mean\nabline(v = quantiles, col = \"red\", lty = 9)\nabline(v = mean_value, col = \"blue\", lty = 2)"},{"path":"confidence-interval-z-scores-hypothesis-testing.html","id":"value-at-risk","chapter":"Lecture 11 Confidence interval, z-scores, hypothesis testing","heading":"11.1.2 Value-at-risk","text":"Think value risk probability value. case, like understand probability incurring loss game .find probability getting 0 less sum_total_winnings vector, can use mean() function R calculate proportion values vector 0 less. example :seems like 24.64% likely incur 0 loss. can show graphically histogram :","code":"\n# Calculate the proportion of values in the sum_total_winnings vector that are 0 or less\nvalue_at_risk <- mean(sum_total_winnings <= 0)\n\nprint(value_at_risk)\n#> [1] 0.2464\n# Plot a histogram of the sum_total_winnings vector\nhist(sum_total_winnings, col = \"steelblue\")\n\n# Add lines to the histogram showing value 0\nabline(v = 0, col = \"red\", lty = 3, lwd = 2)"},{"path":"confidence-interval-z-scores-hypothesis-testing.html","id":"measure-of-dispersion","chapter":"Lecture 11 Confidence interval, z-scores, hypothesis testing","heading":"11.2 Measure of dispersion","text":"far, discussing central tendencies like mean median. quickly looked dispersion data 2.5% 97.5% quantiles. Let’s examine measures dispersion.mean deviation measure dispersion dataset. calculated average absolute difference dataset’s values dataset’s mean. example, let’s say data \\(x\\) mean data \\(\\bar{x}\\). deviation can defined \\(x - \\bar{x}\\).one statistical property. sums deviations \\(\\sum (x-\\bar{x})\\) always zero also means deviation \\(\\frac{\\sum (x-\\bar{x})}{n}\\) zero. Lets verify .Variance: Variance another measure dispersion dataset. calculated average squared difference dataset’s values dataset’s mean. saw, mean deviations zero, ’s tricky interpret 0. , another approach square deviation take mean \\(var = \\frac{\\sum (x-\\bar{x})^2}{n}\\). However, issue unit variance. squares unit. data dollar, unit variance unit squared. creates slight trouble interpret. One way solve issue take square root.Variance: Variance another measure dispersion dataset. calculated average squared difference dataset’s values dataset’s mean. saw, mean deviations zero, ’s tricky interpret 0. , another approach square deviation take mean \\(var = \\frac{\\sum (x-\\bar{x})^2}{n}\\). However, issue unit variance. squares unit. data dollar, unit variance unit squared. creates slight trouble interpret. One way solve issue take square root.Standard deviation: Standard deviation measure dispersion dataset. calculated square root variance dataset \\(\\sigma = \\sqrt \\frac{\\sum (x-\\bar{x})^2}{n}\\).Standard deviation: Standard deviation measure dispersion dataset. calculated square root variance dataset \\(\\sigma = \\sqrt \\frac{\\sum (x-\\bar{x})^2}{n}\\).","code":"\n# Define a dataset containing the values 1, 2, 3, 4, 5\ndataset <- c(1, 2, 3, 4, 5)\n\n# Calculate the mean of the dataset\nmean_value <- mean(dataset)\n\n# Calculate the deviation of the dataset\ndeviation_value <- dataset - mean_value\n\n# print the deviation\nprint(deviation_value)\n#> [1] -2 -1  0  1  2\n# Sum of deviations\nsum(deviation_value)\n#> [1] 0\n\n# Sum of deviations\nmean(deviation_value)\n#> [1] 0\n# variance\nvar(dataset)\n#> [1] 2.5\n\n# standard deviation\nsd(dataset)\n#> [1] 1.581139"},{"path":"confidence-interval-z-scores-hypothesis-testing.html","id":"z-scores","chapter":"Lecture 11 Confidence interval, z-scores, hypothesis testing","heading":"11.3 Z-scores","text":"focus little standard deviation. name suggests standard deviation allows standardize data. z-score, also known standard score, measure many standard deviations value mean dataset. calculated subtracting mean dataset value, dividing result standard deviation dataset.standardized data called z-scores, can written \\(Z=\\frac{x-\\bar{x}}{\\sigma}\\). can simply interpreted many standard deviation data ’s mean.calculate z-score R, can use scale() function. example :z-score helpful allows compare values different datasets standardizing . example, two datasets various means standard deviations, can calculate z-scores values dataset compare directly.Let show z-scores allow comparing two different datasets. example, consider following two datasets.mean standard deviation dataset1 3 1.5811388, respectively. mean standard deviation dataset2 15.8113883 15.8113883, respectively. calculate z-score value 2 dataset1 value 20 dataset2, get following results:code first calculate mean standard deviation dataset using mean() sd() functions. calculate z-score value 2 subtracting mean value dividing result standard deviation using scale() function. result stored z_score variable, containing z-score value 2. example, z_score variable value -0.6324555.Note mean z-scores 0, standard deviation 1. Let’s check.","code":"\nz_score_manual <- (dataset - mean(dataset))/sd(dataset)\nprint(z_score_manual)\n#> [1] -1.2649111 -0.6324555  0.0000000  0.6324555  1.2649111\nz_score <- scale(dataset, center = mean(dataset), scale = sd(dataset))\nprint(z_score)\n#>            [,1]\n#> [1,] -1.2649111\n#> [2,] -0.6324555\n#> [3,]  0.0000000\n#> [4,]  0.6324555\n#> [5,]  1.2649111\n#> attr(,\"scaled:center\")\n#> [1] 3\n#> attr(,\"scaled:scale\")\n#> [1] 1.581139\n# Define the first dataset\ndataset1 <- c(1, 2, 3, 4, 5)\n\nmean(dataset1)\n#> [1] 3\nsd(dataset1)\n#> [1] 1.581139\n\n# Define the second dataset\ndataset2 <- c(10, 20, 30, 40, 50)\n\nmean(dataset2)\n#> [1] 30\nsd(dataset2)\n#> [1] 15.81139\n# Calculate the z-score for the value 2 in dataset1\nz_score1 <- scale(2, center = mean(dataset1), scale = sd(dataset1))\nz_score1\n#>            [,1]\n#> [1,] -0.6324555\n#> attr(,\"scaled:center\")\n#> [1] 3\n#> attr(,\"scaled:scale\")\n#> [1] 1.581139\n\n# Calculate the z-score for the value 20 in dataset2\nz_score2 <- scale(20, center = mean(dataset2), scale = sd(dataset2))\nz_score2\n#>            [,1]\n#> [1,] -0.6324555\n#> attr(,\"scaled:center\")\n#> [1] 30\n#> attr(,\"scaled:scale\")\n#> [1] 15.81139\nmean(z_score)\n#> [1] 0\nsd(z_score)\n#> [1] 1\n\nz_score_wininigs <- scale(sum_total_winnings, center = mean(sum_total_winnings), scale = sd(sum_total_winnings))\nmean(z_score_wininigs)\n#> [1] 7.530745e-17\nsd(z_score_wininigs)\n#> [1] 1"},{"path":"confidence-interval-z-scores-hypothesis-testing.html","id":"normal-distribution-and-standard-normal-distribution","chapter":"Lecture 11 Confidence interval, z-scores, hypothesis testing","heading":"11.4 Normal distribution and standard normal distribution","text":"normal distribution type continuous probability distribution defined symmetrical bell-shaped curve. type distribution commonly used statistics model distribution continuous random variable.normal distribution defined two parameters: mean, average value distribution, standard deviation, measure spread distribution. mean standard deviation determine shape location normal distribution curve.normal distribution several important properties, including:mean, median, mode distribution equal.curve symmetrical, left right halves mirror images .standard deviation increases, curve becomes wider flatter.normal distribution often used statistics model distribution continuous random variable, height population, weight sample fruits, time taken complete task. particularly useful symmetrical shape mathematical properties, allow easy calculation probabilities confidence intervals.Let’s plot histogram sum_total_winnings.mean median . curve looks symmetrical, , normal. statistical tests verify normal distribution. explore later class.divide data standard deviation, get z-scores, defined standard normal distribution. standard normal distribution normal distribution mean 0 standard deviation 1. special case normal distribution often used statistics reference distribution compare normal distributions.following probability density function defines standard normal distribution:\\[ f(x) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{x^2}{2}} \\]function describes probability density given value x, height normal distribution curve value. can see, standard normal distribution mean 0 standard deviation 1.standard normal distribution several important properties, including:total area curve equal 1, represents total probability possible outcomes.curve symmetrical, left right halves mirror images .mean, median, mode distribution equal 0.curve always shape, regardless value standard deviation.standard normal distribution often used reference distribution compare normal distributions . particularly useful symmetrical shape mathematical properties, allow easy calculation probabilities confidence intervals.Let’s plot histogram z-scores sum_total_winnings.might see breaks . day trading discrete problem, continuous one. Visually, mean, median, mode centered zero symmetrical, seems standard normal. can exploit properties standard normal curve. Let’s check critical values.","code":"\nhist(sum_total_winnings, main = \"Does it look normal to you?\")\nabline(v = mean(sum_total_winnings), col = \"red\", lty = 9)\nabline(v = median(sum_total_winnings), col = \"blue\", lty = 2)\nz_score_wininigs <- scale(sum_total_winnings, center = mean(sum_total_winnings), scale = sd(sum_total_winnings))\nhist(z_score_wininigs, main = \"Does it look standard normal to you?\")\nabline(v = mean(z_score_wininigs), col = \"red\", lty = 9)\nabline(v = median(z_score_wininigs), col = \"blue\", lty = 2)"},{"path":"confidence-interval-z-scores-hypothesis-testing.html","id":"critical-values","chapter":"Lecture 11 Confidence interval, z-scores, hypothesis testing","heading":"11.5 Critical values","text":"critical values Z values used determine confidence interval population mean normal distribution. confidence interval range values within population mean likely fall, given certain confidence level.normal distribution, critical values Z 90% confidence interval -1.645 1.645. 95% confidence interval, -1.96 1.96, 99% confidence interval, -2.575 2.575.critical values generated? quick intuition. First, let’s reprint sum_total_winnings z_score_wininigs 90%, 95%, 99% quantiles. , take closer look z_score_wininigs’ quantiles. intervals look similar critical values.","code":"\n# Use the quantile() function to compute the quantiles for sum_total_winnings\nquantile(sum_total_winnings, probs = c(0.005, 0.025, 0.05, 0.95, 0.975, 0.995))\n#>  0.5%  2.5%    5%   95% 97.5% 99.5% \n#> -1400  -950  -725  1975  2200  2650\n\n# Use the quantile() function to compute the quantiles for z_score_wininigs\nquantile(z_score_wininigs, probs = c(0.005, 0.025, 0.05, 0.95, 0.975, 0.995))\n#>      0.5%      2.5%        5%       95%     97.5%     99.5% \n#> -2.516156 -1.953012 -1.671440  1.707424  1.988996  2.552140"},{"path":"confidence-interval-z-scores-hypothesis-testing.html","id":"hypothesis-testing-with-z-score","chapter":"Lecture 11 Confidence interval, z-scores, hypothesis testing","heading":"11.6 Hypothesis testing with z-score","text":"Hypothesis testing statistical procedure used determine whether sufficient evidence sample data infer certain relationship difference two population characteristics. hypothesis testing, researcher first states hypothesis. hypothesis may based previous research existing theories, may new idea researcher wants test. Next, researcher collects sample data uses statistical tests evaluate strength evidence sample support hypothesis. evidence strong enough, researcher can reject null hypothesis conclude alternative hypothesis true. Hypothesis testing important tool statistical analysis, allows researchers draw conclusions population characteristics based sample data. testing hypotheses, researchers can gain insight relationships variables make informed decisions based evidence.case, like test hypothesis average winnings zero. One way look 95% confidence interval quickly. 95% confidence interval winnings :check zero exists lower bound -950 upper bound 2200 . zero exits, average winnings likely zero. Unfortunately, ’s case.Alternatively, can formally test z-scores 0 sum_total_winnings. idea ask much standard deviation zero away mean sum_total_winnings.\\[Z = \\frac{0-\\bar{x}}{\\sigma}\\]examine zscore_0, value -0.764152, ranges 95% critical value -1.96 1.96. suggests average winnings can zero.","code":"\nci <- quantile(sum_total_winnings, probs = c(0.025, 0.975))\nci\n#>  2.5% 97.5% \n#>  -950  2200\nzscore_0 <- (0-mean(sum_total_winnings))/sd(sum_total_winnings)\n\nzscore_0\n#> [1] -0.764152"},{"path":"unconstrainted-optimization.html","id":"unconstrainted-optimization","chapter":"Lecture 12 Unconstrainted optimization","heading":"Lecture 12 Unconstrainted optimization","text":"calculus, optimization process finding maximum minimum value function. often done using techniques calculus, taking derivatives using first second derivative test.derivative function measure rate change can used identify local maxima minima function. example, derivative function positive certain point, indicates function increasing point may local minimum nearby. Similarly, derivative negative certain point, indicates function decreasing point may local maximum nearby.using derivatives identify local maxima minima, can find values function give maximum minimum output. useful many applications, finding maximum profit business, minimum amount time complete task, maximum likelihood statistical model.summary, optimization using derivatives process using calculus find maximum minimum value function. taking derivatives using first second derivative test, can identify points function local maximum minimum find values give maximum minimum output.examples explore lecture called unconstrained optimization. Unconstrained optimization type optimization problem constraints solution. words, solution can take value maximizes minimizes objective function without constraints.Unconstrained optimization problems typically simpler constrained optimization problems since constraints consider finding optimal solution.","code":""},{"path":"unconstrainted-optimization.html","id":"example-with-bivariate-quadratic-function","chapter":"Lecture 12 Unconstrainted optimization","heading":"12.1 Example with bivariate quadratic function","text":"quadratic function polynomial function form f(x) = ax^2 + bx + c, , b, c constants. quadratic function can maximum minimum value depending values , b, c.example using derivatives optimize quadratic function. ’s called analytical approach. example, suppose following quadratic function:\\[ y = f(x) = x^2 - 4x + 3 \\]find maximum minimum value function, can take derivative set equal 0:\\[ f'(x) = \\frac{\\partial y}{\\partial x} = 2x - 4 = 0 \\]Solving equation, find derivative 0 \\(x = 2\\). indicates function local maximum minimum \\(x = 2\\).determine whether function maximum minimum point, can take second derivative function evaluate \\(x = 2\\):\\[ f''(x) = \\frac{\\partial^2 y}{\\partial x^2} = 2 \\]Evaluating \\(x = 2\\), get \\(f''(2) = 2\\). Since second derivative positive point, indicates function local minimum \\(x = 2\\).Therefore, find minimum value quadratic function, can substitute \\(x = 2\\) original function get:\\[ f(2) = 2^2 - 4 \\cdot 2 + 3 = -1 \\]Thus, minimum value function 1, achieved \\(x = 2\\).example, used derivatives find minimum value quadratic function. taking first second derivatives function setting equal 0, able identify points function local minimum find values give minimum output.","code":""},{"path":"unconstrainted-optimization.html","id":"example-with-r-codes","chapter":"Lecture 12 Unconstrainted optimization","heading":"12.1.1 Example with R codes","text":"Let’s first define function R.function, given value \\(x\\), can generate value \\(y\\). example value x = 40 \\(y=f(x)=f(40)=40^2 - 4*40 + 3\\) equates 1443.Let’s plot function, sequences x value ranging -5 +5 0.1.Now Lets evaluate function plot.code creates sequence x values -10 10, step size 0.01. evaluates function x value plots resulting y values. resulting plot look like thisThe plot shows function minimum around x = 2, found using derivatives earlier. can also see function symmetric around x = 1, x-coordinate vertex parabola (point parabola changes direction).","code":"\n# Define the function\nf <- function(x) {\n  y <- x^2 - 4*x + 3\n  return(y)\n}\nvalue_of_y <- f(x = 40)\n# Create a sequence of x values from -10 to 10\nx <- seq(-5, 5, by = 0.1)\nx\n#>   [1] -5.0 -4.9 -4.8 -4.7 -4.6 -4.5 -4.4 -4.3 -4.2 -4.1 -4.0\n#>  [12] -3.9 -3.8 -3.7 -3.6 -3.5 -3.4 -3.3 -3.2 -3.1 -3.0 -2.9\n#>  [23] -2.8 -2.7 -2.6 -2.5 -2.4 -2.3 -2.2 -2.1 -2.0 -1.9 -1.8\n#>  [34] -1.7 -1.6 -1.5 -1.4 -1.3 -1.2 -1.1 -1.0 -0.9 -0.8 -0.7\n#>  [45] -0.6 -0.5 -0.4 -0.3 -0.2 -0.1  0.0  0.1  0.2  0.3  0.4\n#>  [56]  0.5  0.6  0.7  0.8  0.9  1.0  1.1  1.2  1.3  1.4  1.5\n#>  [67]  1.6  1.7  1.8  1.9  2.0  2.1  2.2  2.3  2.4  2.5  2.6\n#>  [78]  2.7  2.8  2.9  3.0  3.1  3.2  3.3  3.4  3.5  3.6  3.7\n#>  [89]  3.8  3.9  4.0  4.1  4.2  4.3  4.4  4.5  4.6  4.7  4.8\n#> [100]  4.9  5.0\n# Evaluate the function at each x value\ny <- f(x)\n\ny\n#>   [1] 48.00 46.61 45.24 43.89 42.56 41.25 39.96 38.69 37.44\n#>  [10] 36.21 35.00 33.81 32.64 31.49 30.36 29.25 28.16 27.09\n#>  [19] 26.04 25.01 24.00 23.01 22.04 21.09 20.16 19.25 18.36\n#>  [28] 17.49 16.64 15.81 15.00 14.21 13.44 12.69 11.96 11.25\n#>  [37] 10.56  9.89  9.24  8.61  8.00  7.41  6.84  6.29  5.76\n#>  [46]  5.25  4.76  4.29  3.84  3.41  3.00  2.61  2.24  1.89\n#>  [55]  1.56  1.25  0.96  0.69  0.44  0.21  0.00 -0.19 -0.36\n#>  [64] -0.51 -0.64 -0.75 -0.84 -0.91 -0.96 -0.99 -1.00 -0.99\n#>  [73] -0.96 -0.91 -0.84 -0.75 -0.64 -0.51 -0.36 -0.19  0.00\n#>  [82]  0.21  0.44  0.69  0.96  1.25  1.56  1.89  2.24  2.61\n#>  [91]  3.00  3.41  3.84  4.29  4.76  5.25  5.76  6.29  6.84\n#> [100]  7.41  8.00\n# Plot the function\nplot(x, y, type = \"l\", col = \"blue\", xlab = \"x\", ylab = \"f(x)\")\n\n# Add a point at the minimum of the function\npoints(2, -1, col = \"red\", pch = 16)"},{"path":"unconstrainted-optimization.html","id":"example-with-multivariate-quadratic-function","chapter":"Lecture 12 Unconstrainted optimization","heading":"12.2 Example with multivariate quadratic function","text":"multivariate optimization problem involves finding optimal values multiple variables (case, x z) minimize maximize given objective function (case, f(x, z)). words, goal find values x z produce best result plugged objective function.example using derivatives optimize multivariate function. Suppose following function:\\[ f(x, z) = x^2 + z^2 - 4xz + 3 \\]find maximum minimum value function, can take partial derivatives respect variable set equal 0:\\[ \\frac{\\partial f}{\\partial x} = 2x - 4z = 0 \\]\\[ \\frac{\\partial f}{\\partial z} = 2z - 4x = 0 \\]Solving equations, find partial derivatives 0 \\(x = z = 2\\). indicates function local maximum minimum coordinates.determine whether function maximum minimum point, can take second partial derivatives function evaluate \\(x = z = 2\\):\n\\[ \\frac{\\partial^2 f}{\\partial x^2} = 2 \\]\\[ \\frac{\\partial^2 f}{\\partial z^2} = 2 \\]\\[ \\frac{\\partial^2 f}{\\partial x \\partial z} = -4 \\]Evaluating \\(x = z = 2\\), get:\\[ \\frac{\\partial^2 f}{\\partial x^2} = 2 \\]\\[ \\frac{\\partial^2 f}{\\partial z^2} = 2 \\]\\[ \\frac{\\partial^2 f}{\\partial x \\partial z} = -4 \\]can use values compute Hessian matrix function point, given :\\[ H = \\begin{bmatrix} \\frac{\\partial^2 f}{\\partial x^2} & \\frac{\\partial^2 f}{\\partial x \\partial z} \\\\ \\frac{\\partial^2 f}{\\partial z \\partial x} & \\frac{\\partial^2 f}{\\partial z^2} \\end{bmatrix} = \\begin{bmatrix} 2 & -4 \\\\ -4 & 2 \\end{bmatrix} \\]Hessian matrix square matrix used multivariate optimization approximate behavior function near given point. particular, Hessian matrix used determine local curvature function, can help identify location local minimum maximum. example, Hessian matrix positive definite given point, indicates function locally convex point, means local minimum vicinity. hand, Hessian matrix negative definite given point, indicates function locally concave, means local maximum vicinity.Hessian matrix matrix second-order partial derivatives can used determine nature local maximum minimum given point. case, Hessian matrix negative definite determinant \\(H\\) \\(2(2)-(-4)(-4) = 4-16=-12\\).","code":""},{"path":"unconstrainted-optimization.html","id":"example-with-r-codes-1","chapter":"Lecture 12 Unconstrainted optimization","heading":"12.2.1 Example with R codes","text":"code defines function f() takes two inputs, x z, returns value \\(x^2 + z^2 - 4*x*z + 3\\).xaxis yaxis vectors created using : operator generate sequence numbers -5 5. creates two vectors length 11 values ranging -5 5, inclusive.zaxis vector computed applying f() function combination x z values xaxis yaxis, respectively. done using outer() function, applies function combinations elements two input vectors. case, outer() used apply f() function combination x z values xaxis yaxis, respectively.result two-dimensional array (matrix) values, ith row jth column containing value f(x = xaxis[], z = yaxis[j]). array assigned zaxis.Think zaxis comprises. First values value z-axis (y-variable) xaxis -5 5, holding value yaxis constant, like partial derivative \\(\\frac{\\partial y}{\\partial x}|_{z}\\). Second, values value z-axis yaxis -5 5, holding value xaxis constant, like partial derivative \\(\\frac{\\partial y}{\\partial z}|_{x}\\).Next, plot3D library loaded, 3D perspective plot created using values zaxis, xaxis, yaxis z, x, y coordinates, respectively. plot rotated 30 degrees along x y axes, box drawn around plot slight shading. contour lines drawn, axes displayed.plot, can visually see minimum value function \\(y = x^2 + z^2 - 4*x*z + 3\\). \\(x=2\\) \\(z=2\\), function minimum value \\(y = 2^2 + 2^2 - 4*2*2 + 3 = -5\\).Let’s examine plot different camera angles.","code":"\nf <- function(x, z){\n  return(x^2 + z^2 - 4*x*z + 3)\n}\nxaxis <- -5:5\nyaxis <- -5:5\nzaxis <- outer(xaxis, yaxis, f)\nzaxis\n#>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n#>  [1,]  -47  -36  -23   -8    9   28   49   72   97   124\n#>  [2,]  -36  -29  -20   -9    4   19   36   55   76    99\n#>  [3,]  -23  -20  -15   -8    1   12   25   40   57    76\n#>  [4,]   -8   -9   -8   -5    0    7   16   27   40    55\n#>  [5,]    9    4    1    0    1    4    9   16   25    36\n#>  [6,]   28   19   12    7    4    3    4    7   12    19\n#>  [7,]   49   36   25   16    9    4    1    0    1     4\n#>  [8,]   72   55   40   27   16    7    0   -5   -8    -9\n#>  [9,]   97   76   57   40   25   12    1   -8  -15   -20\n#> [10,]  124   99   76   55   36   19    4   -9  -20   -29\n#> [11,]  153  124   97   72   49   28    9   -8  -23   -36\n#>       [,11]\n#>  [1,]   153\n#>  [2,]   124\n#>  [3,]    97\n#>  [4,]    72\n#>  [5,]    49\n#>  [6,]    28\n#>  [7,]     9\n#>  [8,]    -8\n#>  [9,]   -23\n#> [10,]   -36\n#> [11,]   -47\n\nlibrary(plot3D)\n#> Warning: package 'plot3D' was built under R version 4.0.5\npersp3D(\n  z = zaxis,\n  x = xaxis,\n  y = yaxis,\n  phi = 30,\n  theta = 30,\n  box = TRUE,\n  border = NA,\n  shade = .1,\n  expand = 0.6,\n  contour = F,\n  axes = TRUE\n)\npar(mfrow = c(2, 2), mai = c(1, 0.1, 0.1, 0.1))\npersp3D(z = zaxis, x = xaxis, y = yaxis, \n        phi = 10, \n        theta = 50, \n        box = TRUE, border = NA, shade = .1, expand = 0.6, contour = F)\n\npersp3D(z = zaxis, x = xaxis, y = yaxis, \n        phi = 10, \n        theta = 30, \n        box = TRUE, border = NA, shade = .1, expand = 0.6, contour = F)\n\npersp3D(z = zaxis, x = xaxis, y = yaxis, \n        phi = 30, \n        theta = 30, \n        box = TRUE, border = NA, shade = .1, expand = 0.6, contour = F)\n\npersp3D(z = zaxis, x = xaxis, y = yaxis, \n        phi = 50, \n        theta = 30, \n        box = TRUE, border = NA, shade = .1, expand = 0.6, contour = F)\npar(mfrow = c(1, 1))"},{"path":"unconstrainted-optimization.html","id":"exercise-3","chapter":"Lecture 12 Unconstrainted optimization","heading":"12.3 Exercise","text":"Show analytic solution minima \\(f(x) = -18x^2 +180x + 10\\) show graphical illustration using R codes.Find optimal solution \\(y = -4x^2 + -6z^2 - 3*x*z + 3\\) show graphical illustration using R codes.","code":""},{"path":"gradient-descent.html","id":"gradient-descent","chapter":"Lecture 13 Gradient descent","heading":"Lecture 13 Gradient descent","text":"","code":""},{"path":"gradient-descent.html","id":"intution","chapter":"Lecture 13 Gradient descent","heading":"13.1 Intution","text":"Gradient descent iterative optimization algorithm used find function’s “minimum” value taking small steps direction opposite gradient (slope) function current position.Let give intuitive example.Given function, first, analytically find gradient. example, given function \\(y = f(x) = 2x^2 - 8x + 3\\), gradient \\(f'(x) = 4x - 8\\).Given function, first, analytically find gradient. example, given function \\(y = f(x) = 2x^2 - 8x + 3\\), gradient \\(f'(x) = 4x - 8\\).Calculate gradient function initial guess. Guess can number. matter. Usually, start zero. let’s evaluate gradient 0. \\(f'(x_0 = 0) = 4x - 8 = 4(0) - 8 = -8\\).Calculate gradient function initial guess. Guess can number. matter. Usually, start zero. let’s evaluate gradient 0. \\(f'(x_0 = 0) = 4x - 8 = 4(0) - 8 = -8\\).want learn gradient. much want learn defined learning rate parameter. example, let’s define learning parameter \\(\\alpha = 0.01\\). learn say \\(\\alpha f'(x_0 = 0)\\) = \\(0.01 (-8) = -0.08\\).want learn gradient. much want learn defined learning rate parameter. example, let’s define learning parameter \\(\\alpha = 0.01\\). learn say \\(\\alpha f'(x_0 = 0)\\) = \\(0.01 (-8) = -0.08\\).Now, update value initial guess 0 learn. Thus new guess say, \\(x_1\\), \\(x_1 = x_0 - \\alpha f'(x_0 = 0)\\). example, \\(x_1 = 0-(-0.08) = 0.08\\). Note gradient decreasing, opposite– increase value x. gradient positive increasing, opposite– decrease value x.Now, update value initial guess 0 learn. Thus new guess say, \\(x_1\\), \\(x_1 = x_0 - \\alpha f'(x_0 = 0)\\). example, \\(x_1 = 0-(-0.08) = 0.08\\). Note gradient decreasing, opposite– increase value x. gradient positive increasing, opposite– decrease value x.Next, calculate function’s gradient using \\(x_1\\) \\(f'(x_0 = 0) = 4(0.08) - 8 = -7.68\\). update value \\(x_1\\) \\(x_2\\) \\(x_2 = x_1 - \\alpha f'(x_1 = 0.01)\\) \\(x_2 = 0.08 - 0.01(-7.68) = 0.157\\).Next, calculate function’s gradient using \\(x_1\\) \\(f'(x_0 = 0) = 4(0.08) - 8 = -7.68\\). update value \\(x_1\\) \\(x_2\\) \\(x_2 = x_1 - \\alpha f'(x_1 = 0.01)\\) \\(x_2 = 0.08 - 0.01(-7.68) = 0.157\\).iterate process long time, say 1000 times, enables us find value \\(x\\) minimizes function \\(y = f(x) = 2x^2 - 8x + 3\\).iterate process long time, say 1000 times, enables us find value \\(x\\) minimizes function \\(y = f(x) = 2x^2 - 8x + 3\\).","code":""},{"path":"gradient-descent.html","id":"gradient-descent-using-for-loop-in-r-codes","chapter":"Lecture 13 Gradient descent","heading":"13.2 Gradient descent using “for loop” in R codes","text":"Let’s first define function gradient function.Now, define three criteria. First initialization value. choose \\(x = 0\\). Second learning rate. choose 0.01. Third many time want iterate , say 1000 times.Now, information, let’s implement gradient descent. suppressing results table print 1000 rows x values. better way . show latter. use code, simply un-comment print(x).running algorithm, just simply check value x, find answer x.","code":"\n# Define the function\nf = function(x) {\n  return(2*x^2 - 8*x + 3)\n}\n\n# Define the gradient of the function\nf_grad = function(x) {\n  return(4*x - 8)\n}\n# Set the initial value of x\nx = 0\n\n# Set the learning rate\nalpha = 0.01\n\n# Set the number of iterations\nn_iter = 1000\n# Perform gradient descent\nfor (i in 1:n_iter) {\n  x = x - alpha * f_grad(x)\n  #print(x)\n}\n# Print the final value of x\nprint(x)\n#> [1] 2"},{"path":"gradient-descent.html","id":"gradient-descent-using-while-in-r-codes","chapter":"Lecture 13 Gradient descent","heading":"13.3 Gradient descent using “while” in R codes","text":"Lets use conditional statement implement loop. similar set .However, want initialize iteration 0. also want set tolerance error, say 0.1. means okay gradient near 0.1 rather perfectly zero.Next, use statement. R, statement used execute block code repeatedly long specified condition true. condition expression evaluated iteration loop. condition evaluates TRUE, code within loop executed. condition evaluates FALSE, loop terminated, control passed next statement loop.case, n_iter < max_iter, calculate gradient function. absolute value gradient function less tolerance error, case 0.1, stop break loop.","code":"\n# Define the function\nf = function(x) {\n  return(2*x^2 - 8*x + 3)\n}\n\n# Define the gradient of the function\nf_grad = function(x) {\n  return(4*x - 8)\n}\n\n# Set the initial value of x\nx = 0\n\n# Set the learning rate\nalpha = 0.1\n\n# Set the maximum number of iterations\nmax_iter = 1000\n# Set the tolerance\ntol = 0.1\n\n# Initialize the number of iterations\nn_iter = 0\n# Perform gradient descent\nwhile (n_iter < max_iter) {\n  # Calculate the gradient of the function\n  grad = f_grad(x)\n  \n  # Check if the gradient is below the tolerance\n  if (abs(grad) < tol) {\n    #print(\"converged!\")\n    break\n  }\n  \n  # Update the value of x\n  x = x - alpha * grad\n  \n  # Increment the number of iterations\n  n_iter = n_iter + 1\n  \n  print(paste0(n_iter,\" \", x))\n}\n#> [1] \"1 0.8\"\n#> [1] \"2 1.28\"\n#> [1] \"3 1.568\"\n#> [1] \"4 1.7408\"\n#> [1] \"5 1.84448\"\n#> [1] \"6 1.906688\"\n#> [1] \"7 1.9440128\"\n#> [1] \"8 1.96640768\"\n#> [1] \"9 1.979844608\"\n\n# Print the final value of x\n#print(x)"},{"path":"gradient-descent.html","id":"exercise-4","chapter":"Lecture 13 Gradient descent","heading":"13.4 Exercise","text":"want play parameters, change initial value 5 -1, see can get results. Next, change learning rate 0.01 0.1 0.001. Examine converge find answer. Try changing number iterations well. Explain understanding.determine got correct solution ? example, can adjust code exhibit prompt “solution doesnot converge, please adjust either intialization learning rate iteration.”","code":""},{"path":"gradient-descent-for-more-than-one-variable.html","id":"gradient-descent-for-more-than-one-variable","chapter":"Lecture 14 Gradient descent for more than one variable","heading":"Lecture 14 Gradient descent for more than one variable","text":"","code":""},{"path":"gradient-descent-for-more-than-one-variable.html","id":"intution-1","chapter":"Lecture 14 Gradient descent for more than one variable","heading":"14.1 Intution","text":"Now use gradient descent optimize one variable. Let’s begin two variable set .Consider following function \\[z = x^2 + 2y^2 + 2xy + 2x + 8y + 10\\].Consider following function \\[z = x^2 + 2y^2 + 2xy + 2x + 8y + 10\\].first find gradients \\[f'_{x} = \\frac{\\partial z}{\\partial x} = 2x + 2y + 2\\] \\[f'_{y} = \\frac{\\partial z}{\\partial y} =  4y+2x+8\\]first find gradients \\[f'_{x} = \\frac{\\partial z}{\\partial x} = 2x + 2y + 2\\] \\[f'_{y} = \\frac{\\partial z}{\\partial y} =  4y+2x+8\\]Now want use initial values \\(x_0 = 0\\) \\(y_0 = 0\\) evaluate \\[f'_{x} = 2x + 2y + 2 = 2(0)+2(0)+2 = 2\\] \\[f'_{y} = 4y+2x+8 = 4(0)+2(0)+8 = 8\\]Now want use initial values \\(x_0 = 0\\) \\(y_0 = 0\\) evaluate \\[f'_{x} = 2x + 2y + 2 = 2(0)+2(0)+2 = 2\\] \\[f'_{y} = 4y+2x+8 = 4(0)+2(0)+8 = 8\\]Now learn gradients say, learning parameter \\(\\alpha =0.1\\) \\[x_1 = x_0 - \\alpha f'_{x} = 0 - 0.1(2) = -0.2\\] \\[y_1 = y_0 - \\alpha f'_{y} = 0-0.1(8) = -0.8\\]Now learn gradients say, learning parameter \\(\\alpha =0.1\\) \\[x_1 = x_0 - \\alpha f'_{x} = 0 - 0.1(2) = -0.2\\] \\[y_1 = y_0 - \\alpha f'_{y} = 0-0.1(8) = -0.8\\]Now use updated value \\(x_1\\) \\(y_1\\), calculate gradient \\(f'_{x}\\) \\(f'_{y}\\), learn gradients \\(x_1 = x_0 - \\alpha f'_{x}\\) \\(y_1 = y_0 - \\alpha f'_{y}\\), converge solution.Now use updated value \\(x_1\\) \\(y_1\\), calculate gradient \\(f'_{x}\\) \\(f'_{y}\\), learn gradients \\(x_1 = x_0 - \\alpha f'_{x}\\) \\(y_1 = y_0 - \\alpha f'_{y}\\), converge solution.","code":""},{"path":"gradient-descent-for-more-than-one-variable.html","id":"rcodes","chapter":"Lecture 14 Gradient descent for more than one variable","heading":"14.2 Rcodes","text":"Let show R codes .code defines function called f takes two arguments, x y, returns value expression z defined within function. expression z quadratic function x y form \\(z = ax^2 + ^2 + cxy + dx + ey + f\\), , b, c, d, e, f constants. particular case, values constants = 1, b = 2, c = 2, d = 2, e = 8, f = 10. means function f return value z given values x y passed argumentsFor example, call function f arguments x = 2 y = 3, return value z corresponds values, \\(z = 1 * 2^2 + 2 * 3^2 + 2 * 2 * 3 + 2 * 2 + 8 * 3 + 10 = 60\\).Now lets define gradients descent.code defines function called gradient_descent implements gradient descent algorithm optimizing function two variables. function takes three arguments: x, y, learning_rate. values x y starting values optimization, learning_rate parameter controls step size algorithm.function first calculates gradient function f(x, y) respect x y, using formula partial derivative function. gradient function tells us function changes vary input values, useful quantity optimization indicates direction function increasing decreasing. case, gradient calculated using values constants definition f(x, y) given previous answer.gradient calculated, function updates values x y using gradient learning rate. core step gradient descent algorithm, move direction gradient find minimum value function. updated values x y returned function.Now let’s initialize x y zero learning rate 0.1.code first sets initial values x y 0. sets learning rate, parameter controls step size gradient descent algorithm. case, learning rate set 0.1.code uses gradient_descent function defined previously answer find minimum value function f(x, y). running gradient descent algorithm fixed number iterations, say 500 iterations, starting initial values x y set beginning code.code runs gradient descent algorithm 500 iterations. done using loop calls gradient_descent function iteration, passing current values x y arguments. gradient_descent function returns updated values x y, assigned variables x y loop.iteration, code prints iteration number, value x, value y console. allows us see values x y change course optimization.given function \\(z = x^2 + 2y^2 + 2xy + 2x + 8y + 10\\), value \\(x\\) 2 \\(y\\) -3 minimizes function. minimum value function zero.Let’s plot function.","code":"\n# define the function f(x, y)\nf <- function(x, y) {\n  # define the function\n  z <- x^2 + 2*y^2 + 2 * x * y + 2 * x + 8 * y + 10\n  # return the function value\n  return(z)\n}\nf(x = 2, y = 3)\n#> [1] 72\n# define the gradient descent algorithm\ngradient_descent <- function(x, y, learning_rate) {\n  # calculate the gradient of f(x, y) with respect to x\n  gradient_x <- 2 * x + 2 * y + 2\n  # calculate the gradient of f(x, y) with respect to y\n  gradient_y <- 4 * y + 2 * x + 8\n  # update the value of x using the gradient and the learning rate\n  x <- x - learning_rate * gradient_x\n  # update the value of y using the gradient and the learning rate\n  y <- y - learning_rate * gradient_y\n  # return the updated values of x and y\n  return(c(x, y))\n}\n# set the initial values of x and y\nx <- 0\ny <- 0\n\n# set the learning rate\nlearning_rate <- 0.1\n# run the gradient descent algorithm for 10 iterations\nfor (i in 1:500) {\n  c <- gradient_descent(x, y, learning_rate)\n  x <- c[1]\n  y <- c[2]\n  print(paste0(i, \" \", x, \" \", y))\n}\n#> [1] \"1 -0.2 -0.8\"\n#> [1] \"2 -0.2 -1.24\"\n#> [1] \"3 -0.112 -1.504\"\n#> [1] \"4 0.0112 -1.68\"\n#> [1] \"5 0.14496 -1.81024\"\n#> [1] \"6 0.278016 -1.915136\"\n#> [1] \"7 0.40544 -2.0046848\"\n#> [1] \"8 0.52528896 -2.08389888\"\n#> [1] \"9 0.637010944 -2.15539712\"\n#> [1] \"10 0.7406881792 -2.2206404608\"\n#> [1] \"11 0.83667863552 -2.28052191232\"\n#> [1] \"12 0.92544729088 -2.335648874496\"\n#> [1] \"13 1.0074876076032 -2.3864787828736\"\n#> [1] \"14 1.08328584265728 -2.4333847912448\"\n#> [1] \"15 1.15330563237478 -2.47668804327834\"\n#> [1] \"16 1.21798211455549 -2.51667395244196\"\n#> [1] \"17 1.27772048213279 -2.55360079437627\"\n#> [1] \"18 1.33289654458148 -2.58770457305232\"\n#> [1] \"19 1.38385815027565 -2.61920205274769\"\n#> [1] \"20 1.43092693077006 -2.64829286170374\"\n#> [1] \"21 1.4744001169568 -2.67516110317626\"\n#> [1] \"22 1.51455231420069 -2.69997668529711\"\n#> [1] \"23 1.55163718841997 -2.72289647401841\"\n#> [1] \"24 1.58588904553966 -2.74406532209504\"\n#> [1] \"25 1.61752430085074 -2.76361700236496\"\n#> [1] \"26 1.64674284115358 -2.78167506158912\"\n#> [1] \"27 1.67372928524069 -2.79835360518419\"\n#> [1] \"28 1.69865414922939 -2.81375802015865\"\n#> [1] \"29 1.72167492341524 -2.82798564194107\"\n#> [1] \"30 1.74293706712041 -2.84112636984769\"\n#> [1] \"31 1.76257492766586 -2.85326323533269\"\n#> [1] \"32 1.78071258919923 -2.86447292673279\"\n#> [1] \"33 1.79746465670594 -2.87482627387952\"\n#> [1] \"34 1.81293698014066 -2.8843886956689\"\n#> [1] \"35 1.82722732324631 -2.89322061342947\"\n#> [1] \"36 1.84042598128294 -2.90137783270694\"\n#> [1] \"37 1.85261635156774 -2.90891189588075\"\n#> [1] \"38 1.86387546043034 -2.915870407842\"\n#> [1] \"39 1.87427444991267 -2.92229733679127\"\n#> [1] \"40 1.88387902728839 -2.9282332920573\"\n#> [1] \"41 1.89274988024217 -2.93371578069206\"\n#> [1] \"42 1.90094306033215 -2.93877944446367\"\n#> [1] \"43 1.90851033715845 -2.94345627874463\"\n#> [1] \"44 1.91549952547569 -2.94777583467847\"\n#> [1] \"45 1.92195478731625 -2.95176540590222\"\n#> [1] \"46 1.92791691103344 -2.95545020100458\"\n#> [1] \"47 1.93342356902767 -2.95885350280944\"\n#> [1] \"48 1.93850955578402 -2.9619968154912\"\n#> [1] \"49 1.94320700772546 -2.96490000045152\"\n#> [1] \"50 1.94754560627067 -2.967581401816\"\n#> [1] \"51 1.95155276537974 -2.97005796234374\"\n#> [1] \"52 1.95525380477254 -2.97234533048219\"\n#> [1] \"53 1.95867210991447 -2.97445795924382\"\n#> [1] \"54 1.96182927978034 -2.97640919752919\"\n#> [1] \"55 1.96474526333011 -2.97821137447358\"\n#> [1] \"56 1.9674384855588 -2.97987587735017\"\n#> [1] \"57 1.96992596391708 -2.98141322352186\"\n#> [1] \"58 1.97222341583803 -2.98283312689653\"\n#> [1] \"59 1.97434535804973 -2.98414455930553\"\n#> [1] \"60 1.97630519830089 -2.98535580719326\"\n#> [1] \"61 1.97811532007937 -2.98647452397614\"\n#> [1] \"62 1.97978716085872 -2.98750777840155\"\n#> [1] \"63 1.98133128436729 -2.98846209921268\"\n#> [1] \"64 1.98275744733636 -2.98934351640106\"\n#> [1] \"65 1.9840746611493 -2.99015759930791\"\n#> [1] \"66 1.98529124878103 -2.99090949181461\"\n#> [1] \"67 1.98641489738774 -2.99160394484497\"\n#> [1] \"68 1.98745270687919 -2.99224534638453\"\n#> [1] \"69 1.98841123478026 -2.99283774920656\"\n#> [1] \"70 1.98929653766552 -2.99338489647998\"\n#> [1] \"71 1.99011420942841 -2.99389024542109\"\n#> [1] \"72 1.99086941662695 -2.99435698913834\"\n#> [1] \"73 1.99156693112923 -2.99478807680839\"\n#> [1] \"74 1.99221116026506 -2.99518623231088\"\n#> [1] \"75 1.99280617467422 -2.99555397143954\"\n#> [1] \"76 1.99335573402729 -2.99589361779857\"\n#> [1] \"77 1.99386331078154 -2.9962073174846\"\n#> [1] \"78 1.99433211212215 -2.99649705264707\"\n#> [1] \"79 1.99476510022714 -2.99676465401267\"\n#> [1] \"80 1.99516501098424 -2.99701181245303\"\n#> [1] \"81 1.995534371278 -2.99724008966867\"\n#> [1] \"82 1.99587551495613 -2.9974509280568\"\n#> [1] \"83 1.99619059757627 -2.99764565982531\"\n#> [1] \"84 1.99648161002608 -2.99782551541044\"\n#> [1] \"85 1.99675039110295 -2.99799163125148\"\n#> [1] \"86 1.99699863913265 -2.99814505697148\"\n#> [1] \"87 1.99722792270042 -2.99828676200942\"\n#> [1] \"88 1.99743969056222 -2.99841764174573\"\n#> [1] \"89 1.99763528079892 -2.99853852315988\"\n#> [1] \"90 1.99781592927111 -2.99865017005571\"\n#> [1] \"91 1.99798277742803 -2.99875328788765\"\n#> [1] \"92 1.99813687951996 -2.9988485282182\"\n#> [1] \"93 1.99827920925961 -2.99893649283491\"\n#> [1] \"94 1.99841066597467 -2.99901773755287\"\n#> [1] \"95 1.99853208029031 -2.99909277572665\"\n#> [1] \"96 1.99864421937758 -2.99916208149405\"\n#> [1] \"97 1.99874779180087 -2.99922609277195\"\n#> [1] \"98 1.99884345199509 -2.99928521402334\"\n#> [1] \"99 1.99893180440074 -2.99933981881302\"\n#> [1] \"100 1.99901340728319 -2.99939025216796\"\n#> [1] \"101 1.99908877626015 -2.99943683275742\"\n#> [1] \"102 1.9991583875596 -2.99947985490648\"\n#> [1] \"103 1.99922268102898 -2.99951959045581\"\n#> [1] \"104 1.99928206291434 -2.99955629047928\"\n#> [1] \"105 1.99933690842733 -2.99959018687044\"\n#> [1] \"106 1.99938756411595 -2.99962149380773\"\n#> [1] \"107 1.99943435005431 -2.99965040910783\"\n#> [1] \"108 1.99947756186501 -2.99967711547556\"\n#> [1] \"109 1.99951747258712 -2.99970178165834\"\n#> [1] \"110 1.99955433440136 -2.99972456351243\"\n#> [1] \"111 1.99958838022358 -2.99974560498773\"\n#> [1] \"112 1.99961982517641 -2.99976503903735\"\n#> [1] \"113 1.9996488679486 -2.99978298845769\"\n#> [1] \"114 1.99967569205042 -2.99979956666433\"\n#> [1] \"115 1.9997004669732 -2.99981487840868\"\n#> [1] \"116 1.9997233492603 -2.99982902043985\"\n#> [1] \"117 1.99974448349621 -2.99984208211597\"\n#> [1] \"118 1.99976400322016 -2.99985414596882\"\n#> [1] \"119 1.99978203176989 -2.99986528822533\"\n#> [1] \"120 1.99979868306098 -2.99987557928917\"\n#> [1] \"121 1.99981406230662 -2.9998850841857\"\n#> [1] \"122 1.99982826668243 -2.99989386297274\"\n#> [1] \"123 1.9998413859405 -2.99990197112013\"\n#> [1] \"124 1.99985350297642 -2.99990945986018\"\n#> [1] \"125 1.99986469435317 -2.99991637651139\"\n#> [1] \"126 1.99987503078482 -2.99992276477747\"\n#> [1] \"127 1.99988457758335 -2.99992866502345\"\n#> [1] \"128 1.99989339507137 -2.99993411453074\"\n#> [1] \"129 1.99990153896324 -2.99993914773272\"\n#> [1] \"130 1.99990906071714 -2.99994379643228\"\n#> [1] \"131 1.99991600786016 -2.99994809000279\"\n#> [1] \"132 1.99992242428869 -2.99995205557371\"\n#> [1] \"133 1.99992835054569 -2.99995571820196\"\n#> [1] \"134 1.99993382407695 -2.99995910103032\"\n#> [1] \"135 1.99993887946762 -2.99996222543358\"\n#> [1] \"136 1.99994354866081 -2.99996511115367\"\n#> [1] \"137 1.99994786115939 -2.99996777642437\"\n#> [1] \"138 1.99995184421238 -2.9999702380865\"\n#> [1] \"139 1.9999555229872 -2.99997251169437\"\n#> [1] \"140 1.99995892072864 -2.99997461161407\"\n#> [1] \"141 1.99996205890572 -2.99997655111417\"\n#> [1] \"142 1.99996495734741 -2.99997834244965\"\n#> [1] \"143 1.99996763436786 -2.99997999693927\"\n#> [1] \"144 1.99997010688214 -2.99998152503713\"\n#> [1] \"145 1.99997239051314 -2.99998293639871\"\n#> [1] \"146 1.99997449969025 -2.99998423994185\"\n#> [1] \"147 1.99997644774057 -2.99998544390316\"\n#> [1] \"148 1.99997824697309 -2.99998655589001\"\n#> [1] \"149 1.99997990875648 -2.99998758292863\"\n#> [1] \"150 1.99998144359091 -2.99998853150847\"\n#> [1] \"151 1.99998286117442 -2.99998940762326\"\n#> [1] \"152 1.99998417046419 -2.99999021680884\"\n#> [1] \"153 1.99998537973312 -2.99999096417814\"\n#> [1] \"154 1.99998649662212 -2.99999165445351\"\n#> [1] \"155 1.9999875281884 -2.99999229199653\"\n#> [1] \"156 1.99998848095003 -2.9999928808356\"\n#> [1] \"157 1.99998936092714 -2.99999342469136\"\n#> [1] \"158 1.99999017367999 -2.99999392700025\"\n#> [1] \"159 1.99999092434404 -2.99999439093615\"\n#> [1] \"160 1.99999161766246 -2.99999481943049\"\n#> [1] \"161 1.99999225801607 -2.99999521519079\"\n#> [1] \"162 1.99999284945101 -2.99999558071769\"\n#> [1] \"163 1.99999339570435 -2.99999591832081\"\n#> [1] \"164 1.99999390022764 -2.99999623013336\"\n#> [1] \"165 1.99999436620878 -2.99999651812554\"\n#> [1] \"166 1.99999479659213 -2.99999678411708\"\n#> [1] \"167 1.99999519409712 -2.99999702978868\"\n#> [1] \"168 1.99999556123543 -2.99999725669263\"\n#> [1] \"169 1.99999590032687 -2.99999746626266\"\n#> [1] \"170 1.99999621351403 -2.99999765982297\"\n#> [1] \"171 1.99999650277582 -2.99999783859659\"\n#> [1] \"172 1.99999676993997 -2.99999800371312\"\n#> [1] \"173 1.9999970166946 -2.99999815621587\"\n#> [1] \"174 1.99999724459886 -2.99999829706844\"\n#> [1] \"175 1.99999745509277 -2.99999842716084\"\n#> [1] \"176 1.99999764950639 -2.99999854731506\"\n#> [1] \"177 1.99999782906812 -2.99999865829031\"\n#> [1] \"178 1.99999799491256 -2.99999876078781\"\n#> [1] \"179 1.99999814808761 -2.9999988554552\"\n#> [1] \"180 1.99999828956113 -2.99999894289064\"\n#> [1] \"181 1.99999842022703 -2.99999902364661\"\n#> [1] \"182 1.99999854091094 -2.99999909823337\"\n#> [1] \"183 1.99999865237543 -2.99999916712221\"\n#> [1] \"184 1.99999875532479 -2.99999923074841\"\n#> [1] \"185 1.99999885040951 -2.99999928951401\"\n#> [1] \"186 1.99999893823041 -2.99999934379031\"\n#> [1] \"187 1.99999901934239 -2.99999939392027\"\n#> [1] \"188 1.99999909425796 -2.99999944022064\"\n#> [1] \"189 1.9999991634505 -2.99999948298398\"\n#> [1] \"190 1.99999922735719 -2.99999952248048\"\n#> [1] \"191 1.99999928638185 -2.99999955895973\"\n#> [1] \"192 1.99999934089743 -2.99999959265221\"\n#> [1] \"193 1.99999939124838 -2.99999962377081\"\n#> [1] \"194 1.99999943775287 -2.99999965251216\"\n#> [1] \"195 1.99999948070473 -2.99999967905787\"\n#> [1] \"196 1.99999952037536 -2.99999970357567\"\n#> [1] \"197 1.99999955701542 -2.99999972622047\"\n#> [1] \"198 1.99999959085643 -2.99999974713537\"\n#> [1] \"199 1.99999962211222 -2.99999976645251\"\n#> [1] \"200 1.99999965098028 -2.99999978429395\"\n#> [1] \"201 1.99999967764301 -2.99999980077242\"\n#> [1] \"202 1.99999970226889 -2.99999981599206\"\n#> [1] \"203 1.99999972501353 -2.99999983004901\"\n#> [1] \"204 1.99999974602062 -2.99999984303211\"\n#> [1] \"205 1.99999976542292 -2.99999985502339\"\n#> [1] \"206 1.99999978334301 -2.99999986609862\"\n#> [1] \"207 1.99999979989414 -2.99999987632777\"\n#> [1] \"208 1.99999981518086 -2.99999988577549\"\n#> [1] \"209 1.99999982929979 -2.99999989450147\"\n#> [1] \"210 1.99999984234012 -2.99999990256084\"\n#> [1] \"211 1.99999985438427 -2.99999991000453\"\n#> [1] \"212 1.99999986550832 -2.99999991687957\"\n#> [1] \"213 1.99999987578257 -2.99999992322941\"\n#> [1] \"214 1.99999988527194 -2.99999992909416\"\n#> [1] \"215 1.99999989403638 -2.99999993451088\"\n#> [1] \"216 1.99999990213128 -2.99999993951381\"\n#> [1] \"217 1.99999990960779 -2.99999994413454\"\n#> [1] \"218 1.99999991651314 -2.99999994840228\"\n#> [1] \"219 1.99999992289097 -2.999999952344\"\n#> [1] \"220 1.99999992878157 -2.99999995598459\"\n#> [1] \"221 1.99999993422218 -2.99999995934707\"\n#> [1] \"222 1.99999993924715 -2.99999996245268\"\n#> [1] \"223 1.99999994388826 -2.99999996532104\"\n#> [1] \"224 1.99999994817481 -2.99999996797027\"\n#> [1] \"225 1.99999995213391 -2.99999997041713\"\n#> [1] \"226 1.99999995579055 -2.99999997267706\"\n#> [1] \"227 1.99999995916785 -2.99999997476434\"\n#> [1] \"228 1.99999996228715 -2.99999997669218\"\n#> [1] \"229 1.99999996516816 -2.99999997847274\"\n#> [1] \"230 1.99999996782907 -2.99999998011727\"\n#> [1] \"231 1.99999997028671 -2.99999998163618\"\n#> [1] \"232 1.99999997255661 -2.99999998303905\"\n#> [1] \"233 1.99999997465309 -2.99999998433475\"\n#> [1] \"234 1.99999997658943 -2.99999998553147\"\n#> [1] \"235 1.99999997837783 -2.99999998663677\"\n#> [1] \"236 1.99999998002962 -2.99999998765763\"\n#> [1] \"237 1.99999998155522 -2.9999999886005\"\n#> [1] \"238 1.99999998296428 -2.99999998947134\"\n#> [1] \"239 1.99999998426569 -2.99999999027566\"\n#> [1] \"240 1.99999998546769 -2.99999999101854\"\n#> [1] \"241 1.99999998657786 -2.99999999170466\"\n#> [1] \"242 1.99999998760322 -2.99999999233837\"\n#> [1] \"243 1.99999998855025 -2.99999999292366\"\n#> [1] \"244 1.99999998942493 -2.99999999346425\"\n#> [1] \"245 1.99999999023279 -2.99999999396353\"\n#> [1] \"246 1.99999999097894 -2.99999999442468\"\n#> [1] \"247 1.99999999166809 -2.9999999948506\"\n#> [1] \"248 1.99999999230459 -2.99999999524398\"\n#> [1] \"249 1.99999999289247 -2.9999999956073\"\n#> [1] \"250 1.99999999343543 -2.99999999594288\"\n#> [1] \"251 1.99999999393692 -2.99999999625281\"\n#> [1] \"252 1.9999999944001 -2.99999999653907\"\n#> [1] \"253 1.99999999482789 -2.99999999680346\"\n#> [1] \"254 1.99999999522301 -2.99999999704766\"\n#> [1] \"255 1.99999999558794 -2.9999999972732\"\n#> [1] \"256 1.99999999592499 -2.99999999748151\"\n#> [1] \"257 1.99999999623629 -2.9999999976739\"\n#> [1] \"258 1.99999999652381 -2.9999999978516\"\n#> [1] \"259 1.99999999678937 -2.99999999801572\"\n#> [1] \"260 1.99999999703464 -2.99999999816731\"\n#> [1] \"261 1.99999999726117 -2.99999999830731\"\n#> [1] \"262 1.9999999974704 -2.99999999843662\"\n#> [1] \"263 1.99999999766365 -2.99999999855605\"\n#> [1] \"264 1.99999999784213 -2.99999999866636\"\n#> [1] \"265 1.99999999800697 -2.99999999876824\"\n#> [1] \"266 1.99999999815923 -2.99999999886234\"\n#> [1] \"267 1.99999999829985 -2.99999999894925\"\n#> [1] \"268 1.99999999842973 -2.99999999902952\"\n#> [1] \"269 1.99999999854969 -2.99999999910366\"\n#> [1] \"270 1.99999999866048 -2.99999999917213\"\n#> [1] \"271 1.99999999876281 -2.99999999923538\"\n#> [1] \"272 1.99999999885733 -2.99999999929379\"\n#> [1] \"273 1.99999999894462 -2.99999999934774\"\n#> [1] \"274 1.99999999902524 -2.99999999939757\"\n#> [1] \"275 1.99999999909971 -2.99999999944359\"\n#> [1] \"276 1.99999999916848 -2.99999999948609\"\n#> [1] \"277 1.99999999923201 -2.99999999952535\"\n#> [1] \"278 1.99999999929067 -2.99999999956161\"\n#> [1] \"279 1.99999999934486 -2.9999999995951\"\n#> [1] \"280 1.99999999939491 -2.99999999962603\"\n#> [1] \"281 1.99999999944114 -2.9999999996546\"\n#> [1] \"282 1.99999999948383 -2.99999999968099\"\n#> [1] \"283 1.99999999952326 -2.99999999970536\"\n#> [1] \"284 1.99999999955968 -2.99999999972787\"\n#> [1] \"285 1.99999999959332 -2.99999999974866\"\n#> [1] \"286 1.99999999962439 -2.99999999976786\"\n#> [1] \"287 1.99999999965308 -2.99999999978559\"\n#> [1] \"288 1.99999999967958 -2.99999999980197\"\n#> [1] \"289 1.99999999970406 -2.9999999998171\"\n#> [1] \"290 1.99999999972667 -2.99999999983107\"\n#> [1] \"291 1.99999999974755 -2.99999999984398\"\n#> [1] \"292 1.99999999976683 -2.9999999998559\"\n#> [1] \"293 1.99999999978465 -2.9999999998669\"\n#> [1] \"294 1.9999999998011 -2.99999999987707\"\n#> [1] \"295 1.99999999981629 -2.99999999988646\"\n#> [1] \"296 1.99999999983033 -2.99999999989514\"\n#> [1] \"297 1.99999999984329 -2.99999999990315\"\n#> [1] \"298 1.99999999985526 -2.99999999991055\"\n#> [1] \"299 1.99999999986632 -2.99999999991738\"\n#> [1] \"300 1.99999999987653 -2.99999999992369\"\n#> [1] \"301 1.99999999988596 -2.99999999992952\"\n#> [1] \"302 1.99999999989467 -2.9999999999349\"\n#> [1] \"303 1.99999999990272 -2.99999999993988\"\n#> [1] \"304 1.99999999991015 -2.99999999994447\"\n#> [1] \"305 1.99999999991702 -2.99999999994871\"\n#> [1] \"306 1.99999999992335 -2.99999999995263\"\n#> [1] \"307 1.99999999992921 -2.99999999995625\"\n#> [1] \"308 1.99999999993462 -2.99999999995959\"\n#> [1] \"309 1.99999999993961 -2.99999999996268\"\n#> [1] \"310 1.99999999994423 -2.99999999996553\"\n#> [1] \"311 1.99999999994849 -2.99999999996816\"\n#> [1] \"312 1.99999999995242 -2.9999999999706\"\n#> [1] \"313 1.99999999995606 -2.99999999997284\"\n#> [1] \"314 1.99999999995941 -2.99999999997492\"\n#> [1] \"315 1.99999999996251 -2.99999999997683\"\n#> [1] \"316 1.99999999996538 -2.9999999999786\"\n#> [1] \"317 1.99999999996802 -2.99999999998024\"\n#> [1] \"318 1.99999999997047 -2.99999999998175\"\n#> [1] \"319 1.99999999997272 -2.99999999998314\"\n#> [1] \"320 1.99999999997481 -2.99999999998443\"\n#> [1] \"321 1.99999999997673 -2.99999999998562\"\n#> [1] \"322 1.99999999997851 -2.99999999998672\"\n#> [1] \"323 1.99999999998015 -2.99999999998773\"\n#> [1] \"324 1.99999999998167 -2.99999999998867\"\n#> [1] \"325 1.99999999998307 -2.99999999998953\"\n#> [1] \"326 1.99999999998436 -2.99999999999033\"\n#> [1] \"327 1.99999999998556 -2.99999999999107\"\n#> [1] \"328 1.99999999998666 -2.99999999999175\"\n#> [1] \"329 1.99999999998768 -2.99999999999238\"\n#> [1] \"330 1.99999999998862 -2.99999999999297\"\n#> [1] \"331 1.99999999998949 -2.9999999999935\"\n#> [1] \"332 1.99999999999029 -2.999999999994\"\n#> [1] \"333 1.99999999999103 -2.99999999999446\"\n#> [1] \"334 1.99999999999172 -2.99999999999488\"\n#> [1] \"335 1.99999999999235 -2.99999999999527\"\n#> [1] \"336 1.99999999999293 -2.99999999999563\"\n#> [1] \"337 1.99999999999347 -2.99999999999597\"\n#> [1] \"338 1.99999999999397 -2.99999999999627\"\n#> [1] \"339 1.99999999999443 -2.99999999999656\"\n#> [1] \"340 1.99999999999486 -2.99999999999682\"\n#> [1] \"341 1.99999999999525 -2.99999999999707\"\n#> [1] \"342 1.99999999999561 -2.99999999999729\"\n#> [1] \"343 1.99999999999595 -2.9999999999975\"\n#> [1] \"344 1.99999999999626 -2.99999999999769\"\n#> [1] \"345 1.99999999999654 -2.99999999999786\"\n#> [1] \"346 1.99999999999681 -2.99999999999803\"\n#> [1] \"347 1.99999999999705 -2.99999999999818\"\n#> [1] \"348 1.99999999999728 -2.99999999999832\"\n#> [1] \"349 1.99999999999749 -2.99999999999845\"\n#> [1] \"350 1.99999999999768 -2.99999999999856\"\n#> [1] \"351 1.99999999999785 -2.99999999999867\"\n#> [1] \"352 1.99999999999802 -2.99999999999878\"\n#> [1] \"353 1.99999999999817 -2.99999999999887\"\n#> [1] \"354 1.99999999999831 -2.99999999999896\"\n#> [1] \"355 1.99999999999844 -2.99999999999904\"\n#> [1] \"356 1.99999999999856 -2.99999999999911\"\n#> [1] \"357 1.99999999999867 -2.99999999999918\"\n#> [1] \"358 1.99999999999877 -2.99999999999924\"\n#> [1] \"359 1.99999999999886 -2.9999999999993\"\n#> [1] \"360 1.99999999999895 -2.99999999999935\"\n#> [1] \"361 1.99999999999903 -2.9999999999994\"\n#> [1] \"362 1.99999999999911 -2.99999999999945\"\n#> [1] \"363 1.99999999999917 -2.99999999999949\"\n#> [1] \"364 1.99999999999924 -2.99999999999953\"\n#> [1] \"365 1.9999999999993 -2.99999999999956\"\n#> [1] \"366 1.99999999999935 -2.9999999999996\"\n#> [1] \"367 1.9999999999994 -2.99999999999963\"\n#> [1] \"368 1.99999999999944 -2.99999999999966\"\n#> [1] \"369 1.99999999999949 -2.99999999999968\"\n#> [1] \"370 1.99999999999953 -2.99999999999971\"\n#> [1] \"371 1.99999999999956 -2.99999999999973\"\n#> [1] \"372 1.9999999999996 -2.99999999999975\"\n#> [1] \"373 1.99999999999963 -2.99999999999977\"\n#> [1] \"374 1.99999999999966 -2.99999999999979\"\n#> [1] \"375 1.99999999999968 -2.9999999999998\"\n#> [1] \"376 1.99999999999971 -2.99999999999982\"\n#> [1] \"377 1.99999999999973 -2.99999999999983\"\n#> [1] \"378 1.99999999999975 -2.99999999999985\"\n#> [1] \"379 1.99999999999977 -2.99999999999986\"\n#> [1] \"380 1.99999999999979 -2.99999999999987\"\n#> [1] \"381 1.9999999999998 -2.99999999999988\"\n#> [1] \"382 1.99999999999982 -2.99999999999989\"\n#> [1] \"383 1.99999999999983 -2.9999999999999\"\n#> [1] \"384 1.99999999999984 -2.9999999999999\"\n#> [1] \"385 1.99999999999986 -2.99999999999991\"\n#> [1] \"386 1.99999999999987 -2.99999999999992\"\n#> [1] \"387 1.99999999999988 -2.99999999999992\"\n#> [1] \"388 1.99999999999989 -2.99999999999993\"\n#> [1] \"389 1.9999999999999 -2.99999999999994\"\n#> [1] \"390 1.9999999999999 -2.99999999999994\"\n#> [1] \"391 1.99999999999991 -2.99999999999994\"\n#> [1] \"392 1.99999999999992 -2.99999999999995\"\n#> [1] \"393 1.99999999999992 -2.99999999999995\"\n#> [1] \"394 1.99999999999993 -2.99999999999996\"\n#> [1] \"395 1.99999999999993 -2.99999999999996\"\n#> [1] \"396 1.99999999999994 -2.99999999999996\"\n#> [1] \"397 1.99999999999994 -2.99999999999997\"\n#> [1] \"398 1.99999999999995 -2.99999999999997\"\n#> [1] \"399 1.99999999999995 -2.99999999999997\"\n#> [1] \"400 1.99999999999996 -2.99999999999997\"\n#> [1] \"401 1.99999999999996 -2.99999999999998\"\n#> [1] \"402 1.99999999999996 -2.99999999999998\"\n#> [1] \"403 1.99999999999997 -2.99999999999998\"\n#> [1] \"404 1.99999999999997 -2.99999999999998\"\n#> [1] \"405 1.99999999999997 -2.99999999999998\"\n#> [1] \"406 1.99999999999997 -2.99999999999998\"\n#> [1] \"407 1.99999999999997 -2.99999999999998\"\n#> [1] \"408 1.99999999999998 -2.99999999999999\"\n#> [1] \"409 1.99999999999998 -2.99999999999999\"\n#> [1] \"410 1.99999999999998 -2.99999999999999\"\n#> [1] \"411 1.99999999999998 -2.99999999999999\"\n#> [1] \"412 1.99999999999998 -2.99999999999999\"\n#> [1] \"413 1.99999999999998 -2.99999999999999\"\n#> [1] \"414 1.99999999999999 -2.99999999999999\"\n#> [1] \"415 1.99999999999999 -2.99999999999999\"\n#> [1] \"416 1.99999999999999 -2.99999999999999\"\n#> [1] \"417 1.99999999999999 -2.99999999999999\"\n#> [1] \"418 1.99999999999999 -2.99999999999999\"\n#> [1] \"419 1.99999999999999 -2.99999999999999\"\n#> [1] \"420 1.99999999999999 -2.99999999999999\"\n#> [1] \"421 1.99999999999999 -2.99999999999999\"\n#> [1] \"422 1.99999999999999 -3\"\n#> [1] \"423 1.99999999999999 -3\"\n#> [1] \"424 1.99999999999999 -3\"\n#> [1] \"425 1.99999999999999 -3\"\n#> [1] \"426 1.99999999999999 -3\"\n#> [1] \"427 1.99999999999999 -3\"\n#> [1] \"428 2 -3\"\n#> [1] \"429 2 -3\"\n#> [1] \"430 2 -3\"\n#> [1] \"431 2 -3\"\n#> [1] \"432 2 -3\"\n#> [1] \"433 2 -3\"\n#> [1] \"434 2 -3\"\n#> [1] \"435 2 -3\"\n#> [1] \"436 2 -3\"\n#> [1] \"437 2 -3\"\n#> [1] \"438 2 -3\"\n#> [1] \"439 2 -3\"\n#> [1] \"440 2 -3\"\n#> [1] \"441 2 -3\"\n#> [1] \"442 2 -3\"\n#> [1] \"443 2 -3\"\n#> [1] \"444 2 -3\"\n#> [1] \"445 2 -3\"\n#> [1] \"446 2 -3\"\n#> [1] \"447 2 -3\"\n#> [1] \"448 2 -3\"\n#> [1] \"449 2 -3\"\n#> [1] \"450 2 -3\"\n#> [1] \"451 2 -3\"\n#> [1] \"452 2 -3\"\n#> [1] \"453 2 -3\"\n#> [1] \"454 2 -3\"\n#> [1] \"455 2 -3\"\n#> [1] \"456 2 -3\"\n#> [1] \"457 2 -3\"\n#> [1] \"458 2 -3\"\n#> [1] \"459 2 -3\"\n#> [1] \"460 2 -3\"\n#> [1] \"461 2 -3\"\n#> [1] \"462 2 -3\"\n#> [1] \"463 2 -3\"\n#> [1] \"464 2 -3\"\n#> [1] \"465 2 -3\"\n#> [1] \"466 2 -3\"\n#> [1] \"467 2 -3\"\n#> [1] \"468 2 -3\"\n#> [1] \"469 2 -3\"\n#> [1] \"470 2 -3\"\n#> [1] \"471 2 -3\"\n#> [1] \"472 2 -3\"\n#> [1] \"473 2 -3\"\n#> [1] \"474 2 -3\"\n#> [1] \"475 2 -3\"\n#> [1] \"476 2 -3\"\n#> [1] \"477 2 -3\"\n#> [1] \"478 2 -3\"\n#> [1] \"479 2 -3\"\n#> [1] \"480 2 -3\"\n#> [1] \"481 2 -3\"\n#> [1] \"482 2 -3\"\n#> [1] \"483 2 -3\"\n#> [1] \"484 2 -3\"\n#> [1] \"485 2 -3\"\n#> [1] \"486 2 -3\"\n#> [1] \"487 2 -3\"\n#> [1] \"488 2 -3\"\n#> [1] \"489 2 -3\"\n#> [1] \"490 2 -3\"\n#> [1] \"491 2 -3\"\n#> [1] \"492 2 -3\"\n#> [1] \"493 2 -3\"\n#> [1] \"494 2 -3\"\n#> [1] \"495 2 -3\"\n#> [1] \"496 2 -3\"\n#> [1] \"497 2 -3\"\n#> [1] \"498 2 -3\"\n#> [1] \"499 2 -3\"\n#> [1] \"500 2 -3\"\nf(x = x, y = y)\n#> [1] 1.776357e-15\nxaxis <- -5:5\nyaxis <- -5:5\nzaxis <- outer(xaxis, yaxis, f)\nlibrary(plot3D)\n#> Warning: package 'plot3D' was built under R version 4.0.5\npar(mfrow = c(2, 2), mai = c(1, 0.1, 0.1, 1))\npersp3D(z = zaxis, x = xaxis, y = yaxis, \n        phi = 10, \n        theta = 50, \n        box = TRUE, border = NA, shade = .1, expand = 0.6, contour = F)\n\npersp3D(z = zaxis, x = xaxis, y = yaxis, \n        phi = 10, \n        theta = 30, \n        box = TRUE, border = NA, shade = .1, expand = 0.6, contour = F)\n\npersp3D(z = zaxis, x = xaxis, y = yaxis, \n        phi = 30, \n        theta = 30, \n        box = TRUE, border = NA, shade = .1, expand = 0.6, contour = F)\n\npersp3D(z = zaxis, x = xaxis, y = yaxis, \n        phi = 50, \n        theta = 30, \n        box = TRUE, border = NA, shade = .1, expand = 0.6, contour = F)\npar(mfrow = c(1, 1))"},{"path":"gradient-descent-for-more-than-one-variable.html","id":"exercise-5","chapter":"Lecture 14 Gradient descent for more than one variable","heading":"14.3 Exercise","text":"E1. Update codes using statement.","code":""},{"path":"gradient-descent-for-simple-regression.html","id":"gradient-descent-for-simple-regression","chapter":"Lecture 15 Gradient descent for simple regression","heading":"Lecture 15 Gradient descent for simple regression","text":"","code":""},{"path":"gradient-descent-for-simple-regression.html","id":"scatter-plot","chapter":"Lecture 15 Gradient descent for simple regression","heading":"15.1 Scatter plot","text":"scatter plot data visualization type showing relationship two variables. called scatter plot uses dots markers represent data points, plotted two-dimensional grid values one variable horizontal axis values variable vertical axis.Scatter plots helpful visualizing relationship two variables allow us see data points distributed. example, strong linear relationship two variables, might see clear pattern data points forms straight line scatter plot. hand, relationship complex relationship variables, data points might scattered form clear pattern.Scatter plots also helpful identifying trends outliers data. example, trend data one variable increases variable increases, might see cluster data points forms diagonal line scatter plot. hand, outliers data points significantly different rest data might indicated dots far away main cluster data points.general, scatter plots help explore visualize relationship two variables dataset. can help us understand data identify patterns trends might apparent raw data.Let generate data plot R.code creates scatter plot using plot function R. plot function takes several arguments specify plotted data, plot’s appearance, options.first two arguments plot function x y, specify data plotted. x y values defined vectors using c function case. x vector contains values 1, 2, 3, 4, 5, y vector contains values 3, 4, 8, 12, 11. values used create scatter plot, values x vector plotted horizontal axis values y vector plotted vertical axis.plot function also takes main argument, specifies plot’s title. case, title set “Scatter plot”. Finally, xlim ylim arguments specify range values shown horizontal vertical axes, respectively. case, range values horizontal axis set -2 7, range vertical axis set 0 16.col argument specifies color data points scatter plot. case, color set “black”.","code":"\n# Generate some dummy data\nx <- c(1, 2, 3, 4, 5)\ny <- c(3, 4, 8, 12, 11)\nplot(x = x, y = y, main = \"Scatter plot\", xlim = c(-2, 7), ylim = c(0, 16), col = \"black\")"},{"path":"gradient-descent-for-simple-regression.html","id":"intuition-of-simple-linear-regression","chapter":"Lecture 15 Gradient descent for simple regression","heading":"15.2 Intuition of simple linear regression","text":"kind trend see data? ’s tough miss- positive upward trend.Now, use scale ruler pen draw straight line scatter plot think best. probably draw something like .’s simple linear regression. find best fit line two variables. say simple linear regression, can expressed equation straight line \\[y = mx + c\\]However, write \\[y = \\beta_0 + \\beta_1x\\]slope \\(m = \\beta_1\\) y-intercept \\(c = \\beta_0\\). may think economists tend use Greek letters look cool. However, use Greek letters whenever feel quantity can estimated enough data.say estimate– mean best guess best prediction value \\(y\\) best guess true \\(\\beta_0\\) \\(\\widehat{\\beta_0}\\) \\(\\beta_1\\) \\(\\widehat{\\beta_1}\\).Thus can express : \\[\\widehat{y} = \\widehat{\\beta_0} = \\widehat{\\beta_1}x\\]Therefore residual actual \\(y\\) \\(\\widehat{y}\\).\n\\[e = y - \\widehat{y}\\]sake example, let’s say initialize (best guess) value \\(\\widehat{\\beta_0}\\) \\(\\widehat{\\beta_1}\\) 1 2. , value x given previously 1, 2, 3, 4, 5, corresponding predicted \\(y\\) \\(\\widehat{y}\\) 3,5,7,9 11.difference actual \\(y\\) predicted \\(\\widehat{y}\\) residuals error \\(e = y - \\widehat{y}\\) given 0,-1,1,3, 0.regression analysis, residuals represent difference observed predicted values. Therefore sum mean residuals always zero. sum mean residuals zero predicted values perfectly match observed values. However, often case, especially noise sources error data.Now want optimize error. One way square residual take mean mean squared error given \\[MSE = \\frac{\\sum e^2}{n}=n^{-1}\\sum e^2 = n^{-1}\\sum(y-\\widehat{y})^2\\].another word, like find \\(\\widehat{\\beta_0}\\) \\(\\widehat{\\beta}\\) minimizes \\(MSE\\).Analytically, take derivative gradient \\(MSE\\) w.r.t \\(\\widehat{\\beta_0}\\) \\(\\widehat{\\beta}\\), set zero solve .\\[\\frac{\\partial n^{-1}\\sum e^2}{\\partial \\widehat{\\beta_0}}=\\frac{\\partial n^{-1}\\sum(y-\\widehat{y})^2}{\\partial \\widehat{\\beta_0}}= \\frac{n^{-1}\\partial \\sum(y-\\widehat{y})^2}{\\partial (y-\\widehat{y})} \\frac{\\partial (y-\\widehat{y})}{\\widehat{\\beta_0}}=2n^{-1}\\sum(y-\\widehat{y})\\frac{\\partial (y-\\widehat{\\beta_0}-\\widehat{\\beta_1}x)}{\\widehat{\\beta_0}}=-2n^{-1}\\sum(y-\\widehat{y})\\]\n\\[\\frac{\\partial n^{-1}\\sum e^2}{\\partial \\widehat{\\beta_0}}=-2n^{-1}\\sum(y-\\widehat{y})=-2\\frac{\\sum e}{n}\\]Similarly,\\[\\frac{\\partial n^{-1}\\sum e^2}{\\partial \\widehat{\\beta_1}}=-2n^{-1}\\sum(y-\\widehat{y})=-2\\frac{\\sum ex}{n}\\]Now let’s use gradient descent using R.begin let’s first initialize \\(\\widehat{\\beta_0}\\) \\(\\widehat{\\beta}\\) zero, can choose numbers. Also set learning rate 0.1.Let’s use gradient descent \\(\\widehat{\\beta_0}\\) \\(\\widehat{\\beta}\\) minimize \\(MSE\\), let’s call cost.code, cost function mean squared error predicted values dependent variable (y_pred) true values dependent variable (y). predicted values computed using current values coefficients beta0 beta1, updated iteration algorithm using gradient cost function respect coefficients.gradient descent algorithm run 10,000 iterations, means values beta0 beta1 updated 10,000 times order find values minimize cost function. learning rate alpha determines size updates coefficients iteration hyperparameter needs set running algorithm.need make adjustments algorithm allow algorithm stop reaches convergence certain threshold. Second, keep learning parameter per wish twice size.code uses gradient descent algorithm fit simple linear regression model dummy data set. data consists 5 pairs values (x y), goal find values coefficients beta0 beta1 best fit data.gradient descent algorithm works starting initial values coefficients (case, beta0 = 0 beta1 = 0) iteratively updating values coefficients way reduces cost (measure well model fits data). cost computed using mean squared error (MSE) predicted values actual values y.iteration, code computes predicted values y, errors, cost. updates coefficients moving opposite direction gradient (derivative cost respect coefficients). update scaled learning rate, determines size step taken opposite direction gradient.code includes convergence check compares current cost previous cost terminates loop difference less convergence threshold (set 1e-5 example). ensures algorithm continue running stop reaches point updates coefficients likely improve model significantly.Let’s examine results algorithm analytic solution.summary() function R used generate summary model. case, lm() function used fit linear regression model data, y response variable x predictor variable. summary() function applied resulting model object generate summary model fit.summary linear regression model typically includes information coefficients (.e., estimated values beta0 beta1 case), intercept, residuals (.e., difference observed values y predicted values), R-squared value (indicates well model fits data), F-statistic (used assess overall significance model). summary can also include diagnostic information, distribution residuals, can useful checking assumptions model.compare results, seems pretty close!","code":"\nplot(x = x, y = y, main = \"Scatter plot\", xlim = c(-2, 7), ylim = c(0, 16), col = \"black\")\nabline(lm(y~x), col=\"red\", lwd=2, lty = 3)\n# Generate some dummy data\nx <- c(1, 2, 3, 4, 5)\ny <- c(3, 4, 8, 12, 11)\n\n# Set the learning rate\nalpha <- 0.01\n\n# Set the initial values of the coefficients\nbeta0 <- 0\nbeta1 <- 0\nresults <- list()\n# Define the gradient descent algorithm\nfor (i in 1:10000) {\n  # Compute the predicted values\n  y_pred <- beta0 + beta1 * x\n  \n  # Compute the errors\n  # computer scientists tend to use error = y_pred - y, but we will remain consistent with economist\n  # taking square error of (y_pred - y) seem same as (y - y_pred), but there are some fundamental issues\n  error <- y - y_pred \n  \n  # Compute the cost\n  cost <- mean((error^2))\n  \n  # Update the coefficients\n  # Since computer scientist do y_pred-y, their gradient would be 2*mean(error)\n  beta0 <- beta0 - alpha * (-2)*mean(error)\n  \n  #Since computer scientist do y_pred-y, their gradient would be 2*mean(error * x)\n  beta1 <- beta1 - alpha * (-2)*mean(error * x) #\n  \n  results[[i]] <- data.frame(\"iteration\" = i,\"beta0\" = beta0, \"beta1\" = beta1, \"MSE\" = cost)\n  \n  # The alpha * (-2)*mean(error) mathematically means (-2 * alpha)(mean(error))\n  # which actually doubles your learning rate, which is bad for precision.\n  # So the value of betas can be expressed as\n  # beta0 <- beta0 + alpha*mean(error)\n  # beta1 <- beta1 + alpha*mean(error * x)\n  \n}\n# Generate some dummy data\nx <- c(1, 2, 3, 4, 5)\ny <- c(3, 4, 8, 12, 11)\n\n# Set the learning rate\nalpha <- 0.01\n\n# Set the initial values of the coefficients\nbeta0 <- 0\nbeta1 <- 0\n\n# Set the convergence threshold\nconvergence_threshold <- 1e-10\n\n# Set the initial value of the previous cost\nprev_cost <- Inf\n\n# Initialize the iteration counter\niteration <- 0\n\n# Start the loop\nwhile (TRUE) {\n  # Increment the iteration counter\n  iteration <- iteration + 1\n  \n  # Compute the predicted values\n  y_pred <- beta0 + beta1 * x\n  \n  # Compute the errors\n  error <- y - y_pred\n  \n  # Compute the cost\n  cost <- mean((error^2))\n  \n  # Print the current state\n  # print(paste(iteration, beta0, beta1, cost, sep = \", \"))\n  \n  # Store the results\n  results <- data.frame(\"iteration\" = iteration,\"beta0\" = beta0, \"beta1\" = beta1, \"MSE\" = cost)\n  \n  # Check for convergence\n  if (abs(cost - prev_cost) < convergence_threshold) {\n    break\n  }\n  \n  # Update the previous cost\n  prev_cost <- cost\n  \n  # Update the coefficients\n  beta0 <- beta0 - alpha * (-1)*mean(error)\n  beta1 <- beta1 - alpha * (-1)*mean(error * x)\n}\nresults\n#>   iteration     beta0    beta1  MSE\n#> 1      3793 0.4004022 2.399889 1.52\nsummary(lm(y~x))\n#> \n#> Call:\n#> lm(formula = y ~ x)\n#> \n#> Residuals:\n#>    1    2    3    4    5 \n#>  0.2 -1.2  0.4  2.0 -1.4 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)  \n#> (Intercept)   0.4000     1.6693   0.240   0.8261  \n#> x             2.4000     0.5033   4.768   0.0175 *\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 1.592 on 3 degrees of freedom\n#> Multiple R-squared:  0.8834, Adjusted R-squared:  0.8446 \n#> F-statistic: 22.74 on 1 and 3 DF,  p-value: 0.01752"},{"path":"gradient-descent-for-simple-regression.html","id":"exercise-6","chapter":"Lecture 15 Gradient descent for simple regression","heading":"15.3 Exercise","text":"E1. Use following data estimate coefficients.E2. Use following data estimate coefficients.","code":"\nn <- 1000\nx <- rnorm(n)\ny <- 1 - 4 * x + rnorm(n)\n# you can see the actual estimate of intercept and slope with \n# summary(lm(y~x))\n# Use gradient descent approach to identify those coefficients.\nn <- 1000\nx1 <- rnorm(n)\nx2 <- rnorm(n = n, 1, 1)\ny <- 2 - 3 * x1 + 4 * x2 + rnorm(n)"},{"path":"standard-error.html","id":"standard-error","chapter":"Lecture 16 Standard error","heading":"Lecture 16 Standard error","text":"","code":""},{"path":"standard-error.html","id":"standard-error-of-linear-regression","chapter":"Lecture 16 Standard error","heading":"16.1 Standard error of linear regression","text":"standard error linear regression measure well regression line fits data. represents average distance data points fall regression line. smaller standard error, better regression line fits data.Intuitively, can think standard error “average” distance data point regression line. example, standard error 0.5, average, data point 0.5 units away regression line.standard error used construct confidence intervals predicted values dependent variable. example, standard error 0.5 confidence level 95%, can 95% confident true value dependent variable fall within 1 standard error (0.5) predicted value.general, smaller standard error indicates data points closer regression line, means regression model better fit data. However, important remember standard error one measure goodness--fit, factors also considered evaluating regression model.step--step process:calculate standard error estimate simple linear regression, first find difference observed value dependent variable (y) predicted value dependent variable (ŷ) data point. differences called residuals.calculate standard error estimate simple linear regression, first find difference observed value dependent variable (y) predicted value dependent variable (ŷ) data point. differences called residuals.Next, square residuals add . give sum squares residuals, also known error sum squares (ESS).Next, square residuals add . give sum squares residuals, also known error sum squares (ESS)., divide ESS degrees freedom model, number data points minus number regression coefficients. give mean square error (MSE)., divide ESS degrees freedom model, number data points minus number regression coefficients. give mean square error (MSE).Finally, take square root MSE find standard error estimate. measure well regression line fits data.Finally, take square root MSE find standard error estimate. measure well regression line fits data.alternatively, can run linear model check :can also check summary regression, can find R puts standard error linear model?","code":"\nset.seed(123)\n# Lets define the number of observation\nn <- 1000\n\n# generate some random data\nx = rnorm(n)\ny = 1 + 2 * x + rnorm(n)\n\n# fit a linear regression model\nmodel = lm(y ~ x)\n\n# calculate the residuals\nresiduals = residuals(model)\n\n# calculate the error sum of squares\ness = sum(residuals^2)\n\n# calculate the degrees of freedom for the model\ndf = length(x) - length(coef(model))\n\n# calculate the mean square error\nmse = ess / df\n\n# calculate the standard error of the estimate\nse = sqrt(mse)\n\n# print the result\nse\n#> [1] 1.006395\n# calculate the standard error of the regression\nsummary(lm(y~x))$sigma\n#> [1] 1.006395\nsummary(lm(y~x))\n#> \n#> Call:\n#> lm(formula = y ~ x)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -3.0279 -0.6914  0.0043  0.7087  3.2911 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)  1.04105    0.03183   32.71   <2e-16 ***\n#> x            2.08805    0.03211   65.03   <2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 1.006 on 998 degrees of freedom\n#> Multiple R-squared:  0.8091, Adjusted R-squared:  0.8089 \n#> F-statistic:  4229 on 1 and 998 DF,  p-value: < 2.2e-16"},{"path":"standard-error.html","id":"standard-error-of-a-regression-coefficient","chapter":"Lecture 16 Standard error","heading":"16.2 Standard error of a regression coefficient","text":"standard error regression coefficient standard deviation sampling distribution coefficient. words, measure accurately regression coefficient estimates population parameter.standard error regression coefficient used construct confidence intervals true value coefficient. example, standard error regression coefficient 0.1 confidence level 95%, can 95% confident true value coefficient lies within 0.2 estimated value (0.1 * 2 = 0.2).calculate standard error regression coefficient, need know standard error regression, estimated standard deviation error term. standard error regression coefficient calculated standard error regression divided square root sum squares independent variable.","code":"\n# calculate the standard error of the regression\nse = summary(model)$sigma\n\n# calculate the sum of squares of the independent variable\nssx = sum(x^2)\n\n# calculate the standard error of the regression coefficient\nse_beta = se / sqrt(ssx)\n\n# print the result\nse_beta\n#> [1] 0.03210335\n# calculate the standard error of the regression\nse = summary(model)$sigma\n\n# calculate the sum of squares of the independent variable\nssx = sum(x^2)\n\n# calculate the means of the independent variable\nx_mean = mean(x)\n\n# calculate the standard error of the intercept\nse_beta0 = se * sqrt(1/n + x_mean^2/ssx)\n\n# print the result\nse_beta0\n#> [1] 0.03182923"},{"path":"standard-error.html","id":"simulation","chapter":"Lecture 16 Standard error","heading":"16.3 Simulation","text":"increase size 100 , standard deviation beta coeffecient reduce.key learning random sampling data able identify coefficient however data improve precision reducing standard error.","code":"\n# generate some random data\ndf <- data.frame(x = x, y = y)\nbeta0_value <- c()\nbeta1_value <- c()\nfor(i in 1:1000){\n  # sample 200 rows from the data frame with replacement\n  sample_data <- df[sample(nrow(df), size = 100, replace = TRUE), ]\n  \n  # fit a linear regression model\n  sample_model <- lm(y ~ x, data = sample_data)\n  \n  # Extract the intercept from sample model\n  beta0_value[i] <- sample_model$coefficients[1]\n  \n  # Extract the slope coefficient from sample model\n  beta1_value[i] <- sample_model$coefficients[2]\n}\n\nhist(beta0_value, main = paste0(\"Mean = \", round(mean(beta0_value),3), \" SD = \", round(sd(beta0_value),3)))\n\nhist(beta1_value, main = paste0(\"Mean = \", round(mean(beta1_value),3), \" SD = \", round(sd(beta1_value),3)))\nbeta0_value <- c()\nbeta1_value <- c()\nfor(i in 1:1000){\n  # sample 200 rows from the data frame with replacement\n  sample_data <- df[sample(nrow(df), size = 500, replace = TRUE), ]\n  \n  # fit a linear regression model\n  sample_model <- lm(y ~ x, data = sample_data)\n  \n  # Extract the intercept from sample model\n  beta0_value[i] <- sample_model$coefficients[1]\n  \n  # Extract the slope coefficient from sample model\n  beta1_value[i] <- sample_model$coefficients[2]\n}\n\nhist(beta0_value, main = paste0(\"Mean = \", round(mean(beta0_value),3), \" SD = \", round(sd(beta0_value),3)))\n\nhist(beta1_value, main = paste0(\"Mean = \", round(mean(beta1_value),3), \" SD = \", round(sd(beta1_value),3)))"}]
