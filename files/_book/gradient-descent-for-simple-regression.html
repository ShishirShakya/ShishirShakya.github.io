<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Lecture 15 Gradient descent for simple regression | Mostly Handsdirty Metrics</title>
<meta name="author" content="Shishir Shakya">
<meta name="description" content="15.1 Scatter plot A scatter plot is a data visualization type showing the relationship between two variables. It is called a scatter plot because it uses dots or markers to represent the data...">
<meta name="generator" content="bookdown 0.27 with bs4_book()">
<meta property="og:title" content="Lecture 15 Gradient descent for simple regression | Mostly Handsdirty Metrics">
<meta property="og:type" content="book">
<meta property="og:description" content="15.1 Scatter plot A scatter plot is a data visualization type showing the relationship between two variables. It is called a scatter plot because it uses dots or markers to represent the data...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Lecture 15 Gradient descent for simple regression | Mostly Handsdirty Metrics">
<meta name="twitter:description" content="15.1 Scatter plot A scatter plot is a data visualization type showing the relationship between two variables. It is called a scatter plot because it uses dots or markers to represent the data...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.0/transition.js"></script><script src="libs/bs3compat-0.4.0/tabs.js"></script><script src="libs/bs3compat-0.4.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Mostly Handsdirty Metrics</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> This is a work in progress!</a></li>
<li><a class="" href="data-types-structures-and-extractions.html"><span class="header-section-number">2</span> Data types, structures, and extractions</a></li>
<li><a class="" href="sampling.html"><span class="header-section-number">3</span> Sampling</a></li>
<li><a class="" href="for-loop-and-probability.html"><span class="header-section-number">4</span> For loop and probability</a></li>
<li><a class="" href="if-else-and-probability.html"><span class="header-section-number">5</span> If else and probability</a></li>
<li><a class="" href="basic-statistics.html"><span class="header-section-number">6</span> Basic statistics</a></li>
<li><a class="" href="investing-basics.html"><span class="header-section-number">7</span> Investing basics</a></li>
<li><a class="" href="recursive-investment.html"><span class="header-section-number">8</span> Recursive investment</a></li>
<li><a class="" href="index-universal-life-insurance.html"><span class="header-section-number">9</span> Index universal life insurance</a></li>
<li><a class="" href="stock-market-monte-carlo-simulation.html"><span class="header-section-number">10</span> Stock market monte-carlo simulation</a></li>
<li><a class="" href="confidence-interval-z-scores-hypothesis-testing.html"><span class="header-section-number">11</span> Confidence interval, z-scores, hypothesis testing</a></li>
<li><a class="" href="unconstrainted-optimization.html"><span class="header-section-number">12</span> Unconstrainted optimization</a></li>
<li><a class="" href="gradient-descent.html"><span class="header-section-number">13</span> Gradient descent</a></li>
<li><a class="" href="gradient-descent-for-more-than-one-variable.html"><span class="header-section-number">14</span> Gradient descent for more than one variable</a></li>
<li><a class="active" href="gradient-descent-for-simple-regression.html"><span class="header-section-number">15</span> Gradient descent for simple regression</a></li>
<li><a class="" href="standard-error.html"><span class="header-section-number">16</span> Standard error</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/rstudio/bookdown-demo">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="gradient-descent-for-simple-regression" class="section level1" number="15">
<h1>
<span class="header-section-number">Lecture 15</span> Gradient descent for simple regression<a class="anchor" aria-label="anchor" href="#gradient-descent-for-simple-regression"><i class="fas fa-link"></i></a>
</h1>
<div id="scatter-plot" class="section level2" number="15.1">
<h2>
<span class="header-section-number">15.1</span> Scatter plot<a class="anchor" aria-label="anchor" href="#scatter-plot"><i class="fas fa-link"></i></a>
</h2>
<p>A scatter plot is a data visualization type showing the relationship between two variables. It is called a scatter plot because it uses dots or markers to represent the data points, which are plotted on a two-dimensional grid with the values of one variable on the horizontal axis and the values of the other variable on the vertical axis.</p>
<p>Scatter plots are helpful in visualizing the relationship between two variables because they allow us to see the data points and how they are distributed. For example, if there is a strong linear relationship between the two variables, we might see a clear pattern in the data points that forms a straight line on the scatter plot. On the other hand, if there is no relationship or a more complex relationship between the variables, the data points might be more scattered and not form a clear pattern.</p>
<p>Scatter plots are also helpful in identifying trends and outliers in the data. For example, if there is a trend in the data where one variable increases as the other variable increases, we might see a cluster of data points that forms a diagonal line on the scatter plot. On the other hand, outliers are data points that are significantly different from the rest of the data and might be indicated by dots that are far away from the main cluster of data points.</p>
<p>In general, scatter plots help explore and visualize the relationship between two variables in a dataset. They can help us understand the data and identify patterns and trends that might not be apparent from the raw data.</p>
<p>Let me generate some data and plot them in R.</p>
<div class="sourceCode" id="cb116"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Generate some dummy data</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span>, <span class="fl">3</span>, <span class="fl">4</span>, <span class="fl">5</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">4</span>, <span class="fl">8</span>, <span class="fl">12</span>, <span class="fl">11</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span>, main <span class="op">=</span> <span class="st">"Scatter plot"</span>, xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">2</span>, <span class="fl">7</span><span class="op">)</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">16</span><span class="op">)</span>, col <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="14-gradient-descent-simple-regression_files/figure-html/unnamed-chunk-1-1.png" width="672"></div>
<p>This code creates a scatter plot using the plot function in R. The plot function takes several arguments that specify the plotted data, the plot’s appearance, and other options.</p>
<p>The first two arguments to the plot function are x and y, which specify the data to be plotted. The x and y values are defined as vectors using the c function in this case. The x vector contains the values 1, 2, 3, 4, and 5, and the y vector contains the values 3, 4, 8, 12, and 11. These values will be used to create the scatter plot, with the values in the x vector plotted on the horizontal axis and the values in the y vector plotted on the vertical axis.</p>
<p>The plot function also takes the main argument, which specifies the plot’s title. In this case, the title is set to “Scatter plot”. Finally, the xlim and ylim arguments specify the range of values to be shown on the horizontal and vertical axes, respectively. In this case, the range of values for the horizontal axis is set from -2 to 7, and the range for the vertical axis is set from 0 to 16.</p>
<p>The col argument specifies the color of the data points on the scatter plot. In this case, the color is set to “black”.</p>
</div>
<div id="intuition-of-simple-linear-regression" class="section level2" number="15.2">
<h2>
<span class="header-section-number">15.2</span> Intuition of simple linear regression<a class="anchor" aria-label="anchor" href="#intuition-of-simple-linear-regression"><i class="fas fa-link"></i></a>
</h2>
<p>What kind of trend do you see in these data? It’s tough to miss- a positive upward trend.</p>
<p>Now, use a scale ruler and pen to draw a straight line on this scatter plot that you think is the best. You will probably draw something like this.</p>
<div class="sourceCode" id="cb117"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span>, main <span class="op">=</span> <span class="st">"Scatter plot"</span>, xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">2</span>, <span class="fl">7</span><span class="op">)</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">16</span><span class="op">)</span>, col <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span><span class="op">~</span><span class="va">x</span><span class="op">)</span>, col<span class="op">=</span><span class="st">"red"</span>, lwd<span class="op">=</span><span class="fl">2</span>, lty <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="14-gradient-descent-simple-regression_files/figure-html/unnamed-chunk-2-1.png" width="672"></div>
<p>That’s what we will do in simple linear regression. We will find the best fit line between the two variables. When we say a simple linear regression, it can be expressed with an equation of straight line as <span class="math display">\[y = mx + c\]</span></p>
<p>However, we will write this as <span class="math display">\[y = \beta_0 + \beta_1x\]</span></p>
<p>where slope <span class="math inline">\(m = \beta_1\)</span> and y-intercept <span class="math inline">\(c = \beta_0\)</span>. You may think economists tend to use Greek letters to look cool. However, we use Greek letters whenever we feel the quantity can be estimated with enough data.</p>
<p>When we say estimate– we mean the best guess or best prediction of the value of <span class="math inline">\(y\)</span> with the best guess of true <span class="math inline">\(\beta_0\)</span> as <span class="math inline">\(\widehat{\beta_0}\)</span> and <span class="math inline">\(\beta_1\)</span> as <span class="math inline">\(\widehat{\beta_1}\)</span>.</p>
<p>Thus we can express as: <span class="math display">\[\widehat{y} = \widehat{\beta_0} = \widehat{\beta_1}x\]</span></p>
<p>Therefore there will be some residual between actual <span class="math inline">\(y\)</span> and <span class="math inline">\(\widehat{y}\)</span>.
<span class="math display">\[e = y - \widehat{y}\]</span></p>
<p>For the sake of our example, let’s say initialize (best guess) the value of <span class="math inline">\(\widehat{\beta_0}\)</span> and <span class="math inline">\(\widehat{\beta_1}\)</span> as 1 and 2. Then, for each value of x given previously as 1, 2, 3, 4, and 5, the corresponding predicted <span class="math inline">\(y\)</span> or <span class="math inline">\(\widehat{y}\)</span> would be 3,5,7,9 and 11.</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="20%">
<col width="20%">
<col width="20%">
<col width="20%">
<col width="20%">
</colgroup>
<thead><tr class="header">
<th align="center">x</th>
<th align="center">y</th>
<th align="center">
<span class="math inline">\(\widehat{y}\)</span> when <span class="math inline">\(\widehat{\beta_0}\)</span> = 1 &amp; <span class="math inline">\(\widehat{\beta_1}\)</span> = 2</th>
<th align="center"><span class="math inline">\(e = y - \widehat{y}\)</span></th>
<th align="center">e^2</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">3</td>
<td align="center">3</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">4</td>
<td align="center">5</td>
<td align="center">-1</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">8</td>
<td align="center">7</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">12</td>
<td align="center">9</td>
<td align="center">3</td>
<td align="center">9</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">11</td>
<td align="center">11</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
</tbody>
</table></div>
<p>The difference between actual <span class="math inline">\(y\)</span> and predicted <span class="math inline">\(\widehat{y}\)</span> is residuals or error <span class="math inline">\(e = y - \widehat{y}\)</span> is given as 0,-1,1,3, and 0.</p>
<p>In a regression analysis, the residuals represent the difference between the observed and predicted values. Therefore the sum or the mean of the residuals is not always zero. The sum or the mean of the residuals will be zero only if the predicted values perfectly match the observed values. However, this is often not the case, especially when there is noise or other sources of error in the data.</p>
<p>Now we want to optimize the error. One way to do this is to square the residual and take a mean or mean squared error given as <span class="math display">\[MSE = \frac{\sum e^2}{n}=n^{-1}\sum e^2 = n^{-1}\sum(y-\widehat{y})^2\]</span>.</p>
<p>In another word, we would like to find <span class="math inline">\(\widehat{\beta_0}\)</span> and <span class="math inline">\(\widehat{\beta}\)</span> that minimizes <span class="math inline">\(MSE\)</span>.</p>
<p>Analytically, we have to take the derivative or gradient of <span class="math inline">\(MSE\)</span> w.r.t <span class="math inline">\(\widehat{\beta_0}\)</span> and <span class="math inline">\(\widehat{\beta}\)</span>, then set them to zero and solve it.</p>
<p><span class="math display">\[\frac{\partial n^{-1}\sum e^2}{\partial \widehat{\beta_0}}=\frac{\partial n^{-1}\sum(y-\widehat{y})^2}{\partial \widehat{\beta_0}}= \frac{n^{-1}\partial \sum(y-\widehat{y})^2}{\partial (y-\widehat{y})} \frac{\partial (y-\widehat{y})}{\widehat{\beta_0}}=2n^{-1}\sum(y-\widehat{y})\frac{\partial (y-\widehat{\beta_0}-\widehat{\beta_1}x)}{\widehat{\beta_0}}=-2n^{-1}\sum(y-\widehat{y})\]</span>
<span class="math display">\[\frac{\partial n^{-1}\sum e^2}{\partial \widehat{\beta_0}}=-2n^{-1}\sum(y-\widehat{y})=-2\frac{\sum e}{n}\]</span></p>
<p>Similarly,</p>
<p><span class="math display">\[\frac{\partial n^{-1}\sum e^2}{\partial \widehat{\beta_1}}=-2n^{-1}\sum(y-\widehat{y})=-2\frac{\sum ex}{n}\]</span></p>
<p>Now let’s use gradient descent using R.</p>
<p>To begin let’s first initialize <span class="math inline">\(\widehat{\beta_0}\)</span> and <span class="math inline">\(\widehat{\beta}\)</span> as zero, we can choose any numbers. Also set the learning rate as 0.1.</p>
<div class="sourceCode" id="cb118"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Generate some dummy data</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span>, <span class="fl">3</span>, <span class="fl">4</span>, <span class="fl">5</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">4</span>, <span class="fl">8</span>, <span class="fl">12</span>, <span class="fl">11</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Set the learning rate</span></span>
<span><span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fl">0.01</span></span>
<span></span>
<span><span class="co"># Set the initial values of the coefficients</span></span>
<span><span class="va">beta0</span> <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span><span class="va">beta1</span> <span class="op">&lt;-</span> <span class="fl">0</span></span></code></pre></div>
<p>Let’s use the gradient descent on <span class="math inline">\(\widehat{\beta_0}\)</span> and <span class="math inline">\(\widehat{\beta}\)</span> to minimize the <span class="math inline">\(MSE\)</span>, let’s call it the cost.</p>
<div class="sourceCode" id="cb119"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co"># Define the gradient descent algorithm</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">10000</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># Compute the predicted values</span></span>
<span>  <span class="va">y_pred</span> <span class="op">&lt;-</span> <span class="va">beta0</span> <span class="op">+</span> <span class="va">beta1</span> <span class="op">*</span> <span class="va">x</span></span>
<span>  </span>
<span>  <span class="co"># Compute the errors</span></span>
<span>  <span class="co"># computer scientists tend to use error = y_pred - y, but we will remain consistent with economist</span></span>
<span>  <span class="co"># taking square error of (y_pred - y) seem same as (y - y_pred), but there are some fundamental issues</span></span>
<span>  <span class="va">error</span> <span class="op">&lt;-</span> <span class="va">y</span> <span class="op">-</span> <span class="va">y_pred</span> </span>
<span>  </span>
<span>  <span class="co"># Compute the cost</span></span>
<span>  <span class="va">cost</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">error</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Update the coefficients</span></span>
<span>  <span class="co"># Since computer scientist do y_pred-y, their gradient would be 2*mean(error)</span></span>
<span>  <span class="va">beta0</span> <span class="op">&lt;-</span> <span class="va">beta0</span> <span class="op">-</span> <span class="va">alpha</span> <span class="op">*</span> <span class="op">(</span><span class="op">-</span><span class="fl">2</span><span class="op">)</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">error</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co">#Since computer scientist do y_pred-y, their gradient would be 2*mean(error * x)</span></span>
<span>  <span class="va">beta1</span> <span class="op">&lt;-</span> <span class="va">beta1</span> <span class="op">-</span> <span class="va">alpha</span> <span class="op">*</span> <span class="op">(</span><span class="op">-</span><span class="fl">2</span><span class="op">)</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">error</span> <span class="op">*</span> <span class="va">x</span><span class="op">)</span> <span class="co">#</span></span>
<span>  </span>
<span>  <span class="va">results</span><span class="op">[[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="st">"iteration"</span> <span class="op">=</span> <span class="va">i</span>,<span class="st">"beta0"</span> <span class="op">=</span> <span class="va">beta0</span>, <span class="st">"beta1"</span> <span class="op">=</span> <span class="va">beta1</span>, <span class="st">"MSE"</span> <span class="op">=</span> <span class="va">cost</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># The alpha * (-2)*mean(error) mathematically means (-2 * alpha)(mean(error))</span></span>
<span>  <span class="co"># which actually doubles your learning rate, which is bad for precision.</span></span>
<span>  <span class="co"># So the value of betas can be expressed as</span></span>
<span>  <span class="co"># beta0 &lt;- beta0 + alpha*mean(error)</span></span>
<span>  <span class="co"># beta1 &lt;- beta1 + alpha*mean(error * x)</span></span>
<span>  </span>
<span><span class="op">}</span></span></code></pre></div>
<p>In this code, the cost function is the mean squared error between the predicted values of the dependent variable (y_pred) and the true values of the dependent variable (y). The predicted values are computed using the current values of the coefficients beta0 and beta1, which are updated in each iteration of the algorithm using the gradient of the cost function with respect to the coefficients.</p>
<p>The gradient descent algorithm is run for 10,000 iterations, which means that the values of beta0 and beta1 are updated 10,000 times in order to find the values that minimize the cost function. The learning rate alpha determines the size of the updates to the coefficients in each iteration and is a hyperparameter that needs to be set before running the algorithm.</p>
<p>We need to make a few adjustments to this algorithm in which we allow the algorithm to stop after it reaches the convergence or a certain threshold. Second, we keep the learning parameter as per our wish and not twice the size.</p>
<div class="sourceCode" id="cb120"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Generate some dummy data</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span>, <span class="fl">3</span>, <span class="fl">4</span>, <span class="fl">5</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">4</span>, <span class="fl">8</span>, <span class="fl">12</span>, <span class="fl">11</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Set the learning rate</span></span>
<span><span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fl">0.01</span></span>
<span></span>
<span><span class="co"># Set the initial values of the coefficients</span></span>
<span><span class="va">beta0</span> <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span><span class="va">beta1</span> <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span></span>
<span><span class="co"># Set the convergence threshold</span></span>
<span><span class="va">convergence_threshold</span> <span class="op">&lt;-</span> <span class="fl">1e-10</span></span>
<span></span>
<span><span class="co"># Set the initial value of the previous cost</span></span>
<span><span class="va">prev_cost</span> <span class="op">&lt;-</span> <span class="cn">Inf</span></span>
<span></span>
<span><span class="co"># Initialize the iteration counter</span></span>
<span><span class="va">iteration</span> <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span></span>
<span><span class="co"># Start the loop</span></span>
<span><span class="kw">while</span> <span class="op">(</span><span class="cn">TRUE</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># Increment the iteration counter</span></span>
<span>  <span class="va">iteration</span> <span class="op">&lt;-</span> <span class="va">iteration</span> <span class="op">+</span> <span class="fl">1</span></span>
<span>  </span>
<span>  <span class="co"># Compute the predicted values</span></span>
<span>  <span class="va">y_pred</span> <span class="op">&lt;-</span> <span class="va">beta0</span> <span class="op">+</span> <span class="va">beta1</span> <span class="op">*</span> <span class="va">x</span></span>
<span>  </span>
<span>  <span class="co"># Compute the errors</span></span>
<span>  <span class="va">error</span> <span class="op">&lt;-</span> <span class="va">y</span> <span class="op">-</span> <span class="va">y_pred</span></span>
<span>  </span>
<span>  <span class="co"># Compute the cost</span></span>
<span>  <span class="va">cost</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">error</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Print the current state</span></span>
<span>  <span class="co"># print(paste(iteration, beta0, beta1, cost, sep = ", "))</span></span>
<span>  </span>
<span>  <span class="co"># Store the results</span></span>
<span>  <span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="st">"iteration"</span> <span class="op">=</span> <span class="va">iteration</span>,<span class="st">"beta0"</span> <span class="op">=</span> <span class="va">beta0</span>, <span class="st">"beta1"</span> <span class="op">=</span> <span class="va">beta1</span>, <span class="st">"MSE"</span> <span class="op">=</span> <span class="va">cost</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Check for convergence</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">cost</span> <span class="op">-</span> <span class="va">prev_cost</span><span class="op">)</span> <span class="op">&lt;</span> <span class="va">convergence_threshold</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw">break</span></span>
<span>  <span class="op">}</span></span>
<span>  </span>
<span>  <span class="co"># Update the previous cost</span></span>
<span>  <span class="va">prev_cost</span> <span class="op">&lt;-</span> <span class="va">cost</span></span>
<span>  </span>
<span>  <span class="co"># Update the coefficients</span></span>
<span>  <span class="va">beta0</span> <span class="op">&lt;-</span> <span class="va">beta0</span> <span class="op">-</span> <span class="va">alpha</span> <span class="op">*</span> <span class="op">(</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">error</span><span class="op">)</span></span>
<span>  <span class="va">beta1</span> <span class="op">&lt;-</span> <span class="va">beta1</span> <span class="op">-</span> <span class="va">alpha</span> <span class="op">*</span> <span class="op">(</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">error</span> <span class="op">*</span> <span class="va">x</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>The code uses the gradient descent algorithm to fit a simple linear regression model into a dummy data set. The data consists of 5 pairs of values (x and y), and the goal is to find the values of the coefficients beta0 and beta1 that best fit the data.</p>
<p>The gradient descent algorithm works by starting with initial values for the coefficients (in this case, beta0 = 0 and beta1 = 0) and then iteratively updating the values of the coefficients in a way that reduces the cost (which is a measure of how well the model fits the data). The cost is computed using the mean squared error (MSE) between the predicted values and the actual values of y.</p>
<p>At each iteration, the code computes the predicted values of y, the errors, and the cost. It then updates the coefficients by moving in the opposite direction of the gradient (which is the derivative of the cost with respect to the coefficients). This update is scaled by the learning rate, which determines the size of the step taken in the opposite direction of the gradient.</p>
<p>The code includes a convergence check that compares the current cost with the previous cost and terminates the loop if the difference is less than the convergence threshold (which is set to 1e-5 in this example). This ensures that the algorithm will continue running for a while but will stop when it reaches a point where further updates to the coefficients will not likely improve the model significantly.</p>
<p>Let’s examine the results of the algorithm to the analytic solution.</p>
<div class="sourceCode" id="cb121"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">results</span></span>
<span><span class="co">#&gt;   iteration     beta0    beta1  MSE</span></span>
<span><span class="co">#&gt; 1      3793 0.4004022 2.399889 1.52</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span><span class="op">~</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; lm(formula = y ~ x)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;    1    2    3    4    5 </span></span>
<span><span class="co">#&gt;  0.2 -1.2  0.4  2.0 -1.4 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)  </span></span>
<span><span class="co">#&gt; (Intercept)   0.4000     1.6693   0.240   0.8261  </span></span>
<span><span class="co">#&gt; x             2.4000     0.5033   4.768   0.0175 *</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  </span></span>
<span><span class="co">#&gt; 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residual standard error: 1.592 on 3 degrees of freedom</span></span>
<span><span class="co">#&gt; Multiple R-squared:  0.8834, Adjusted R-squared:  0.8446 </span></span>
<span><span class="co">#&gt; F-statistic: 22.74 on 1 and 3 DF,  p-value: 0.01752</span></span></code></pre></div>
<p>The summary() function in R is used to generate a summary of a model. In this case, the lm() function is used to fit a linear regression model to the data, with y as the response variable and x as the predictor variable. The summary() function is then applied to the resulting model object to generate a summary of the model fit.</p>
<p>The summary of a linear regression model typically includes information such as the coefficients (i.e., the estimated values of beta0 and beta1 in this case), the intercept, the residuals (i.e., the difference between the observed values of y and the predicted values), the R-squared value (which indicates how well the model fits the data), and the F-statistic (which is used to assess the overall significance of the model). The summary can also include other diagnostic information, such as the distribution of the residuals, which can be useful for checking the assumptions of the model.</p>
<p>But when we compare the results, it seems we were pretty close!</p>
</div>
<div id="exercise-6" class="section level2" number="15.3">
<h2>
<span class="header-section-number">15.3</span> Exercise<a class="anchor" aria-label="anchor" href="#exercise-6"><i class="fas fa-link"></i></a>
</h2>
<blockquote>
<p>E1. Use the following data and estimate the coefficients.</p>
</blockquote>
<div class="sourceCode" id="cb122"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">1000</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="fl">4</span> <span class="op">*</span> <span class="va">x</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="co"># you can see the actual estimate of intercept and slope with </span></span>
<span><span class="co"># summary(lm(y~x))</span></span>
<span><span class="co"># Use gradient descent approach to identify those coefficients.</span></span></code></pre></div>
<blockquote>
<p>E2. Use the following data and estimate the coefficients.</p>
</blockquote>
<div class="sourceCode" id="cb123"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">1000</span></span>
<span><span class="va">x1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="va">x2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">2</span> <span class="op">-</span> <span class="fl">3</span> <span class="op">*</span> <span class="va">x1</span> <span class="op">+</span> <span class="fl">4</span> <span class="op">*</span> <span class="va">x2</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span></code></pre></div>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="gradient-descent-for-more-than-one-variable.html"><span class="header-section-number">14</span> Gradient descent for more than one variable</a></div>
<div class="next"><a href="standard-error.html"><span class="header-section-number">16</span> Standard error</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#gradient-descent-for-simple-regression"><span class="header-section-number">15</span> Gradient descent for simple regression</a></li>
<li><a class="nav-link" href="#scatter-plot"><span class="header-section-number">15.1</span> Scatter plot</a></li>
<li><a class="nav-link" href="#intuition-of-simple-linear-regression"><span class="header-section-number">15.2</span> Intuition of simple linear regression</a></li>
<li><a class="nav-link" href="#exercise-6"><span class="header-section-number">15.3</span> Exercise</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/rstudio/bookdown-demo/blob/master/14-gradient-descent-simple-regression.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/rstudio/bookdown-demo/edit/master/14-gradient-descent-simple-regression.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Mostly Handsdirty Metrics</strong>" was written by Shishir Shakya. It was last built on 2022-12-15.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
